<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="dark"><head><meta charset="UTF-8"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@500&display=swap" rel="stylesheet"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="SeulQxQ"><meta name="keywords" content=""><meta name="description" content="Keep Working"><meta property="og:type" content="website"><meta property="og:title" content="Seul"><meta property="og:url" content="http://seulqxq.top/page/3/index.html"><meta property="og:site_name" content="Seul"><meta property="og:description" content="Keep Working"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="SeulQxQ"><meta name="twitter:card" content="summary_large_image"><title>Seul</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css"><link rel="stylesheet" href="/css/cloudedGlass.css"><link rel="stylesheet" href="/css/selection.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"seulqxq.top",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:50,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><header><div class="header-inner" style="height:100vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>SeulQxQ&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url('/img/1.png') no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.2)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="Keep Working"></span></div></div><div class="scroll-down-bar"><i class="iconfont icon-arrowdown"></i></div></div></div></div></div></header><main><div class="container nopadding-x-md"><div id="board" style="margin-top:0"><div class="container"><div class="row"><div class="col-12 col-md-10 m-auto"><div class="row mx-auto index-card"><div class="col-12 col-md-4 m-auto index-img"><a href="/posts/47195/" target="_self"><img src="/img/index/17.jpg" srcset="/img/loading.gif" lazyload alt="Model"></a></div><article class="col-12 col-md-8 mx-auto index-info"><h1 class="index-header"><a href="/posts/47195/" target="_self">Model</a></h1><a class="index-excerpt" href="/posts/47195/" target="_self"><div>pi-GAN 主要结构 1 pi-GAN 的overview 映射网络是一个简单的 ReLU MLP，它将噪声向量 z 作为输入并输出频率 γi 和相移 βi，它调节 SIREN 的每一层。 2 pi-GAN代码主要函数 3 渐进式增长辨别器overview pi-GAN 主要的网络 1 siren: FiLMed-SIREN network (8个隐藏层)</div></a><div class="index-btm post-metas"><div class="post-meta mr-3"><i class="iconfont icon-date"></i> <time datetime="2023-10-29 20:44" pubdate>2023-10-29</time></div><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/NeRF/" class="category-chain-item">NeRF</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/NeRF/">#NeRF</a> <a href="/tags/%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/">#源码解读</a></div></div></article></div><div class="row mx-auto index-card"><div class="col-12 col-md-4 m-auto index-img"><a href="/posts/35133/" target="_self"><img src="/img/index/16.jpg" srcset="/img/loading.gif" lazyload alt="A Survey on Deep Generative 3D-aware Image Synthesis"></a></div><article class="col-12 col-md-8 mx-auto index-info"><h1 class="index-header"><a href="/posts/35133/" target="_self">A Survey on Deep Generative 3D-aware Image Synthesis</a></h1><a class="index-excerpt" href="/posts/35133/" target="_self"><div>A Survey on Deep Generative 3D-aware Image Synthesis time line INR(implicit nerual representation) NVS(3D novel view synthesis) NVS方法擅长从新颖的视角合成高保真和详细的图像，从而能够探索以前看不到的视角。 考虑到深度生成3D感知图像合成与基于I</div></a><div class="index-btm post-metas"><div class="post-meta mr-3"><i class="iconfont icon-date"></i> <time datetime="2023-10-22 16:40" pubdate>2023-10-22</time></div><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/3D/">#3D</a></div></div></article></div><div class="row mx-auto index-card"><div class="col-12 col-md-4 m-auto index-img"><a href="/posts/43769/" target="_self"><img src="/img/index/15.jpg" srcset="/img/loading.gif" lazyload alt="Deep3DSketch+_ Rapid 3D Modeling from Single Free-hand Sketches"></a></div><article class="col-12 col-md-8 mx-auto index-info"><h1 class="index-header"><a href="/posts/43769/" target="_self">Deep3DSketch+_ Rapid 3D Modeling from Single Free-hand Sketches</a></h1><a class="index-excerpt" href="/posts/43769/" target="_self"><div>Deep3DSketch+: Rapid 3D Modeling from Single Free-hand Sketches 1 引言 &amp; 相关工作 1. 引言 ​ 本文提出了一种名为Deep3DSketch+的新型3D建模方法，该方法可以从单个手绘草图中生成高保真度的3D模型。Deep3DSketch+采用了端到端的神经网络结构，包括==轻量级生成网络==和==结构感知的对抗</div></a><div class="index-btm post-metas"><div class="post-meta mr-3"><i class="iconfont icon-date"></i> <time datetime="2023-10-17 15:29" pubdate>2023-10-17</time></div><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/3D/">#3D</a> <a href="/tags/%E7%95%A5%E8%AF%BB/">#略读</a></div></div></article></div><div class="row mx-auto index-card"><div class="col-12 col-md-4 m-auto index-img"><a href="/posts/39032/" target="_self"><img src="/img/index/13.png" srcset="/img/loading.gif" lazyload alt="pi-GAN_ Periodic Implicit Generative Adversarial Networks for 3D-Aware"></a></div><article class="col-12 col-md-8 mx-auto index-info"><h1 class="index-header"><a href="/posts/39032/" target="_self">pi-GAN_ Periodic Implicit Generative Adversarial Networks for 3D-Aware</a></h1><a class="index-excerpt" href="/posts/39032/" target="_self"><div>pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware 1 提出的方法，贡献，相关工作 1. 方法 ​ 所提出的方法利用==基于SIREN==的神经辐射场表示来鼓励多视图一致性，从而允许从较宽的范围进行渲染相机姿势范围并提供可解释的 3D 结构。 SIREN隐式场景表示利用周期性激活函数，比ReLU</div></a><div class="index-btm post-metas"><div class="post-meta mr-3"><i class="iconfont icon-date"></i> <time datetime="2023-10-10 15:17" pubdate>2023-10-10</time></div><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/3D/">#3D</a> <a href="/tags/%E7%B2%BE%E5%BA%A6/">#精度</a></div></div></article></div><div class="row mx-auto index-card"><div class="col-12 col-md-4 m-auto index-img"><a href="/posts/7366/" target="_self"><img src="/img/index/13.jpg" srcset="/img/loading.gif" lazyload alt="Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion"></a></div><article class="col-12 col-md-8 mx-auto index-info"><h1 class="index-header"><a href="/posts/7366/" target="_self">Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion</a></h1><a class="index-excerpt" href="/posts/7366/" target="_self"><div>Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion 一、提出的方法与贡献 1.方法： ​ 作者提出了一种新的方法，将无条件生成模型与混合反演范式相结合，从单个图像中恢复三维信息。具体来说，他们使用神经辐射场（NeRF）来表示三维场景，并使用编码器产生潜在表示和</div></a><div class="index-btm post-metas"><div class="post-meta mr-3"><i class="iconfont icon-date"></i> <time datetime="2023-10-09 22:01" pubdate>2023-10-09</time></div><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/NeRF/">#NeRF</a> <a href="/tags/%E7%B2%BE%E8%AF%BB/">#精读</a></div></div></article></div><div class="row mx-auto index-card"><div class="col-12 col-md-4 m-auto index-img"><a href="/posts/52856/" target="_self"><img src="/img/index/14.jpg" srcset="/img/loading.gif" lazyload alt="Efficient Geometry-aware 3D Generative Adversarial Networks"></a></div><article class="col-12 col-md-8 mx-auto index-info"><h1 class="index-header"><a href="/posts/52856/" target="_self">Efficient Geometry-aware 3D Generative Adversarial Networks</a></h1><a class="index-excerpt" href="/posts/52856/" target="_self"><div>Efficient Geometry-aware 3D Generative Adversarial Networks 一、提出的方法、贡献、相关工作 1.方法： ​ 设计了一种混合显式-隐式3D感知网络，该网络使用内存高效的三平面表示显式地存储由轻量级隐式特征解码器聚合的轴对齐平面上的特征，以实现高效的体绘制，提高了3D基础渲染的计算效率。使用了一些偏离3D基础渲染的图像空间近似，同时</div></a><div class="index-btm post-metas"><div class="post-meta mr-3"><i class="iconfont icon-date"></i> <time datetime="2023-10-09 21:48" pubdate>2023-10-09</time></div><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/3D/">#3D</a> <a href="/tags/%E7%B2%BE%E8%AF%BB/">#精读</a></div></div></article></div><div class="row mx-auto index-card"><div class="col-12 col-md-4 m-auto index-img"><a href="/posts/9076/" target="_self"><img src="/img/index/12.jpg" srcset="/img/loading.gif" lazyload alt="Pix2NeRF_ Unsupervised Conditional π-GAN for Single Image to Neural Radiance Fields Translation"></a></div><article class="col-12 col-md-8 mx-auto index-info"><h1 class="index-header"><a href="/posts/9076/" target="_self">Pix2NeRF_ Unsupervised Conditional π-GAN for Single Image to Neural Radiance Fields Translation</a></h1><a class="index-excerpt" href="/posts/9076/" target="_self"><div>Pix2NeRF: Unsupervised Conditional π-GAN for Single Image to Neural Radiance Fields Translation 1 提出的方法， 贡献，相关工作 1. 方法 基于π-GAN模型，用于无条件3D感知图像合成的生成模型，它讲随机latent code映射到一类对象的辐射场。作者同时优化两个目标: （1）π-G</div></a><div class="index-btm post-metas"><div class="post-meta mr-3"><i class="iconfont icon-date"></i> <time datetime="2023-09-24 17:30" pubdate>2023-09-24</time></div><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/NeRF/">#NeRF</a> <a href="/tags/%E7%B2%BE%E5%BA%A6/">#精度</a></div></div></article></div><div class="row mx-auto index-card"><div class="col-12 col-md-4 m-auto index-img"><a href="/posts/51013/" target="_self"><img src="/img/index/11.png" srcset="/img/loading.gif" lazyload alt="每周总结(23.09.18-23.09.24)"></a></div><article class="col-12 col-md-8 mx-auto index-info"><h1 class="index-header"><a href="/posts/51013/" target="_self">每周总结(23.09.18-23.09.24)</a></h1><a class="index-excerpt" href="/posts/51013/" target="_self"><div>Weekly report Date: 23.09.18-23.09.24 Paper Title: Pix2NeRF: Unsupervised Conditional π-GAN for Single Image to Neural Radiance Fields Translation 1 Method, Contribution, Related Work 1.</div></a><div class="index-btm post-metas"><div class="post-meta mr-3"><i class="iconfont icon-date"></i> <time datetime="2023-09-24 16:53" pubdate>2023-09-24</time></div><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%AF%8F%E5%91%A8%E5%9B%9E%E9%A1%BE/" class="category-chain-item">每周回顾</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%80%BB%E7%BB%93-%E5%8F%8D%E6%80%9D/">#总结&反思</a></div></div></article></div><div class="row mx-auto index-card"><div class="col-12 col-md-4 m-auto index-img"><a href="/posts/38005/" target="_self"><img src="/img/index/10.png" srcset="/img/loading.gif" lazyload alt="每周总结(23.09.04-23.09.10)"></a></div><article class="col-12 col-md-8 mx-auto index-info"><h1 class="index-header"><a href="/posts/38005/" target="_self">每周总结(23.09.04-23.09.10)</a></h1><a class="index-excerpt" href="/posts/38005/" target="_self"><div>Weekly report Date: 23.09.04-23.09.10 Paper Title: Efficient Geometry-aware 3D Generative Adversarial Networks 1 Method, Contribution, Related Work. 1.1 Method: ​ A hybrid explicit-impli</div></a><div class="index-btm post-metas"><div class="post-meta mr-3"><i class="iconfont icon-date"></i> <time datetime="2023-09-10 20:03" pubdate>2023-09-10</time></div><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%AF%8F%E5%91%A8%E5%9B%9E%E9%A1%BE/" class="category-chain-item">每周回顾</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%80%BB%E7%BB%93-%E5%8F%8D%E6%80%9D/">#总结&反思</a></div></div></article></div><div class="row mx-auto index-card"><div class="col-12 col-md-4 m-auto index-img"><a href="/posts/36354/" target="_self"><img src="/img/index/9.jpg" srcset="/img/loading.gif" lazyload alt="每周总结(23.08.28-23.09.03)"></a></div><article class="col-12 col-md-8 mx-auto index-info"><h1 class="index-header"><a href="/posts/36354/" target="_self">每周总结(23.08.28-23.09.03)</a></h1><a class="index-excerpt" href="/posts/36354/" target="_self"><div>Weekly report Date: 23.08.28-23.09.03 1.Paper Title: Efficient Geometry-aware 3D Generative Adversarial Networks ​ 这篇论文介绍了一种高效的几何感知3D生成对抗网络（GANs）方法，该方法可以使用单视角2D照片集合生成高质量的多视角一致图像和3D形状。该方法采用</div></a><div class="index-btm post-metas"><div class="post-meta mr-3"><i class="iconfont icon-date"></i> <time datetime="2023-09-01 10:12" pubdate>2023-09-01</time></div><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%AF%8F%E5%91%A8%E5%9B%9E%E9%A1%BE/" class="category-chain-item">每周回顾</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%80%BB%E7%BB%93-%E5%8F%8D%E6%80%9D/">#总结&反思</a></div></div></article></div><nav aria-label="navigation"><span class="pagination" id="pagination"><a class="extend prev" rel="prev" href="/page/2/#board"><i class="iconfont icon-arrowleft"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/#board">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/#board">4</a><a class="extend next" rel="next" href="/page/4/#board"><i class="iconfont icon-arrowright"></i></a></span></nav></div></div></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://hexo.fluid-dev.com/docs/guide" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div></div><div><span id="timeDate">载入天数...</span> <span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("07/02/2020 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="🚀 for&nbsp"+dnum+"&nbspdays",document.getElementById("times").innerHTML=hnum+"&nbsphr&nbsp"+mnum+"&nbspmin&nbsp"+snum+"&nbspsec"}setInterval("createtime()",250)</script></div><div class="text-center py-1"><div><span>Copyright © 2020</span> <a href="https://erenspace.cool/" target="_blank" rel="nofollow noopener"><span>Eren‘s Spaceship</span></a><br></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var o=Fluid.plugins.typing,n=e.getElementById("subtitle");if(n&&o){var r=n.getAttribute("data-typed-text");jQuery.ajax({type:"GET",url:"https://v1.hitokoto.cn/",headers:{},dataType:"json",success:function(t){var e;if(t){var n="hitokoto".split(",");t instanceof Array&&(t=t[0]);for(const o of n){var i=t[o];if("string"==typeof i){e=i;break}i instanceof Object&&(t=i)}}o(e||r)},error:function(t,e,n){n&&console.error("Failed to request https://v1.hitokoto.cn/:",n),o(r)}})}}(window,document)</script><script src="/js/img-lazyload.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script src="/js/backgroundize.js"></script></body></html>