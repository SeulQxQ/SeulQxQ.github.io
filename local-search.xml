<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>每周总结 -- 心平气和，不急不躁</title>
    <link href="/posts/6012/"/>
    <url>/posts/6012/</url>
    
    <content type="html"><![CDATA[<div align = "center"><H3>总结 &amp; 反思</div><p><strong>时间：2023.12.25-2023.12.31</strong></p><p>​真是不好的开头哇，谁能想到这该死的服务器要装这么久啊，奔溃了┭┮﹏┭┮，装了我两天才弄好，害。这周前两天全浪费了，装玩服务器就全用来打游戏了。后面几天还好学了点，想了几个实验的点子，加到<code>pi-GAN</code>上去了，等待它的结果叭，说实话有点不想弄了。。。这周除了刷题，剩下的时间好像全用来看那个<code>Mip-NeRF</code>的代码了，有点难看懂，而且我还隐约感觉这个模块没啥用。</p><p>​这周我的师姐还给我算了一下命，哈哈哈。说我今年有点桃花，难怪这段时间遇到这么多感情上的事情，又是学妹，又是高中白月光，这周末还有一个大学同学要来找我玩，确实是有点（但是全是桃花劫，笑死）。这周是2023年的最后一周了哈，回想一下今年好像并没有干什么事情，从研一下学期开学算起，好像就前半学期有好好学习，看了一些论文，写了一个专利（但是师兄不让我发，气死我了），然后后半学期就没干啥了。暑假回去就考了一个科一（这个真是裂开了，失算了，害）。研二开学倒也看了点论文，学了点东西，但是大部分时间好像都花在学妹身上了，哈哈哈哈，魔幻的一学期，但是前两三个月确实是实实在在地挺开心的。</p><p>​好的，回归到这周来，周末大部分时间都配我大学同学去逛去了，也不知道为什么她突然会来到广州玩耍。该陪的还是得陪的，让人家一个女孩子大老远的一个人跑过来，一个人玩确实也不是很好意思。就陪着她玩了两天，或许是我的错觉，有那么一点点感觉到她对我有点意思，但是只能说一句抱歉了，我现在这个样子确实不适合恋爱，现在的我已经进入了一种贤者的状态了，对什么东西都提不起兴趣（害）。希望她能够找到一个让她开心、幸福的男生哇，这么好的一个女孩子，值得一个更好的男生来照顾她。好的，这周就到这咯，今年也就到这啦。新年快乐哇，新的一年也要天天开心，继续努力ヾ(◍°∇°◍)ﾉﾞ！！！</p><p><strong>心平气和，不急不躁</strong></p>]]></content>
    
    
    <categories>
      
      <category>每周回顾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结&amp;反思</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>小论文实验结果</title>
    <link href="/posts/64309/"/>
    <url>/posts/64309/</url>
    
    <content type="html"><![CDATA[<h4 id="baseline">1 Baseline</h4><p>baseline为 <code>pi-gan</code></p><p>Carla 数据集 128 * 128 结果为31.68(论文中为29)</p><p><img src="1.png" style="zoom: 80%;" /></p><h4 id="添加一层-mapping-network">2 添加一层 mapping network</h4><p>添加一层 mapping network的网络层后，最好结果为 27.65</p><figure><img src="2.png" alt="2" /><figcaption aria-hidden="true">2</figcaption></figure><h4id="添加一层-mapping-network-6层filmlayer2563层relu-mlp128-位置编码">3添加一层 mapping network， 6层FiLMLayer（256），3层ReLU-MLP（128）+位置编码</h4><p>最好结果25.82，最终结果27.79</p><figure><img src="3.png" alt="3" /><figcaption aria-hidden="true">3</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>简记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>简记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3D感知单视图图像合成</title>
    <link href="/posts/20173/"/>
    <url>/posts/20173/</url>
    
    <content type="html"><![CDATA[<div align="center"><H3>3D感知单视图图像合成</div><h3 id="abstract">Abstract</h3><h3 id="introduction">1 Introduction</h3><h3 id="related-work">2 Related Work</h3><h4 id="a.-2d-gans">A. 2D GANs</h4><h4 id="b.-3d-aware-gans">B. 3D-Aware GANs</h4><h4 id="c.-neural-radiance-representations">C. Neural RadianceRepresentations</h4><h3 id="methods">3 Methods</h3><h4 id="a.">A.</h4><h4 id="b.">B.</h4><h4 id="c.">C.</h4><h3 id="experiments-and-results">4 Experiments and Results</h3><h4 id="a.-1">A.</h4><h4 id="b.-1">B.</h4><h4 id="c.-1">C.</h4><h3 id="conclutions">5 Conclutions</h3><h3 id="references">References</h3>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>小论文方法</title>
    <link href="/posts/52414/"/>
    <url>/posts/52414/</url>
    
    <content type="html"><![CDATA[<h4 id="pi-gan">pi-GAN</h4><figure><img src="image-20231219205002454.png" alt="image-20231219205002454" /><figcaption aria-hidden="true">image-20231219205002454</figcaption></figure><figure><img src="image-20231221113745085.png" alt="image-20231221113745085" /><figcaption aria-hidden="true">image-20231221113745085</figcaption></figure><h4id="learning-dense-correspondence-for-nerf-based-face-reenactment">LearningDense Correspondence for NeRF-Based Face Reenactment</h4><p><strong>项目地址：</strong>https://songlin1998.github.io/planedict/（还没有开源）</p><figure><img src="pipeline.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ol type="1"><li>可尝试添加模块，canonical Tri-Planes规范三平面，superresolution超分辨率（提高图像分辨率与质量）</li></ol><h4 id="eg3d">EG3D</h4><figure><img src="image-20231219154538508.png" alt="image-20231219154538508" /><figcaption aria-hidden="true">image-20231219154538508</figcaption></figure><ol type="1"><li>Fourier featureencoding（傅里叶特征编码），加入到MLP网络中，从低频的图像中学习高频信息。</li><li>三平面表示的特征平面可以使用现成的基于2DCNN的生成器生成（例如StyleGAN1 2 3）</li><li>tri-plane decoder，轻量解码器，采用小型MLP网络。</li><li>2D CNN-base super-resolution module进行上采样并且改善RGB图像的特征图。（用于提升分辨率）</li></ol><h4 id="fenerf">FENERF</h4><figure><img src="image-20231224170922298.png" alt="image-20231224170922298" /><figcaption aria-hidden="true">image-20231224170922298</figcaption></figure><ol type="1"><li><p>采用了两个映射网络 <span class="math inline">\(Z_s,Z_t\)</span>，上面的那个输入到MLP网络中用来生成，下面这个输入到颜色输出分支来进行纹理调节。</p><p>train.py</p></li></ol><p><img src="image-20231224202622064.png" alt="image-20231224202622064" style="zoom:80%;" /></p><ol type="1"><li>添加一个额外的可学习特征网格，用来补偿高频图像细节</li></ol><blockquote><ol type="1"><li><p>采用 <spanclass="math inline">\(Z_t\)</span>，也加入到pi-GAN的颜色输出分支，形成一个新的损失函数。需要添加参数</p><pre><code class="hljs">siren.pyself.geo_mapping_network = CustomMappingNetwork(z_geo_dim, 256, len(self.network)*hidden_dim*2)self.app_mapping_network = CustomMappingNetwork(z_app_dim, 256, len(self.color_layer_sine)*hidden_dim*2)generator.pyfrequencies_geo, phase_shifts_geo = self.siren.geo_mapping_network(z_geo)frequencies_app, phase_shifts_app = self.siren.app_mapping_network(z_app)</code></pre></li><li><p>将可学习特征网格一同加入</p></li></ol></blockquote>]]></content>
    
    
    <categories>
      
      <category>简记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>简记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>每周总结 -- 解铃还须系铃人</title>
    <link href="/posts/46941/"/>
    <url>/posts/46941/</url>
    
    <content type="html"><![CDATA[<div align = "center"><H3>总结 &amp; 反思</div><p><strong>时间：2023.12.18-2023.12.24</strong></p><p>​这周终于完成了开题答辩了，这个答辩真的是要笑死我了，也太水了叭~，我还以为会正式一点的呢，第一次见要学生催老师问问题的答辩，哈哈哈哈哈，答辩完咯，好好的玩了一天。答辩完后，就开始了看论文改代码的时候了，害。看了一下<code>Mip-NeRF</code>的论文和代码，感觉可以把它位置编码的部分给加到<code>pi-GAN</code>上去，也不知道能不能行，试试叭。这周的前几天还是比较正常的，也有在每天刷题，最近好像还比较熟练了，纯靠自己也能够把题目做出来了，但是速度有点慢，还有许多进步的空间，继续加油努力！然后最气人的就是服务器被攻击了，好好的周末要我去重装服务器，气死我了<img src="649E7F0C.png" alt="img" style="zoom:50%;" /></p><p>​然后就是这周也许因为是有点忙，所以在思念学妹上没有那么强烈了，但还是会在闲下来的时候，发呆的时候想到她，害，果然是刻入脑海深处的人了哇。但起码生活还是在继续，也在慢慢的回归到以前的样子，没有必要忘记，也不想忘记，毕竟这段时间开心的日子相比难过的日子还是多很多的，以后回想的时候，也能够再开心开心，那个时候应该会更多感谢她有出现过在我的生活中，而不是，多么希望她没有出现过。</p><p>​其次就是在周六的时候，在日本读书的好朋友放假回国了，然后邀请我一起吃饭，但是我没有想到她也会叫上我高中喜欢的女孩子。时隔5年多我又再一次见到了我高中时候的白月光哇，真的没有想到还能够再见到她，很感谢我的好朋友让我再见到她。也许确实时间会消散一切，或者是埋藏一切，这次见到她，并没有了我高中时候的冲动，没有了那种感觉（也许是学妹给的刺激太大了，哈哈哈）。我有再很尽力尝试去和她聊天，但是好像我们并没有许多的共同话题，当然我们当天还是玩得挺开心的。当天结束后，我好像并没有那种对她依依不舍的感觉，更多的是那种很久未见的朋友，短暂相聚后又分别的那种不舍的感觉（对她们两个）。我想这应该就算是一种自我的释怀叭，从一种喜欢转变成另一种朋友之间的喜欢。多年之后我也许也会对学妹是这种感觉吧。最后，希望她们都开开心心的，然后顺风顺水的吧。</p><p><strong>解铃还须系铃人</strong></p>]]></content>
    
    
    <categories>
      
      <category>每周回顾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结&amp;反思</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Mip-NeRF - A Multiscale Representation for Anti-Aliasing Neural Radiance Fields</title>
    <link href="/posts/29490/"/>
    <url>/posts/29490/</url>
    
    <content type="html"><![CDATA[<figure><img src="image-20231222110226139.png" alt="image-20231222110226139" /><figcaption aria-hidden="true">image-20231222110226139</figcaption></figure><p>图 1：NeRF (a) 沿从每个像素的投影中心跟踪的光线采样点x，然后使用位置编码 (PE) γ 对这些点进行编码以产生特征 γ(x)。Mip-NeRF (b)而是推理由相机像素定义的 3D 锥形截锥。然后使用我们的集成位置编码 (IPE)对这些圆锥截锥进行特征化，该编码的工作原理是用多元高斯逼近截锥，然后在高斯内坐标的位置编码上计算（封闭形式）积分E[γ(x)]。</p><ol type="1"><li>解决伪影：mipmap表示一组不同离散下采样尺度下的信号(通常是图像或纹理映射)，并根据像素足迹投影到该射线相交的几何图形上选择适当的尺度用于射线。这种策略被称为预过滤，因为抗锯齿的计算负担从渲染时间(如暴力超采样解决方案)转移到预计算阶段——mipmap只需要为给定的纹理创建一次，而不管纹理渲染的次数如何。</li><li>mip-NeRF(multum in parvo NeRF)，扩展了 NeRF以同时表示连续尺度空间的预过滤辐射场。mip-NeRF 的输入是一个 3D高斯，它表示应该集成辐射场的区域。</li><li>Integrated positional encoding(IPE) 集成位置编码。作用：特征表示，这是 NeRF 的位置编码 (PE)的推广，它允许将空间区域紧凑地特征化，而不是空间中的单个点。</li></ol><blockquote><p>IPE特征作为输入传递给MLP以产生密度 <spanclass="math inline">\(τ_k\)</span> 和颜色 <spanclass="math inline">\(c_k\)</span>，如公式1所示。mip-NeRF中的渲染遵循公式2。 <span class="math display">\[∀t_k ∈ t, [τ_k, c_k] = MLP(γ(r(t_k)); Θ)\]</span></p><p><span class="math display">\[\begin{array}{c}\mathbf{C}(\mathbf{r} ; \Theta, \mathrm{t})=\sum_{k} T_{k}\left(1-\exp\left(-\tau_{k}\left(t_{k+1}-t_{k}\right)\right)\right) \mathbf{c}_{k},\\\text { with } \quad T_{k}=\exp \left(-\sum_{k^{\prime}&lt;k}\tau_{k^{\prime}}\left(t_{k^{\prime}+1}-t_{k^{\prime}}\right)\right),\end{array}\]</span></p></blockquote><ol start="4" type="1"><li><p>Mip-NeRF的特点：Mip-NeRF的尺度感知结构还允许我们将NeRF用于分层采样的独立“粗”和“细”MLP合并为一个MLP。因此，mip-NeRF略快于 NeRF（~7%），参数数量减半。</p></li><li><p>Mip-NeRF通过从每个像素投射一个椎体改善混叠的问题。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>略读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>螺旋矩阵</title>
    <link href="/posts/52933/"/>
    <url>/posts/52933/</url>
    
    <content type="html"><![CDATA[<h4 id="力扣59-螺旋矩阵-ii">力扣59 <ahref="https://leetcode.cn/problems/spiral-matrix-ii/description/">螺旋矩阵II</a></h4><p>给你一个正整数<code>n</code>，生成一个包含<code>1</code>到<spanclass="math inline">\(n^2\)</span>所有元素，且元素按顺时针顺序螺旋排列的<code>n x n</code>正方形矩阵<code>matrix</code>。</p><p><strong>示例：</strong></p><p>输入：n = 3 输出：[[1,2,3],[8,9,4],[7,6,5]]</p><figure><img src="1.jpg?100×100" alt="示例" /><figcaption aria-hidden="true">示例</figcaption></figure><blockquote><p><strong>思路</strong>：该题不需要特别的算法，主要是靠模拟，设定边界。</p><p>​生成一个<code>n×n</code>的矩阵，然后模拟顺时针向内环绕的过程(边界很重要)，模拟过程包括从左到右，从上到下，从右到左，从下到上。分别设定上下左右边界<code>t,b,l,r</code>。每行或每列填充完之后，进行对应的行或列的收缩。当填充的数字满足<spanclass="math inline">\(n^2\)</span>时，结束循环。</p></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">generateMatrix</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:<br>        ans = [[<span class="hljs-number">0</span>]*n <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)] <span class="hljs-comment"># 生成n*n的二维数组</span><br>        l = t = <span class="hljs-number">0</span><br>        r = b = n-<span class="hljs-number">1</span> <br>        num = <span class="hljs-number">1</span><br>        nums = n*n<br>        <span class="hljs-keyword">while</span> num &lt;= nums:          <span class="hljs-comment"># 从外圈到内圈，每次循环一圈</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(l, r+<span class="hljs-number">1</span>): <span class="hljs-comment"># 从左到右</span><br>                ans[t][i] = num<br>                num += <span class="hljs-number">1</span><br>            t += <span class="hljs-number">1</span>                  <span class="hljs-comment"># 上边界下移</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(t, b+<span class="hljs-number">1</span>): <span class="hljs-comment"># 从上到下</span><br>                ans[i][r] = num<br>                num += <span class="hljs-number">1</span><br>            r -= <span class="hljs-number">1</span>                  <span class="hljs-comment"># 右边界左移</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(r, l-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>): <span class="hljs-comment"># 从右到左</span><br>                ans[b][i] = num<br>                num += <span class="hljs-number">1</span><br>            b -= <span class="hljs-number">1</span>                  <span class="hljs-comment"># 下边界上移</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(b, t-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>): <span class="hljs-comment"># 从下到上</span><br>                ans[i][l] = num<br>                num += <span class="hljs-number">1</span><br>            l += <span class="hljs-number">1</span>                  <span class="hljs-comment"># 左边界右移</span><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></td></tr></table></figure><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">generateMatrix</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:<br>        nums = [[<span class="hljs-number">0</span>] * n <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)]<br>        startx, starty = <span class="hljs-number">0</span>, <span class="hljs-number">0</span>               <span class="hljs-comment"># 起始点</span><br>        loop, mid = n // <span class="hljs-number">2</span>, n // <span class="hljs-number">2</span>          <span class="hljs-comment"># 迭代次数、n为奇数时，矩阵的中心点</span><br>        count = <span class="hljs-number">1</span>                           <span class="hljs-comment"># 计数</span><br><br>        <span class="hljs-keyword">for</span> offset <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, loop + <span class="hljs-number">1</span>) :      <span class="hljs-comment"># 每循环一层偏移量加1，偏移量从1开始</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(starty, n - offset) :    <span class="hljs-comment"># 从左至右，左闭右开</span><br>                nums[startx][i] = count<br>                count += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(startx, n - offset) :    <span class="hljs-comment"># 从上至下</span><br>                nums[i][n - offset] = count<br>                count += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n - offset, starty, -<span class="hljs-number">1</span>) : <span class="hljs-comment"># 从右至左</span><br>                nums[n - offset][i] = count<br>                count += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n - offset, startx, -<span class="hljs-number">1</span>) : <span class="hljs-comment"># 从下至上</span><br>                nums[i][starty] = count<br>                count += <span class="hljs-number">1</span>                <br>            startx += <span class="hljs-number">1</span>         <span class="hljs-comment"># 更新起始点</span><br>            starty += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">if</span> n % <span class="hljs-number">2</span> != <span class="hljs-number">0</span> :<span class="hljs-comment"># n为奇数时，填充中心点</span><br>            nums[mid][mid] = count <br>        <span class="hljs-keyword">return</span> nums<br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">generateMatrix</span>(<span class="hljs-type">int</span> n) &#123;<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">ans</span>(n, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;(n)); <span class="hljs-comment">//创建一个n*n的二维数组</span><br>        <span class="hljs-type">int</span> l, t = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> r, b = n<span class="hljs-number">-1</span>;<br>        <span class="hljs-type">int</span> cnt = <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span>(cnt &lt;= n*n)&#123;                      <span class="hljs-comment">//cnt从1开始，每次循环+1，直到n*n</span><br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=l; i&lt;=r; i++)&#123;            <span class="hljs-comment">//从左到右</span><br>                ans[t][i] = cnt;<br>                cnt++;<br>            &#125;   <br>            t++;                                 <span class="hljs-comment">//上边界+1</span><br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=t; i&lt;=b; i++)&#123;            <span class="hljs-comment">//从上到下</span><br>                ans[i][r] = cnt;<br>                cnt++;<br>            &#125;<br>            r--;                                <span class="hljs-comment">//右边界-1</span><br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=r; i&gt;=l; i--)&#123;            <span class="hljs-comment">//从右到左</span><br>                ans[b][i] = cnt;<br>                cnt++;<br>            &#125;<br>            b--;                                <span class="hljs-comment">//下边界-1</span><br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=b; i&gt;=t; i--)&#123;            <span class="hljs-comment">//从下到上</span><br>                ans[i][l] = cnt;<br>                cnt++;<br>            &#125;<br>            l++;                                <span class="hljs-comment">//左边界+1</span><br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>剑指 Offer 29. 顺时针打印矩阵 <ahref="https://leetcode.cn/problems/shun-shi-zhen-da-yin-ju-zhen-lcof/description/">剑指Offer 29. 顺时针打印矩阵</a></p><p>输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字。</p><p><strong>示例：</strong></p><p>输入：matrix = [[1,2,3],[4,5,6],[7,8,9]]输出：[1,2,3,6,9,8,7,4,5]</p><p><strong>限制：</strong></p><ul><li><code>0 &lt;= matrix.length &lt;= 100</code></li><li><code>0 &lt;= matrix[i].length &lt;= 100</code></li></ul><blockquote><p><strong>思路</strong>：该题不需要特别的算法，主要是靠模拟，设定边界。</p><p>模拟顺时针向内环绕的过程(边界很重要)，模拟过程包括从左到右，从上到下，从右到左，从下到上。分别设定上下左右边界<code>t,b,l,r</code>。每行或每列读取完之后，进行对应的行或列的收缩。因为该题中的矩阵并不一定是正方形矩阵，因此判断结束的条件应该为边界是否重合。</p></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">spiralOrder</span>(<span class="hljs-params">self, matrix: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> matrix: <span class="hljs-keyword">return</span> []                <span class="hljs-comment">#判断是否为空  </span><br>        l, r, t, b = <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(matrix[<span class="hljs-number">0</span>]) - <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(matrix) - <span class="hljs-number">1</span>  <span class="hljs-comment"># 列， 行</span><br>        result = []<br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(l, r + <span class="hljs-number">1</span>):           <span class="hljs-comment">#从左到右</span><br>                result.append(matrix[t][i])<br>            t +=  <span class="hljs-number">1</span>                             <span class="hljs-comment">#上边界下移</span><br>            <span class="hljs-keyword">if</span> t &gt; b:                           <span class="hljs-comment">#判断是否越界</span><br>                <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(t, b + <span class="hljs-number">1</span>):           <span class="hljs-comment">#从上到下   </span><br>                result.append(matrix[i][r])<br>            r -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> l &gt; r: <br>                <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(r, l - <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):       <span class="hljs-comment">#从右到左</span><br>                result.append(matrix[b][i])<br>            b -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> t &gt; b: <br>                <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(b, t - <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):       <span class="hljs-comment">#从下到上</span><br>                result.append(matrix[i][l])<br>            l += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> l &gt; r: <br>                <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">spiralOrder</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; matrix)</span> </span>&#123;<br>        vector&lt;<span class="hljs-type">int</span>&gt; ans;        <span class="hljs-comment">// 存放结果     </span><br>        <span class="hljs-keyword">if</span>(matrix.<span class="hljs-built_in">empty</span>())&#123;     <span class="hljs-comment">// 矩阵为空</span><br>            <span class="hljs-keyword">return</span> ans;<br>        &#125;<br>        <span class="hljs-type">int</span> l = <span class="hljs-number">0</span>, t = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> r = matrix[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span> ; <span class="hljs-comment">// 列</span><br>        <span class="hljs-type">int</span> b = matrix.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>;    <span class="hljs-comment">// 行</span><br>        <span class="hljs-keyword">while</span>(<span class="hljs-literal">true</span>)&#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=l; i&lt;=r; i++) ans.<span class="hljs-built_in">push_back</span>(matrix[t][i]); <span class="hljs-comment">// 从左到右</span><br>            t++;                                                 <span class="hljs-comment">// 上边界下移</span><br>            <span class="hljs-keyword">if</span>(t&gt;b) <span class="hljs-keyword">break</span>;                                       <span class="hljs-comment">// 上边界大于下边界，退出</span><br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=t; i&lt;=b; i++) ans.<span class="hljs-built_in">push_back</span>(matrix[i][r]); <span class="hljs-comment">// 从上到下</span><br>            r--;<br>            <span class="hljs-keyword">if</span>(l&gt;r) <span class="hljs-keyword">break</span>;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=r; i&gt;=l; i--) ans.<span class="hljs-built_in">push_back</span>(matrix[b][i]); <span class="hljs-comment">// 从右到左</span><br>            b--;<br>            <span class="hljs-keyword">if</span>(t&gt;b) <span class="hljs-keyword">break</span>;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=b; i&gt;=t; i--) ans.<span class="hljs-built_in">push_back</span>(matrix[i][l]); <span class="hljs-comment">// 从下到上</span><br>            l++;<br>            <span class="hljs-keyword">if</span>(l&gt;r) <span class="hljs-keyword">break</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h4 id="螺旋矩阵总结">螺旋矩阵总结</h4><p>这种题目并不涉及到什么算法，就是模拟过程，但却十分考察对代码的掌控能力。一定要注意边界的问题，统一循环的变量。</p><p>模拟顺时针画矩阵的过程:</p><ul><li>从左到右</li><li>从上到下</li><li>从右到左</li><li>从下到上</li></ul><p>由外向内一圈一圈这么画下去。同时需要注意限制，需要判断矩阵是正方形，还是不一定是正方形，来给出结束的条件。</p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>刷题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>算法训练之 -- 滑动窗口</title>
    <link href="/posts/60655/"/>
    <url>/posts/60655/</url>
    
    <content type="html"><![CDATA[<h3 id="滑动窗口">滑动窗口</h3><h4 id="思路">1. 思路</h4><p>​题目：给定一个含有<code>n</code>个正整数的数组和一个正整数<code>s</code>，找出该数组中满足其和<code>≥s</code>的长度最小的连续子数组，并返回其长度。如果不存在符合条件的子数组，返回<code>0</code>。<ahref="https://leetcode.cn/problems/minimum-size-subarray-sum/">长度最小的子数组</a></p><p>输入：s = 7, nums = [2,3,1,2,4,3] 输出：2 解释：子数组 [4,3]是该条件下的长度最小的子数组。</p><blockquote><p><strong>思路</strong>：所谓滑动窗口，<strong>就是不断的调节子序列的起始位置和终止位置，从而得出我们要想的结果</strong>。在暴力解法中，是一个for循环滑动窗口的起始位置，一个for循环为滑动窗口的终止位置，用两个for循环完成了一个不断搜索区间的过程。其实从动画中可以发现滑动窗口也可以理解为双指针法的一种！只不过这种解法更像是一个窗口的移动，所以叫做滑动窗口更适合一些。</p><p>滑动窗口的方法：<code>i</code>为滑动窗口的终止位置，<code>j</code>为滑动窗口的起始位置，<code>Sum</code>记录当前<code>j-&gt;i</code>连续子数组的和，<code>i-j+1</code>为当前连续子数组的长度。</p><p>PS：滑动窗口最重要的是判断 左边的 指针什么时候开始滑动</p></blockquote><h4 id="解法">2. 解法</h4><p><strong>Python：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">minSubArrayLen</span>(<span class="hljs-params">self, target: <span class="hljs-built_in">int</span>, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        l = Sum = <span class="hljs-number">0</span><br>        Len =  <span class="hljs-built_in">float</span>(<span class="hljs-string">&quot;inf&quot;</span>)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(nums)):<br>            Sum += nums[i]  <span class="hljs-comment"># Sum为当前子数组的和</span><br>            <span class="hljs-keyword">while</span> Sum &gt;= target: <br>                Len = <span class="hljs-built_in">min</span>(Len, i - l + <span class="hljs-number">1</span>)    <span class="hljs-comment"># 有最小 最大要求 就需要进行比较</span><br>                Sum -= nums[l]              <span class="hljs-comment"># Sum减去当前子数组的起始元素</span><br>                l += <span class="hljs-number">1</span><br>        Len = <span class="hljs-number">0</span> <span class="hljs-keyword">if</span> Len == <span class="hljs-built_in">float</span>(<span class="hljs-string">&quot;inf&quot;</span>) <span class="hljs-keyword">else</span> Len <span class="hljs-comment"># 如果Len没有被赋值，说明没有符合条件的子数组，返回0</span><br>        <span class="hljs-keyword">return</span> Len<br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">minSubArrayLen</span><span class="hljs-params">(<span class="hljs-type">int</span> target, vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> l=<span class="hljs-number">0</span>, r = <span class="hljs-number">0</span>, sum = <span class="hljs-number">0</span>, len = INT_MAX;<br>        <span class="hljs-keyword">for</span>(r=<span class="hljs-number">0</span>; r &lt; nums.<span class="hljs-built_in">size</span>(); r++)&#123; <span class="hljs-comment">//滑动窗口</span><br>            sum += nums[r];<br>            <span class="hljs-keyword">while</span>(sum &gt;= target)&#123;<br>                len = <span class="hljs-built_in">min</span>(len, r-l+<span class="hljs-number">1</span>); <span class="hljs-comment">//记录最小长度</span><br>                sum -= nums[l++]; <span class="hljs-comment">//缩小窗口</span><br>            &#125; <br>        &#125;<br>        <span class="hljs-keyword">return</span> len == INT_MAX ? <span class="hljs-number">0</span> : len;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h4 id="变种">3. 变种</h4><p><strong>☆☆（1）题目：</strong>你正在探访一家农场，农场从左到右种植了一排果树。这些树用一个整数数组<code>fruits</code> 表示，其中 <code>fruits[i]</code> 是第<code>i</code> 棵树上的水果 <strong>种类</strong>。你想要尽可能多地收集水果。然而，农场的主人设定了一些严格的规矩，你必须按照要求采摘水果：</p><ul><li>你只有 <strong>两个</strong> 篮子，并且每个篮子只能装<strong>单一类型</strong>的水果。每个篮子能够装的水果总量没有限制。</li><li>你可以选择任意一棵树开始采摘，你必须从 <strong>每棵</strong>树（包括开始采摘的树）上 <strong>恰好摘一个水果</strong>。采摘的水果应当符合篮子中的水果类型。每采摘一次，你将会向右移动到下一棵树，并继续采摘。</li><li>一旦你走到某棵树前，但水果不符合篮子的水果类型，那么就必须停止采摘。</li></ul><p>给你一个整数数组 <code>fruits</code> ，返回你可以收集的水果的<strong>最大</strong> 数目。<ahref="https://leetcode.cn/problems/fruit-into-baskets/description/">904.水果成篮 - 力扣（LeetCode）</a></p><blockquote><p><strong>思路：</strong>本题等价于<code>在一个窗口中找到最长的 只包含两个不同元素的最长子串序列（不同的元素不需要连续）</code></p><p>使用滑动窗口解决本题，left 和 right分别表示满足要求的窗口的左右边界，同时我们使用哈希表存储这个窗口内的数以及出现的次数。</p><ul><li><p>每次将 right 移动一个位置，并将 fruits[right]加入哈希表。</p></li><li><p>如果此时哈希表不满足要求（即哈希表中出现超过两个键值对），那么我们需要不断移动left，并将 fruits[left]从哈希表中移除，直到哈希表满足要求为止。</p></li><li><p>需要注意的是，将 fruits[left] 从哈希表中逐步减少后，如果fruits[left]在哈希表中的出现次数减少为0，需要将对应的键值对从哈希表中移除。</p></li></ul><p>PS：滑动窗口的重点在于如何 <code>创建窗口 和 更新窗口</code></p></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">totalFruit</span>(<span class="hljs-params">self, fruits: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        cnt = Counter() <span class="hljs-comment"># 用字典存储哈希表</span><br>        l = maxlen = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(fruits)):<br>            cnt[fruits[r]] += <span class="hljs-number">1</span><span class="hljs-comment"># 创建一个窗口</span><br>            <span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(cnt) &gt; <span class="hljs-number">2</span>:<span class="hljs-comment"># 缩小窗口 从而更新窗口</span><br>                cnt[fruits[l]] -= <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> cnt[fruits[l]] == <span class="hljs-number">0</span>:<br>                    cnt.pop(fruits[l])<br>                l += <span class="hljs-number">1</span><br><br>            maxlen = <span class="hljs-built_in">max</span>(maxlen, r-l+<span class="hljs-number">1</span>)<br>        <br>        <span class="hljs-keyword">return</span> maxlen<br><br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">totalFruit</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; fruits)</span> </span>&#123;<br>        <span class="hljs-type">int</span> l=<span class="hljs-number">0</span>, maxlen = <span class="hljs-number">0</span>;<br>        unordered_map&lt;<span class="hljs-type">int</span>, <span class="hljs-type">int</span>&gt; cnt;    <span class="hljs-comment">// 创建map字典</span><br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> r=<span class="hljs-number">0</span>; r&lt;fruits.<span class="hljs-built_in">size</span>(); r++)&#123;<br>            cnt[fruits[r]]++;           <span class="hljs-comment">// 创建窗口</span><br>            <span class="hljs-keyword">while</span>(cnt.<span class="hljs-built_in">size</span>() &gt; <span class="hljs-number">2</span>)&#123;<br>                <span class="hljs-keyword">auto</span> it = cnt.<span class="hljs-built_in">find</span>(fruits[l]);  <span class="hljs-comment">// 在字典中查找元素</span><br>                it-&gt;second--;       <br>                <span class="hljs-keyword">if</span>(it-&gt;second == <span class="hljs-number">0</span>)     <span class="hljs-comment">// 破坏窗口</span><br>                    cnt.<span class="hljs-built_in">erase</span>(it);<br>            l++;                        <span class="hljs-comment">// 窗口左移缩小 从而更新</span><br>            &#125;   <br>            maxlen = <span class="hljs-built_in">max</span>(maxlen, r-l+<span class="hljs-number">1</span>);<br>        &#125;<br>        <span class="hljs-keyword">return</span> maxlen;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>☆☆☆ (2) 题目：</strong>给你一个字符串 <code>s</code>、一个字符串 <code>t</code> 。返回 <code>s</code> 中涵盖 <code>t</code>所有字符的最小子串。如果 <code>s</code> 中不存在涵盖 <code>t</code>所有字符的子串，则返回空字符串 <code>""</code> 。<ahref="https://leetcode.cn/problems/minimum-window-substring/description/">76.最小覆盖子串 - 力扣（LeetCode）</a></p><blockquote><p><strong>思路：</strong>用i,j表示滑动窗口的左边界和右边界，通过改变i,j来扩展和收缩滑动窗口，可以想象成一个窗口在字符串上游走，当这个窗口包含的元素满足条件，即包含字符串T的所有元素，记录下这个滑动窗口的长度j-i+1，这些长度中的最小值就是要求的结果。</p><ul><li>不断增加<code>j</code>使滑动窗口增大，直到窗口包含了T的所有元素</li><li>不断增加i使滑动窗口缩小，因为是要求最小字串，所以将不必要的元素排除在外，使长度减小，直到碰到一个必须包含的元素，这个时候不能再扔了，再扔就不满足条件了，记录此时滑动窗口的长度，并保存最小值</li><li>让<code>i</code>再增加一个位置，这个时候滑动窗口肯定不满足条件了，那么继续从<strong>步骤一</strong>开始执行，寻找新的满足条件的滑动窗口，如此反复，直到<code>j</code>超出了字符串S范围。</li></ul><p>PS：思路讲解<ahref="https://leetcode.cn/problems/minimum-window-substring/solutions/258513/tong-su-qie-xiang-xi-de-miao-shu-hua-dong-chuang-k/">本题思路讲解</a></p></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">minWindow</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span>, t: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-comment"># cnt = Counter(t)# 使用下面的字典方法速度更快</span><br>        cnt = collections.defaultdict(<span class="hljs-built_in">int</span>)<span class="hljs-comment"># 使用字典存储 t 中的元素及其个数</span><br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> t:<br>            cnt[c] += <span class="hljs-number">1</span><br>        cntLen = <span class="hljs-built_in">len</span>(t)<br>        left = <span class="hljs-number">0</span><br>        ans = (<span class="hljs-number">0</span>, <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;inf&#x27;</span>))<br>        <span class="hljs-comment"># for right in range(len(s)):# 使用enum函数直接取元素， 比通过索引查询字符串中的元素要快</span><br>        <span class="hljs-comment">#     c = s[right]</span><br>        <span class="hljs-keyword">for</span> idx, c <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(s):<span class="hljs-comment"># 从 s 字符串中取元素</span><br>            <span class="hljs-keyword">if</span> cnt[c] &gt; <span class="hljs-number">0</span>:<br>                cntLen -= <span class="hljs-number">1</span><span class="hljs-comment"># 如果当前元素是 t 中元素， 长度 -1</span><br>            cnt[c] -= <span class="hljs-number">1</span><span class="hljs-comment"># 更新字典，字典中对应的 c 元素 -1（如果在t中不存在，值则为-1）</span><br>            <span class="hljs-keyword">if</span> cntLen == <span class="hljs-number">0</span>:<span class="hljs-comment"># 如果 t 总长度为0， 则说明当前窗口中已经包含了所有的 t 中的元素，准备缩小窗口</span><br>                <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>                    <span class="hljs-keyword">if</span> cnt[s[left]] == <span class="hljs-number">0</span>:<span class="hljs-comment"># 如果当前元素为 t 中的元素，跳出循环（窗口中需要包含 t 中的元素）</span><br>                        <span class="hljs-keyword">break</span><br>                    cnt[s[left]] += <span class="hljs-number">1</span><span class="hljs-comment"># 更新字典，当前元素值 +1</span><br>                    left += <span class="hljs-number">1</span><span class="hljs-comment"># 缩小窗口</span><br>                <span class="hljs-keyword">if</span> idx - left &lt; ans[<span class="hljs-number">1</span>] - ans[<span class="hljs-number">0</span>]:<span class="hljs-comment"># 进行比较，更新最小子串 </span><br>                    ans = (left, idx)<br>                cnt[s[left]] += <span class="hljs-number">1</span><span class="hljs-comment"># 下面这三行是因为 s[left] in t，当前窗口的第一个元素当好在 t 中</span><br>                cntLen += <span class="hljs-number">1</span><span class="hljs-comment"># 从上面的 if 中 break 出来了，所以需要对其进行 +1 操作</span><br>                left += <span class="hljs-number">1</span><span class="hljs-comment"># 同时 t 的总长度就也需要对应的 +1，从而使得窗口继续滑动</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">if</span> ans[<span class="hljs-number">1</span>] &gt; <span class="hljs-built_in">len</span>(s) <span class="hljs-keyword">else</span> s[ans[<span class="hljs-number">0</span>]:ans[<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>]<br>    <br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">string <span class="hljs-title">minWindow</span><span class="hljs-params">(string s, string t)</span> </span>&#123;<br>        unordered_map&lt;<span class="hljs-type">char</span>, <span class="hljs-type">int</span>&gt; cnt;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">const</span> <span class="hljs-type">char</span>&amp; c : t)&#123;<br>            cnt[c]++;<br>        &#125;<br>        <span class="hljs-type">int</span> cntLen = t.<span class="hljs-built_in">length</span>();<br>        <span class="hljs-type">int</span> left = <span class="hljs-number">0</span>, start = <span class="hljs-number">0</span>, end = INT_MAX;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> right=<span class="hljs-number">0</span>; right&lt;s.<span class="hljs-built_in">length</span>(); right++)&#123;<br>            <span class="hljs-keyword">if</span>(cnt[s[right]] &gt; <span class="hljs-number">0</span>)<br>                cntLen--;<br>            cnt[s[right]]--;<br>            <span class="hljs-keyword">if</span>(cntLen == <span class="hljs-number">0</span>)&#123;<br>                <span class="hljs-keyword">while</span>(<span class="hljs-literal">true</span>)&#123;<br>                    <span class="hljs-keyword">if</span>(cnt[s[left]] == <span class="hljs-number">0</span>)<br>                        <span class="hljs-keyword">break</span>;<br>                    cnt[s[left++]]++;<br>                &#125;<br>                <span class="hljs-keyword">if</span>(right - left + <span class="hljs-number">1</span> &lt; end)&#123;<br>                    start = left<br>                    end = right - left + <span class="hljs-number">1</span>;<br>                &#125;<br>                cnt[s[left++]]++;<br>                cntLen++;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> end == INT_MAX ? <span class="hljs-string">&quot;&quot;</span> : s.<span class="hljs-built_in">substr</span>(start, end);  <span class="hljs-comment">// substr(start_idx, len) 开始位置，截取长度</span><br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>(3) 题目：</strong>给定一个字符串 <code>s</code>，请你找出其中不含有重复字符的 <strong>最长子串</strong> 的长度。<ahref="https://leetcode.cn/problems/longest-substring-without-repeating-characters/description/">3.无重复字符的最长子串 - 力扣（LeetCode）</a></p><blockquote><p><strong>思路：</strong>滑动窗口 +哈希表，哈希表的表示可以使用字典和集合，使用集合的速度比使用字典的速度要快</p><p><ahref="https://leetcode.cn/problems/longest-substring-without-repeating-characters/solutions/2361797/3-wu-zhong-fu-zi-fu-de-zui-chang-zi-chua-26i5/">解法一</a>：</p><ul><li><p>哈希表 dicdicdic 统计： 指针 j 遍历字符 s ，哈希表统计字符 s[j]最后一次出现的索引 。</p></li><li><p>更新左指针 i： 根据上轮左指针 i 和 dic[s[j]] ，每轮更新左边界 i，保证区间 [i+1,j][i + 1, j][i+1,j] 内无重复字符且最大。<spanclass="math inline">\(i=max⁡(dic[s[j]],i)\)</span></p></li><li><p>更新结果 res ： 取上轮 res 和本轮双指针区间 [i+1,j] 的宽度（即j−i）中的最大值。<spanclass="math inline">\(res=max⁡(res,j−i)\)</span></p></li></ul><p><ahref="https://leetcode.cn/problems/longest-substring-without-repeating-characters/solutions/227999/wu-zhong-fu-zi-fu-de-zui-chang-zi-chuan-by-leetc-2/">解法二</a>：</p><ul><li><p>我们使用两个指针表示字符串中的某个子串（或窗口）的左右边界，其中左指针代表着上文中「枚举子串的起始位置」，而右指针即为<spanclass="math inline">\(r_k\)</span></p></li><li><p>在每一步的操作中，我们会将左指针向右移动一格，表示我们开始枚举下一个字符作为起始位置，然后我们可以不断地向右移动右指针，但需要保证这两个指针对应的子串中没有重复的字符。在移动结束后，这个子串就对应着以左指针开始的，不包含重复字符的最长子串。我们记录下这个子串的长度；</p></li><li><p>在枚举结束后，我们找到的最长的子串的长度即为答案。</p></li></ul></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 解法一：</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lengthOfLongestSubstring</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        dic, res, i = &#123;&#125;, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span><br>        n = <span class="hljs-built_in">len</span>(s)<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            <span class="hljs-keyword">if</span> s[j] <span class="hljs-keyword">in</span> dic:<br>                i = <span class="hljs-built_in">max</span>(dic[s[j]], i)<span class="hljs-comment"># 找到第二个相同字符的索引</span><br>            dic[s[j]] = j           <span class="hljs-comment"># 字典的值为当前字符的索引</span><br>            res = <span class="hljs-built_in">max</span>(res, j - i)<br>        <span class="hljs-keyword">return</span> res<br>    <br> <span class="hljs-comment"># 解法二：</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lengthOfLongestSubstring</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        <span class="hljs-comment"># 哈希集合，记录每个字符是否出现过</span><br>        occ = <span class="hljs-built_in">set</span>()<br>        n = <span class="hljs-built_in">len</span>(s)<br>        <span class="hljs-comment"># 右指针，初始值为 -1，相当于我们在字符串的左边界的左侧，还没有开始移动</span><br>        rk, ans = -<span class="hljs-number">1</span>, <span class="hljs-number">0</span> <span class="hljs-comment"># 也可以从0开始</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            <span class="hljs-keyword">if</span> i != <span class="hljs-number">0</span>:   <span class="hljs-comment"># 左指针向右移动一格，移除一个字符， 这个时候为遇到了相同字符</span><br>                occ.remove(s[i - <span class="hljs-number">1</span>])<br>            <span class="hljs-keyword">while</span> rk + <span class="hljs-number">1</span> &lt; n <span class="hljs-keyword">and</span> s[rk + <span class="hljs-number">1</span>] <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> occ: <span class="hljs-comment"># 不断地移动右指针，扩大窗口，直到遇到相同字符</span><br>                occ.add(s[rk + <span class="hljs-number">1</span>])<br>                rk += <span class="hljs-number">1</span><br>            ans = <span class="hljs-built_in">max</span>(ans, rk - i + <span class="hljs-number">1</span>)  <span class="hljs-comment"># 第 i 到 rk 个字符是一个极长的无重复字符子串</span><br>        <span class="hljs-keyword">return</span> ans<br><br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">lengthOfLongestSubstring</span><span class="hljs-params">(string s)</span> </span>&#123;<br>        <span class="hljs-comment">// 哈希集合，记录每个字符是否出现过</span><br>        unordered_set&lt;<span class="hljs-type">char</span>&gt; occ;<br>        <span class="hljs-type">int</span> n = s.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-comment">// 右指针，初始值为 -1，相当于我们在字符串的左边界的左侧，还没有开始移动</span><br>        <span class="hljs-type">int</span> rk = <span class="hljs-number">-1</span>, ans = <span class="hljs-number">0</span>;<br>        <span class="hljs-comment">// 枚举左指针的位置，初始值隐性地表示为 -1</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ++i) &#123;<br>            <span class="hljs-keyword">if</span> (i != <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-comment">// 左指针向右移动一格，移除一个字符</span><br>                occ.<span class="hljs-built_in">erase</span>(s[i - <span class="hljs-number">1</span>]);<br>            &#125;<br>            <span class="hljs-keyword">while</span> (rk + <span class="hljs-number">1</span> &lt; n &amp;&amp; !occ.<span class="hljs-built_in">count</span>(s[rk + <span class="hljs-number">1</span>])) &#123;<br>                <span class="hljs-comment">// 不断地移动右指针</span><br>                occ.<span class="hljs-built_in">insert</span>(s[rk + <span class="hljs-number">1</span>]);<br>                ++rk;<br>            &#125;<br>            <span class="hljs-comment">// 第 i 到 rk 个字符是一个极长的无重复字符子串</span><br>            ans = <span class="hljs-built_in">max</span>(ans, rk - i + <span class="hljs-number">1</span>);<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>(4) 题目:</strong>给你两个字符串 <code>s1</code> 和<code>s2</code> ，写一个函数来判断 <code>s2</code> 是否包含<code>s1</code> 的排列。如果是，返回 <code>true</code> ；否则，返回<code>false</code> 。</p><p>换句话说，<code>s1</code> 的排列之一是 <code>s2</code> 的<strong>子串</strong> 。<ahref="https://leetcode.cn/problems/permutation-in-string/description/">567.字符串的排列 - 力扣（LeetCode）</a></p><blockquote><p><strong>思路：</strong><ahref="https://leetcode.cn/problems/permutation-in-string/solutions/599528/zhu-shi-chao-xiang-xi-de-hua-dong-chuang-rc7d/">题解</a>滑动窗口 + 字典 Or 数组 <em>窗口固定</em></p><ul><li>分析一：题目要求 <code>s1</code> 的排列之一是 <code>s2</code>的一个子串。而<strong>子串</strong>必须是连续的，所以要求的<code>s2</code> 子串的长度跟 <code>s1</code> 长度必须相等。</li><li><strong>分析二：</strong> 那么我们有必要把 <code>s1</code>的每个排列都求出来吗？当然不用。如果字符串 <code>a</code> 是<code>b</code>的一个排列，那么当且仅当它们两者中的<strong>每个字符的个数都</strong>必须完全相等。<ul><li>使用一个长度和 s1 长度相等的固定窗口大小的滑动窗口，在 s2上面从左向右滑动，判断 s2 在滑动窗口内的每个字符出现的个数是否跟 s1每个字符出现次数完全相等。</li><li>定义 counter1 是对 s1 内字符出现的个数的统计，定义 counter2 是对 s2内字符出现的个数的统计。在窗口每次右移的时候，需要把右边新加入窗口的字符个数在counter2 中加 1，把左边移出窗口的字符的个数减 1。如果 counter1 ==counter2 ，那么说明窗口内的子串是 s1 的一个排列，返回True；如果窗口已经把 s2 遍历完了仍然没有找到满足条件的排列，返回False。</li></ul></li></ul><p>PS：本题中的 counter可以用字典，也可以用数组来实现。用字典的时候，需要注意：如果移除 left元素后，若 counter2[s2[left]] == 0 那么需要从字典中删除 s2[left]这个key。因为 {"a":0, "b":1} 和 {"b":1} 是不等的。</p></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">checkInclusion</span>(<span class="hljs-params">self, s1, s2</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :type s1: str</span><br><span class="hljs-string">        :type s2: str</span><br><span class="hljs-string">        :rtype: bool</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 统计 s1 中每个字符出现的次数</span><br>        counter1 = collections.Counter(s1)<br>        N = <span class="hljs-built_in">len</span>(s2)<br>        <span class="hljs-comment"># 定义滑动窗口的范围是 [left, right]，闭区间，长度与s1相等</span><br>        left = <span class="hljs-number">0</span><br>        right = <span class="hljs-built_in">len</span>(s1) - <span class="hljs-number">1</span><br>        <span class="hljs-comment"># 统计窗口s2[left, right - 1]内的元素出现的次数</span><br>        counter2 = collections.Counter(s2[<span class="hljs-number">0</span>:right])<br>        <span class="hljs-keyword">while</span> right &lt; N:<br>            <span class="hljs-comment"># 把 right 位置的元素放到 counter2 中</span><br>            counter2[s2[right]] += <span class="hljs-number">1</span><br>            <span class="hljs-comment"># 如果滑动窗口内各个元素出现的次数跟 s1 的元素出现次数完全一致，返回 True</span><br>            <span class="hljs-keyword">if</span> counter1 == counter2:<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>            <span class="hljs-comment"># 窗口向右移动前，把当前 left 位置的元素出现次数 - 1</span><br>            counter2[s2[left]] -= <span class="hljs-number">1</span><br>            <span class="hljs-comment"># 如果当前 left 位置的元素出现次数为 0， 需要从字典中删除，否则这个出现次数为 0 的元素会影响两 counter 之间的比较</span><br>            <span class="hljs-keyword">if</span> counter2[s2[left]] == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">del</span> counter2[s2[left]]<br>            <span class="hljs-comment"># 窗口向右移动</span><br>            left += <span class="hljs-number">1</span><br>            right += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 使用数组来存储</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">checkInclusion</span><span class="hljs-params">(string s1, string s2)</span> </span>&#123;<br>        <span class="hljs-type">int</span> len1 = s1.<span class="hljs-built_in">length</span>(), len2 = s2.<span class="hljs-built_in">length</span>();<br><br>        <span class="hljs-keyword">if</span>(len1 &gt; len2)<span class="hljs-comment">// 使用数组存储需要注意判断子数组的长度是不是大于父数组的长度</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">cnt1</span><span class="hljs-params">(<span class="hljs-number">26</span>)</span>, <span class="hljs-title">cnt2</span><span class="hljs-params">(<span class="hljs-number">26</span>)</span></span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>; i&lt;len1; i++)&#123;<span class="hljs-comment">// 存储 s1的元素 以及 s2 对应s1的元素</span><br>            cnt1[s1[i] - <span class="hljs-string">&#x27;a&#x27;</span>]++;<br>            cnt2[s2[i] - <span class="hljs-string">&#x27;a&#x27;</span>]++;<br>        &#125;<br>        <span class="hljs-keyword">if</span>(cnt1 == cnt2)<span class="hljs-comment">// 判断是否相等</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=len1; i&lt;len2; i++)&#123;<span class="hljs-comment">// 移动窗口， 窗口大小不变</span><br>            cnt2[s2[i] - <span class="hljs-string">&#x27;a&#x27;</span>]++;<span class="hljs-comment">// 一进</span><br>            cnt2[s2[i-len1] - <span class="hljs-string">&#x27;a&#x27;</span>]--;<span class="hljs-comment">// 一出</span><br>            <span class="hljs-keyword">if</span>(cnt1 == cnt2)<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>(5) 题目：</strong>给定两个字符串 <code>s</code> 和<code>p</code>，找到 <code>s</code> 中所有 <code>p</code> 的<strong>异位词</strong>的子串，返回这些子串的起始索引。不考虑答案输出的顺序。</p><p><strong>异位词</strong>指由相同字母重排列形成的字符串（包括相同的字符串）。<ahref="https://leetcode.cn/problems/find-all-anagrams-in-a-string/description/?envType=study-plan-v2&amp;envId=top-100-liked">438.找到字符串中所有字母异位词 - 力扣（LeetCode）</a></p><blockquote><p><strong>思路：</strong>和（4）的解法一样，固定窗口，一进一出</p><p>根据题目要求，我们需要在字符串 s 寻找字符串 p 的异位词。因为字符串 p的异位词的长度一定与字符串 p 的长度相同，所以我们可以在字符串 s中构造一个长度为与字符串 p的长度相同的滑动窗口，并在滑动中维护窗口中每种字母的数量；当窗口中每种字母的数量与字符串p 中每种字母的数量相同时，则说明当前窗口为字符串 p 的异位词。</p></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用字典</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">findAnagrams</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span>, p: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        len_p = <span class="hljs-built_in">len</span>(p)<br>        left, right, ans = <span class="hljs-number">0</span>, len_p, []<br>        cnt_p = collections.defaultdict(<span class="hljs-built_in">int</span>)<br>        cnt_s = collections.defaultdict(<span class="hljs-built_in">int</span>)<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> p:<span class="hljs-comment"># 初始化 p 的字典</span><br>            cnt_p[c] += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> s[<span class="hljs-number">0</span>:right]:<span class="hljs-comment"># 初始化 s 的字典，此时只需要和 p 的长度相同</span><br>            cnt_s[c] += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> cnt_p == cnt_s:<span class="hljs-comment"># 先判断一波是否相等，方便后续窗口移动</span><br>            ans.append(left)<br>        <span class="hljs-keyword">while</span> right &lt; <span class="hljs-built_in">len</span>(s):<span class="hljs-comment"># 开始移动窗口 一进一出 窗口大小固定</span><br>            cnt_s[s[right]] += <span class="hljs-number">1</span><br>            cnt_s[s[left]] -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> cnt_s[s[left]] == <span class="hljs-number">0</span>:<span class="hljs-comment"># ps: 如果元素为0了，则需要将其删除</span><br>                <span class="hljs-keyword">del</span> cnt_s[s[left]]<br>            left += <span class="hljs-number">1</span><br>            right += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> cnt_p == cnt_s:<span class="hljs-comment"># 判断是否相等</span><br>                ans.append(left)<br>        <span class="hljs-keyword">return</span> ans<br><br> <span class="hljs-comment"># 使用数组</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">findAnagrams</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span>, p: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        s_len, p_len = <span class="hljs-built_in">len</span>(s), <span class="hljs-built_in">len</span>(p)<br>        <br>        <span class="hljs-keyword">if</span> s_len &lt; p_len:<span class="hljs-comment"># 使用数组则需要进行长度比较</span><br>            <span class="hljs-keyword">return</span> []<br><br>        ans = []<br>        s_count = [<span class="hljs-number">0</span>] * <span class="hljs-number">26</span><span class="hljs-comment"># 方法一样， 只是将字母通过一个长度为26的数组进行保存</span><br>        p_count = [<span class="hljs-number">0</span>] * <span class="hljs-number">26</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(p_len):<br>            s_count[<span class="hljs-built_in">ord</span>(s[i]) - <span class="hljs-number">97</span>] += <span class="hljs-number">1</span><br>            p_count[<span class="hljs-built_in">ord</span>(p[i]) - <span class="hljs-number">97</span>] += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">if</span> s_count == p_count:<br>            ans.append(<span class="hljs-number">0</span>)<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(s_len - p_len):<br>            s_count[<span class="hljs-built_in">ord</span>(s[i]) - <span class="hljs-number">97</span>] -= <span class="hljs-number">1</span><br>            s_count[<span class="hljs-built_in">ord</span>(s[i + p_len]) - <span class="hljs-number">97</span>] += <span class="hljs-number">1</span><br>            <br>            <span class="hljs-keyword">if</span> s_count == p_count:<br>                ans.append(i + <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">findAnagrams</span><span class="hljs-params">(string s, string p)</span> </span>&#123;<br>        <span class="hljs-type">int</span> len_p = p.<span class="hljs-built_in">size</span>(), len_s = s.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">if</span>(len_p &gt; len_s)<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;();<br>        vector&lt;<span class="hljs-type">int</span>&gt; ans;<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">list_p</span><span class="hljs-params">(<span class="hljs-number">26</span>)</span></span>;<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">list_s</span><span class="hljs-params">(<span class="hljs-number">26</span>)</span></span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>; i&lt;len_p; i++)&#123;<br>            list_p[p[i] - <span class="hljs-string">&#x27;a&#x27;</span>]++;<br>            list_s[s[i] - <span class="hljs-string">&#x27;a&#x27;</span>]++;<br>        &#125;<br>        <span class="hljs-keyword">if</span>(list_p == list_s)<br>            ans.<span class="hljs-built_in">emplace_back</span>(<span class="hljs-number">0</span>);<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=len_p; i&lt;len_s; i++)&#123;<br>            list_s[s[i] - <span class="hljs-string">&#x27;a&#x27;</span>]++;<br>            list_s[s[i-len_p] - <span class="hljs-string">&#x27;a&#x27;</span>]--;<br>            <span class="hljs-keyword">if</span>(list_p==list_s)<br>                ans.<span class="hljs-built_in">emplace_back</span>(i-len_p+<span class="hljs-number">1</span>);<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>刷题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>每周总结 -- 爱意随风起，风止意难平</title>
    <link href="/posts/57809/"/>
    <url>/posts/57809/</url>
    
    <content type="html"><![CDATA[<div align = "center"><H3>总结 &amp; 反思</div><p><strong>时间：2023.12.11-2023.12.17</strong></p><p>这周刷了题，改了一些代码，但是好像也没有很多效果。</p><p>这周的心情也不是那么的理想叭，虽然已经和她说清楚了，她不介意，我也不介意。但是我心里还是会很难受，我的心也是肉做的，我也实实在在的对她动心了，虽然是不介意（我也没有资格介意），但是我还是很在意她。在意她是不是会不开心，在意她现在是不是讨厌我。会去回想过去两个月时间里的点点滴滴，回想她开心的样子，我也不知道什么时候能够好起来，一个月？两个月？两年？或者又是一个6年吗。有时候真的好希望这两个月从来没有发生过，但是又不想失去这一点点的快乐时光。我现在只能让自己忙起来，才能不会去回想那些点滴，不会去想念她。真的、真的好喜欢我的师妹啊，呜呜呜。好想好想好想回到这个学期刚开学的时候啊，每天都能够和她说说话，能够和她互相道晚安，为什么这么优秀、这么开朗的一个女孩子会刚好在我最孤独的时候出现，而为什么又偏偏不能让我们在一起，这难道是老天爷给我的惩罚吗，为什么啊啊啊啊啊啊啊。不知道我们之间的关系还能维持多久，也许过几天我们之间的交流就会断联吧。我现在天天都会想要是她没有出现过，我现在会怎么样，要是我没有跟她表白，现在又会是什么样，但是好像并没有如果，自己造下的孽，只能自己来承受了。也许随着时间，这些思念就会同她一起埋在心底深处叭。现在的我啊，真的很难受啊，不知道为什么会变成这个样子。希望自己能赶快好起来叭，每天做点别的事情分散一下自己的注意力，不然真的太难熬了。也希望她能够好好的，能够变得更优秀，能够开开心心的，我也应该要开开心心的，提升自己，要自己变得更加优秀！这周就这样叭~</p><p><strong>爱意随风起，风止意难平</strong></p>]]></content>
    
    
    <categories>
      
      <category>每周回顾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结&amp;反思</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>毕业设计</title>
    <link href="/posts/26243/"/>
    <url>/posts/26243/</url>
    
    <content type="html"><![CDATA[<p>仅使用单视图 2D 照片集合的无监督生成高质量的多视图一致图像和 3D形状一直是一个长期的挑战。</p><ol type="1"><li><p>3D感知GAN方法可以保证视图一致性，神级辐射场用来开发3D感知图像合成技术。</p></li><li><p>生成纹理：可学习的3D位置嵌入编码，补偿高频图像细节。仅使用siren的网络缺乏细节图像。</p></li><li><p>早期的方法利用显式体素或体积表示，因此分辨率有限。最近，神经隐式场景表示被集成到生成对抗模型中，实现了更好的内存效率和多视图一致性</p></li><li><p>可学习的3D特征网格，，用于坐标嵌入的局部采样（ecoord）。为了预测具有2D 视图方向 d 的 3D 点 x的颜色，我们通过双三次插值从特征网格中采样一个局部特征向量，然后将其作为附加输入输入到颜色分支中。它有助于保留更细粒度的图像细节。</p></li></ol><p>EG3D</p><ol start="2" type="1"><li>EG3D目标：引入了一种新的生成器架构，用于从单视图 2D照片集合中学习无监督 3D表示学习，该架构旨在提高渲染的计算效率，同时保持对 3D基础神经渲染为真。</li><li>通过混合显式隐式 3D 表示来提高基于 3D的渲染的计算效率，该表示在不影响表现力的情况下，比完全隐式或显式方法提供了显着的速度和内存优势。</li><li>我们引入了一个基于三平面的3DGAN框架，该框架既高效又富有表现力，以实现高分辨率的几何感知图像合成。</li><li>显式表示，如离散体素网格，可以快速评估，但经常会产生沉重的内存开销，这使得它们难以扩展到高分辨率或复杂场景。隐式表示或坐标网络，通过将场景表示为连续函数，在内存效率和场景复杂性方面提供了潜在的优势。在实践中，这些隐式架构使用大型全连接网络进行评估缓慢，因为每个查询都需要通过网络进行完全传递。因此，完全显式和隐式表示提供了互补的好处。</li><li>局部隐式表示 [3, 5, 23, 56] 和混合显式隐式表示 [11,35,39,53]通过提供计算和内存高效的架构来组合这两种类型的表示的好处。受这些想法的启发，我们设计了一种新的混合显式隐式3D感知网络，该网络使用内存高效的三平面表示显式地存储由轻量级隐式特征解码器聚合的轴对齐平面上的特征，以实现高效的体绘制(图2c)。</li><li>在三平面公式中，我们沿着三个轴对齐的正交特征平面对齐我们的显式特征，每个平面分辨率为N × N × C（图 2c），N 是空间分辨率，C 是通道数。我们通过将任何 3D 位置 x∈ R3 投影到三个特征平面中的每一个上，通过双线性插值检索相应的特征向量(Fxy , Fxz , Fyz)，并通过求和聚合三个特征向量。一个额外的轻量级解码器网络，实现为一个小的MLP，将聚合的 3D 特征 F解释为颜色和密度。这些量使用(神经)体绘制渲染成RGB图像[41,45]。</li><li>最后，我们的三平面表示与这些替代方案相比具有另一个关键优势：特征平面可以使用现成的基于2D CNN 的生成器生成，从而能够使用接下来讨论的 GAN 框架跨 3D表示进行泛化。</li><li>在 GAN 设置中，我们的神经渲染器不是生成 RGB 图像，而是聚合来自每个32 通道三平面的特征，并从给定的相机姿势预测 32通道特征图像。接下来是一个“超分辨率”模块，用于对这些原始神经渲染图像进行上采样和细化（第4.2 节）</li><li>在我们的 GAN 设置中使用的三平面表示的特征由 StyleGAN2 CNN生成器生成。随机潜在代码和相机参数首先由映射网络处理以产生中间潜在代码，然后调制单独合成网络的卷积核。</li></ol><p>Tri-MipRF</p><ol type="1"><li>我们提出了一种新颖的 Tri-Mip编码，它支持神经辐射场的瞬时重建和反锯齿高保真渲染。关键是在三个正交mipmap 中分解预过滤的 3D 特征空间。通过这种方式，我们可以利用 2D预过滤特征图来有效地执行 3D区域采样，这在不牺牲效率的情况下显着提高了渲染质量。</li></ol><p>pi-GAN</p><ol type="1"><li><p>现有方法以两种方式不足：首先，它们可能缺乏潜在的 3D表示或依赖于视图不一致的渲染，因此合成不是多视图一致的图像；其次，它们通常依赖于表达能力不够的表示网络架构，因此它们的结果缺乏图像质量。我们提出了一种新的生成模型，称为周期性隐式生成对抗网络(π-GAN或pi-GAN)，用于高质量的3D感知图像合成。π-GAN利用具有周期性激活函数和体绘制的神经表示将场景表示为视图一致的辐射场。</p></li><li><p>生成对抗网络(GANs)能够生成高分辨率、逼真的图像[25,26,27]。然而，由于缺乏逼真的3D 训练数据，这些 GAN通常仅限于两个维度；因此，它们不能支持诸如合成单个对象的多个视图等任务。3D感知图像合成提供了从2D图像中学习无监督神经场景表示。学习到的表示可用于从新的相机姿势渲染视图一致的图像[44,57,19]。</p></li><li><p>给定输入噪声，π-GAN 条件由 SIREN 网络 [59]表示的隐式辐射场，这是一个具有周期性激活函数的全连接网络。条件辐射场将3D 位置和 2D 观察方向映射到与视图相关的辐射和视图无关的体积密度 [23,38]。使用依赖于经典体绘制技术的可微体绘制方法，我们可以从任意相机姿势[42]渲染辐射场。</p></li><li><p>π-GAN改进了以前3D感知图像合成方法的图像质量和视图一致性，如图1所示。该方法利用基于siren的神经辐射场表示来鼓励多视图一致性，允许从广泛的相机姿势渲染并提供可解释的3D结构。利用周期激活函数的SIREN隐式场景表示在表示精细细节方面比ReLU隐式表示更有能力，并使π-GAN渲染比以前工作更清晰的图像。</p></li><li><p>除了引入 π-GAN之外，我们还做出了两个额外的技术贡献。首先，我们观察到，虽然现有工作通过将输入噪声连接到一个或多个层来调节基于ReLU的辐射场，但对于周期激活的隐式神经表示（SIREN）来说，逐个连接的条件是次优的。相反，我们建议使用映射网络通过特征线性调制(FiLM) [51, 9] 来调节 SIREN 中的层。这一贡献通常可以应用于 GAN 之外的SIREN 架构。其次，我们引入了一种渐进式增长策略，该策略受到先前在 2D 卷积GAN [25] 中取得成功的启发，以加速训练和抵消 3D GAN的计算复杂度增加。</p></li><li><p>我们建议利用周期激活函数进行隐式神经表示，并证明这些网络被称为正弦表示网络或SIRENs。我们提出了SIREN，这是一种用于隐式神经表示的简单神经网络架构，它使用正弦作为周期激活函数：(具有周期性激活函数的隐式神经表示)</p><p>$Φ (x) = Wn (φn−1 ◦ φn−2 ◦ . . . ◦ φ0) (x) + bn, xi 7 → φi (xi) = sin(Wixi + bi) . $这里，φi : RMi 7 → RNi 是网络的第 i 层。它由权重矩阵 Wi ∈RNi×Mi 定义的仿射变换和应用于输入 xi ∈ RMi 的偏差 bi ∈ RNi组成，然后是应用于结果向量的每个组件的正弦非线性。</p><figure><img src="image-20231215215813115.png" alt="image-20231215215813115" /><figcaption aria-hidden="true">image-20231215215813115</figcaption></figure></li><li><p>FLiM(Feature-wise Linear Modulation): 特征线性调制</p><figure><img src="image-20231215220018656-17026488204801.png"alt="image-20231215220018656" /><figcaption aria-hidden="true">image-20231215220018656</figcaption></figure></li><li><p>FiLM模型从少量数据中学习，以泛化到比训练期间看到的更复杂和/或截然不同的数据。FLiM增强了网络生成复杂和多变场景的能力。FLiM有助于提高生成图像的质量和多样性，特别是在生成具有复杂几何和光照条件的三维场景时。</p></li><li><p>具体来说，我们使用 SIREN 作为我们框架的表示网络架构，并结合受NeRF 启发的神经渲染技术。然而，SIREN 和 NeRF仅在对单个对象或场景的过度拟合的背景下进行了探索，而我们研究了这些开创性作品在3D GAN 中的应用方面的组合。探索训练由自然 2D 数据监督的神经隐式 GAN的独特挑战是我们工作的核心贡献之一。</p></li><li><p>我们利用受 StyleGAN 启发的映射网络，该网络通过 FiLM条件在单个输入噪声向量上调节整个 MLP。</p></li><li><p>我们的生成器 GθG (z, ξ) 不是直接从输入噪声 z 生成 2D图像，而是生成以 z为条件的隐式辐射场。这个辐射场是使用体绘制渲染渲染渲染的，以从一些相机姿势ξ 生成 2D 图像。</p></li><li><p>在训练时，生成的图像被引导到传统的卷积鉴别器进行对抗训练。在测试时，辐射场可以从任意相机姿势渲染以产生视图一致的图像。</p></li><li><p>我们用神经辐射场隐式表示 3D 对象，该神经辐射场参数化为多层感知器(MLP)，它将空间 x = (x, y, z) 中的 3D 坐标和观察方向 d作为输入。神经辐射场输出空间变化的密度σ(x): R3→R和视相关颜色(r, g, b)=c(x, d):R5→R3。此外，我们利用StyleGAN启发的映射网络通过FiLM条件反射在噪声向量z上调节SIREN[51,9]。，我们将表示的FiLM-ed SIREN backbone 形式化为:</p><p><span class="math display">\[\begin{aligned}\Phi(\mathbf{x})= &amp; \phi_{n-1} \circ \phi_{n-2} \circ \ldots \circ\phi_{0}(\mathbf{x}) \\&amp; \phi_{i}\left(\mathbf{x}_{i}\right)=\sin \left(\gamma_{i}\cdot\left(\mathbf{W}_{i}\mathbf{x}_{i}+\mathbf{b}_{i}\right)+\boldsymbol{\beta}_{i}\right)\end{aligned}\]</span></p></li><li><p>神经体渲染</p></li></ol><p><span class="math display">\[\begin{array}{l}\mathbf{C}(\mathbf{r})=\int_{t_{n}}^{t_{f}} T(t) \sigma(\mathbf{r}(t))\mathbf{c}(\mathbf{r}(t), \mathbf{d}) d t \\\text { where } \quad T(t)=\exp \left(-\int_{t_{n}}^{t}\sigma(\mathbf{r}(s)) d s\right) .\end{array} \]</span></p><p>多视图不一致</p><ol type="1"><li><p>在没有几何约束的情况下，从一组 2D训练图像中优化辐射场可能会遇到关键的退化解决方案，从而导致基于 NeRF的生成模型中的多视图不一致问题。一些方法提出了颜色和形状的多视图正则化，以提高光度和几何一致性。采用不同的策略来减少2D渲染器带来的视图不一致工件[12,33,82,103,149]。</p></li><li><p>其实核心就在于体素渲染的时候，密度和颜色本身是跟视角无关的，只跟空间位置有关，不同视角的光线打到同一个位置上，他们的密度是相同的，所以相当于利用了多视图之间的一致性。</p><p>可能这时候就要有伙伴问了，颜色的建模是跟输入角度有关的呀？为什么说是多视图一致的呢。</p><p>这就是NeRF里面最微妙的一部分，虽然角度也作为了输入，但是实际上，<ahref="https://www.zhihu.com/search?q=神经网络&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2718837219%7D">神经网络</a>是可以泛化到未知的角度的。看起来不可思议对不对，但是很多理论跟实验都证明了，MLP本身可以实现某种插值的效果，即便输入是离散的采样，最终也能学到未知的某个位置的采样值，类似于“插值”的功能。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>简记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>简记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TensoRF - Tensorial Radiance Fields</title>
    <link href="/posts/32257/"/>
    <url>/posts/32257/</url>
    
    <content type="html"><![CDATA[<h3 id="tensorf-tensorial-radiance-fields">TensoRF: Tensorial RadianceFields</h3><p><strong>Overview</strong></p><p><img src="image-20231213140258227.png" alt="image-20231213140258227" style="zoom:80%;" /></p><p><strong>张量分解</strong></p><p><img src="image-20231213142555951.png" alt="image-20231213142555951" style="zoom:80%;" /></p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NeRF</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>算法训练之 -- 双指针</title>
    <link href="/posts/3463/"/>
    <url>/posts/3463/</url>
    
    <content type="html"><![CDATA[<h3 id="双指针">双指针</h3><h4 id="思路">1. 思路</h4><p>​ <strong>题目：</strong>给你一个数组 <code>nums</code> 和一个值<code>val</code>，你需要 <strong><ahref="https://baike.baidu.com/item/原地算法">原地</a></strong>移除所有数值等于 <code>val</code> 的元素，并返回移除后数组的新长度。</p><p>不要使用额外的数组空间，你必须仅使用 <code>O(1)</code> 额外空间并<strong><ahref="https://baike.baidu.com/item/原地算法">原地</a>修改输入数组</strong>。</p><p>元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。<ahref="https://leetcode.cn/problems/remove-element/description/">27.移除元素 - 力扣（LeetCode）</a></p><blockquote><p>双指针法（快慢指针法）：<strong>通过一个快指针和慢指针在一个for循环下完成两个for循环的工作。</strong></p><p>定义快慢指针</p><ul><li>快指针：寻找新数组的元素，新数组就是不含有目标元素的数组。这个指针需要一直向前，同时寻找目标元素。</li><li>慢指针：指向更新新数组下标的位置。指向需要更新的元素位置，如果没有找到目标元素，则跟着快指针一起向前移动。</li></ul></blockquote><h4 id="解法">2. 解法</h4><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">removeElement</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], val: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        slowIdx, fastIdx = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> fastIdx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(nums)):<br>            <span class="hljs-keyword">if</span> nums[fastIdx] != val:<span class="hljs-comment"># 快指针寻找目标元素，并一直向前移动，直接满足结束条件</span><br>                nums[slowIdx] = nums[fastIdx]<span class="hljs-comment"># 慢指针指向需要更新的元素位置，如果找到目标元素，则跟着快指针向前移动</span><br>                slowIdx += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> slowIdx<br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">removeElement</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> val)</span> </span>&#123;<br>        <span class="hljs-type">int</span> slowIdx = <span class="hljs-number">0</span>, fastIdx = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(fastIdx=<span class="hljs-number">0</span>; fastIdx&lt;nums.<span class="hljs-built_in">size</span>(); fastIdx++)&#123;<br>            <span class="hljs-keyword">if</span>(nums[fastIdx] != val)<br>                nums[slowIdx++] = nums[fastIdx];<br>        &#125;<br>        <span class="hljs-keyword">return</span> slowIdx;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h4 id="变种">3. 变种</h4><p><strong>(1) 题目：</strong> 给你一个 <strong>非严格递增排列</strong>的数组 <code>nums</code> ，请你<strong><ahref="http://baike.baidu.com/item/原地算法">原地</a></strong>删除重复出现的元素，使每个元素 <strong>只出现一次</strong>，返回删除后数组的新长度。元素的 <strong>相对顺序</strong> 应该保持<strong>一致</strong> 。然后返回 <code>nums</code> 中唯一元素的个数。<ahref="https://leetcode.cn/problems/remove-duplicates-from-sorted-array/description/">26.删除有序数组中的重复项 - 力扣（LeetCode）</a></p><blockquote><p><strong>思路：</strong>还是使用常规的双指针解法。关键步骤是找到一个判断语句，使得<code>slow</code> 慢指针移动，不同的题目 <code>slow</code>移动的条件不同，只要找到符合移动的条件，就可以直接进行逻辑上的元素移动覆盖。最后返回<code>slow + 1</code> 即为最后的数组的长度。</p><p>PS：一般情况下快指针是随着循环一直移动的。</p></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">removeDuplicates</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        slow, fast = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> fast <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(nums)):<br>            <span class="hljs-keyword">if</span> nums[slow] != nums[fast]:  <span class="hljs-comment"># 判断slow指针移动的语句</span><br>                slow += <span class="hljs-number">1</span><br>                nums[slow] = nums[fast]<br>        <span class="hljs-keyword">return</span> slow + <span class="hljs-number">1</span><span class="hljs-comment"># 返回最终的数组长度</span><br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">removeDuplicates</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> slow = <span class="hljs-number">0</span>, fast = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(fast = <span class="hljs-number">0</span>; fast &lt; nums.<span class="hljs-built_in">size</span>(); fast++)&#123;<br>            <span class="hljs-keyword">if</span>(nums[slow] != nums[fast])&#123;<br>                nums[++slow] = nums[fast];<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> slow + <span class="hljs-number">1</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>⁕⁕ (2) 题目：</strong>给定 <code>s</code> 和 <code>t</code>两个字符串，当它们分别被输入到空白的文本编辑器后，如果两者相等，返回<code>true</code> 。<code>#</code> 代表退格字符。<ahref="https://leetcode.cn/problems/backspace-string-compare/description/">844.比较含退格的字符串 - 力扣（LeetCode）</a></p><blockquote><p><strong>思路：</strong>一个字符是否会被删掉，只取决于该字符后面的退格符，而与该字符前面的退格符无关。因此当我们逆序地遍历字符串，就可以立即确定当前字符是否会被删掉。具体地，我们定义skip表示当前待删除的字符的数量。每次我们遍历到一个字符：若该字符为退格符，则我们需要多删除一个普通字符，我们让skip 加 1；若该字符为普通字符：</p><ul><li><p>若skip 为 0，则说明当前字符不需要删去；</p></li><li><p>若skip 不为 0，则说明当前字符需要删去，我们让skip 减 1。</p></li></ul><p>PS：双指针移动，不一定两个指针都在同一个数组上，也可以在两个不同的数组上。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">backspaceCompare</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span>, t: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">bool</span>:<br>        i, j = <span class="hljs-built_in">len</span>(s) -<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(t) - <span class="hljs-number">1</span><span class="hljs-comment"># 从后往前</span><br>        skipS = skipT = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span> i&gt;=<span class="hljs-number">0</span> <span class="hljs-keyword">or</span> j&gt;=<span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">while</span> i&gt;=<span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">if</span> s[i] == <span class="hljs-string">&quot;#&quot;</span>:<span class="hljs-comment"># 如果遇到了 ‘#’， 则说明需要跳过这个字符</span><br>                    skipS += <span class="hljs-number">1</span><br>                    i -= <span class="hljs-number">1</span><span class="hljs-comment"># i 指针需要一直移动</span><br>                <span class="hljs-keyword">elif</span> skipS &gt; <span class="hljs-number">0</span>:<span class="hljs-comment"># 如果还存有‘#’， 则需要将 ‘#’号前面的字符给消除掉</span><br>                    skipS -= <span class="hljs-number">1</span><br>                    i -= <span class="hljs-number">1</span><br>                <span class="hljs-keyword">else</span>:<br>                    <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">while</span> j&gt;=<span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">if</span> t[j] == <span class="hljs-string">&quot;#&quot;</span>:<br>                    skipT += <span class="hljs-number">1</span><br>                    j -= <span class="hljs-number">1</span><br>                <span class="hljs-keyword">elif</span> skipT &gt; <span class="hljs-number">0</span>:<br>                    skipT -= <span class="hljs-number">1</span><br>                    j -= <span class="hljs-number">1</span><br>                <span class="hljs-keyword">else</span>:<br>                    <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">if</span> i&gt;=<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> j&gt;= <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">if</span> s[i] != t[j]:<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>            <span class="hljs-keyword">elif</span> i&gt;=<span class="hljs-number">0</span> <span class="hljs-keyword">or</span> j&gt;=<span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br><br>            i -= <span class="hljs-number">1</span><br>            j -= <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">backspaceCompare</span><span class="hljs-params">(string s, string t)</span> </span>&#123;<br>        <span class="hljs-type">int</span> i = s.<span class="hljs-built_in">length</span>() - <span class="hljs-number">1</span>, j = t.<span class="hljs-built_in">length</span>() - <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span> skipS = <span class="hljs-number">0</span>, skipT = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span>(i &gt;= <span class="hljs-number">0</span> || j &gt;=<span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-keyword">while</span>(i&gt;=<span class="hljs-number">0</span>)&#123;<br>                <span class="hljs-keyword">if</span>(s[i--] == <span class="hljs-string">&#x27;#&#x27;</span>)<br>                    skipS += <span class="hljs-number">1</span>;<br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(skipS &gt; <span class="hljs-number">0</span>)&#123;<br>                    skipS--;<br>                    i--;<br>                &#125;<br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">break</span>;<br>            &#125;<br>            <span class="hljs-keyword">while</span>(j&gt;=<span class="hljs-number">0</span>)&#123;<br>                <span class="hljs-keyword">if</span>(t[j--] == <span class="hljs-string">&#x27;#&#x27;</span>)<br>                    skipT += <span class="hljs-number">1</span>;<br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(skipT &gt; <span class="hljs-number">0</span>)&#123;<br>                    skipS--;<br>                    j--;<br>                &#125;<br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">break</span>;<br>            &#125;<br><br>            <span class="hljs-keyword">if</span>(i&gt;=<span class="hljs-number">0</span> &amp;&amp; j&gt;=<span class="hljs-number">0</span>)&#123;<br>                <span class="hljs-keyword">if</span>(s[i] != t[j])<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(i &gt;=<span class="hljs-number">0</span> || j &gt;= <span class="hljs-number">0</span>)<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>            i--;<br>            j--;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>(3) 题目：</strong>给你一个按 <strong>非递减顺序</strong>排序的整数数组 <code>nums</code>，返回 <strong>每个数字的平方</strong>组成的新数组，要求也按 <strong>非递减顺序</strong> 排序。<ahref="https://leetcode.cn/problems/squares-of-a-sorted-array/description/">977.有序数组的平方 - 力扣（LeetCode）</a></p><blockquote><p><strong>思路：</strong></p><ul><li>使用两个指针分别指向位置 0 和n−1，每次比较两个指针对应的数，选择较大的那个逆序放入答案并移动指针。这种方法无需处理某一指针移动至边界的情况。</li><li>找到正数和负数的分界线，两个指针分别指向分界线和分界线的后一位，然后从中间往两端进行比较，将较小的放入新的数组中。</li></ul></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sortedSquares</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        n = <span class="hljs-built_in">len</span>(nums)<br>        ans = [<span class="hljs-number">0</span>] * n<br><br>        i, j, idx = <span class="hljs-number">0</span>, n-<span class="hljs-number">1</span>, n-<span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> i&lt;=j:<br>            <span class="hljs-keyword">if</span> nums[i]**<span class="hljs-number">2</span> &gt; nums[j]**<span class="hljs-number">2</span>:<br>                ans[idx] = nums[i]**<span class="hljs-number">2</span><br>                i += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                ans[idx] = nums[j]**<span class="hljs-number">2</span><br>                j -= <span class="hljs-number">1</span><br>            idx -= <span class="hljs-number">1</span><br>        <br>        <span class="hljs-keyword">return</span> ans<br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">sortedSquares</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> i=<span class="hljs-number">0</span>, j=nums.<span class="hljs-built_in">size</span>()<span class="hljs-number">-1</span>, idx=nums.<span class="hljs-built_in">size</span>()<span class="hljs-number">-1</span>;<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">ans</span><span class="hljs-params">(nums.size())</span></span>;<br>        <span class="hljs-keyword">while</span>(i&lt;=j)&#123;<br>            <span class="hljs-keyword">if</span>(nums[i]*nums[i] &gt; nums[j]*nums[j])&#123;<br>                ans[idx--] = nums[i] * nums[i];<br>                i++;<br>            &#125;<span class="hljs-keyword">else</span>&#123;<br>                ans[idx--] = nums[j] * nums[j];<br>                j--;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>⁕⁕ (4) 题目：</strong>给定一个长度为 <code>n</code>的整数数组 <code>height</code> 。有 <code>n</code> 条垂线，第<code>i</code> 条线的两个端点是 <code>(i, 0)</code> 和<code>(i, height[i])</code> 。找出其中的两条线，使得它们与<code>x</code>轴共同构成的容器可以容纳最多的水。返回容器可以储存的最大水量。<ahref="https://leetcode.cn/problems/container-with-most-water/description/">11.盛最多水的容器 - 力扣（LeetCode）</a></p><blockquote><p><strong>思路：</strong>面对这个题目，如果没有经验，很难想到双指针。本题的容量大小，即为<code>短板 * 当前水槽的长度</code>。设两指针 i , j ，指向的水槽板高度分别为h[i], h[j]，此状态下水槽面积为S(i,j) 。由于可容纳水的高度由两板中的<code>短板</code> 决定，因此可得如下 面积公式 ：<spanclass="math display">\[S(i,j)=min(h[i],h[j])×(j−i)\]</span></p><p>同时，无论长板还是短板向中间收窄一格，都会导致水槽底边宽度 -1：</p><ul><li>若向内 移动短板 ，水槽的短板 <code>min(h[i],h[j])</code>可能变大，因此下个水槽的面积 可能增大 。</li><li>若向内 移动长板 ，水槽的短板 <code>min(h[i],h[j])</code>不变或变小，因此下个水槽的面积 一定变小 。</li></ul><p>PS：为了减少时间，进行一下优化，当水槽的容量大小，大于<code>max(height) * (j - i)</code>时，则说明，水槽的容量不会再有机会变大了。</p></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">maxArea</span>(<span class="hljs-params">self, height: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        l = <span class="hljs-built_in">len</span>(height)<br>        left, right = <span class="hljs-number">0</span>, l - <span class="hljs-number">1</span><br>        ans = <span class="hljs-number">0</span><br>        maxh = <span class="hljs-built_in">max</span>(height) <span class="hljs-comment"># 最大的 高度</span><br>        <span class="hljs-keyword">while</span> left &lt;= right:<br>            <span class="hljs-keyword">if</span> height[left] &lt; height[right]:<br>                ans = <span class="hljs-built_in">max</span>(ans, height[left] * (right-left))<br>                left += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                ans = <span class="hljs-built_in">max</span>(ans, height[right] * (right-left))<br>                right -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> ans &gt;= maxh * (right - left): <span class="hljs-comment"># 优化</span><br>                <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 因为C++的vector容器需要添加算法头文件才能 使用max_element()函数</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123; <br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxArea</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; height)</span> </span>&#123;<br>        <span class="hljs-type">int</span> left = <span class="hljs-number">0</span>, right = height.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>, ans = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span>(left &lt;= right)&#123;<br>            <span class="hljs-keyword">if</span>(height[left] &lt; height[right])&#123;<br>                ans = <span class="hljs-built_in">max</span>(ans, (right - left) * height[left++]);<br>            &#125;<span class="hljs-keyword">else</span>&#123;<br>                ans = <span class="hljs-built_in">max</span>(ans, (right - left) * height[right--]);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>(5) 题目：</strong>给你一个长度为 <code>n</code> 的整数数组<code>nums</code> 和 一个目标值 <code>target</code>。请你从<code>nums</code> 中选出三个整数，使它们的和与 <code>target</code>最接近。返回这三个数的和。假定每组输入只存在恰好一个解。<ahref="https://leetcode.cn/problems/3sum-closest/description/">16.最接近的三数之和 - 力扣（LeetCode）</a></p><blockquote><p><strong>思路：</strong></p><ul><li>首先进行数组排序，时间复杂度 O(nlogn)</li><li>在数组 nums 中，进行遍历，每遍历一个值利用其下标i，形成一个固定值nums[i]</li><li>再使用前指针指向 start = i + 1 处，后指针指向 end = nums.length - 1处，也就是结尾处 根据 sum = nums[i] + nums[start] + nums[end]的结果，判断 sum 与目标 target 的距离，如果更近则更新结果 ans</li><li>同时判断 sum 与 target 的大小关系，因为数组有序，如果 sum &gt;target 则 end--，如果 sum &lt; target 则 start++，如果 sum == target则说明距离为 0 直接返回结果</li><li>整个遍历过程，固定值为 n 次，双指针为 n 次，时间复杂度为 O(n2)</li><li>总时间复杂度：O(nlogn)+O(n2)=O(n2)</li></ul></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">threeSumClosest</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        nums = <span class="hljs-built_in">sorted</span>(nums)<br>        ans = nums[<span class="hljs-number">0</span>] + nums[<span class="hljs-number">1</span>] + nums[<span class="hljs-number">2</span>]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(nums)):<br>            l, r = i + <span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">while</span> l &lt; r:<span class="hljs-comment"># 注意不需要等号</span><br>                s = nums[l]+nums[r]+nums[i]<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(target - s) &lt; <span class="hljs-built_in">abs</span>(target - ans):<br>                    ans = s<br>                <span class="hljs-keyword">if</span> s &gt; target:<br>                    r -= <span class="hljs-number">1</span><br>                <span class="hljs-keyword">elif</span> s &lt; target:<br>                    l += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">else</span>:<br>                    <span class="hljs-keyword">return</span> ans<br>        <span class="hljs-keyword">return</span> ans<br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">threeSumClosest</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> target)</span> </span>&#123;<br>        <span class="hljs-built_in">sort</span>(nums.<span class="hljs-built_in">begin</span>(), nums.<span class="hljs-built_in">end</span>());<br>        <span class="hljs-type">int</span> ans =  nums[<span class="hljs-number">0</span>] + nums[<span class="hljs-number">1</span>] + nums[<span class="hljs-number">2</span>];<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>; i&lt;nums.<span class="hljs-built_in">size</span>(); i++)&#123;<br>            <span class="hljs-type">int</span> l = i + <span class="hljs-number">1</span>, r = nums.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">while</span>(l &lt; r)&#123;<span class="hljs-comment">// 注意不需要等号</span><br>                <span class="hljs-type">int</span> sum = nums[i] + nums[l] + nums[r];<br>                <span class="hljs-keyword">if</span>(<span class="hljs-built_in">abs</span>(target - sum) &lt; <span class="hljs-built_in">abs</span>(target - ans))<br>                    ans = sum;<br>                <span class="hljs-keyword">if</span>(sum &lt; target)<br>                    l++;<br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(sum &gt; target)<br>                    r--;<br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">return</span> ans;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>刷题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>每周总结 -- 勇敢表达，无需害怕</title>
    <link href="/posts/27646/"/>
    <url>/posts/27646/</url>
    
    <content type="html"><![CDATA[<div align = "center"><H3>总结 &amp; 反思</div><p><strong>时间：2023.12.4-2023.12.10</strong></p><p>这周好像也没有学很多东西，学了点C++，看完了 <code>pi-GAN</code>的代码，好像就这么多。</p><p>这周应该又将是我人生中难以忘记的一周叭，心烦意乱。害，多么希望时间能够往回倒过去一点点啊。两个多月的接触，能够天天聊天，愿意分享自己的喜怒哀乐，真的很难让我不去多想。尤其是在这周，不知道为什么，我真的不能再控制住自己去想她，真的很想对她说“我喜欢你”。也许她并不知道，我做的那些，我发的那些其实都是对她说的。“享受当下时光，珍惜眼前之人”，突然感觉自己很好笑，一直都活在自我感觉良好的状态中。但是为什么她，真的没有对我有一点意思嘛，为什么要在我感觉很孤单的时候进入到我的生活中，真的会有女生跟一位比较陌生的男生说早安、晚安，分享日常吗。但是为什么她又说不想谈恋爱啊，为什么突然对我疏远，但是我真的已经难以自拔了，这种感觉真不好受哇。所以我是真的不能克制自己了，虽然我当时知道机会很渺茫，但是我还是想尝试一下，我不想错过那么哪怕是一丝的希望。其实我好像一直都很自卑，也不知道自己为什么会这样，喜欢一个人不是就应该勇敢的表达吗，但是我就是很害怕被拒绝，害怕自己配不上人家，真的好讨厌这样的自己啊。终于，我鼓起了勇气，表达了我的意思，结果也不出意料，被拒绝了，哈哈哈哈，那一刻确实觉得自己就像是一个小丑。但是我也算是打破了自己的心魔了叭（也许），虽然会很难受。喜欢一个人好像真的会让自己智商降低，这段时间每天都会等她的消息，每天都想着去和她聊天，没有心思去干别的事情，而她在这两个多月的时间里很有耐心的跟我聊天，分享她的日常，真的让我有种恋爱的感觉，这也许是我近几年最开心的两个月了吧。虽然结果不尽人意，但是起码我鼓起了勇气，而且好像除了难受，我也没有失去什么，想想也确实没有什么可害怕的，没有什么可自卑的。我觉得我已经足够勇敢了，但是也许正是一份份的遗憾，才能铸成最终的那一份美好吧。这周就这样叭，希望我自己之后也能一直勇敢，珍惜机会。</p><p><strong>勇敢表达，无需害怕</strong></p>]]></content>
    
    
    <categories>
      
      <category>每周回顾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结&amp;反思</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>C++ prime</title>
    <link href="/posts/61084/"/>
    <url>/posts/61084/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>C++</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C++ 基础语法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>STL源码剖析</title>
    <link href="/posts/10569/"/>
    <url>/posts/10569/</url>
    
    <content type="html"><![CDATA[<h2 id="stl源码解析">STL源码解析</h2><h3 id="stl概论">1 STL概论</h3><h4 id="stl六大组件">1.1 STL六大组件</h4><ol type="1"><li>容器（containers）：各种数据结构，如vector，list，deque，set，map，用来存放数据。</li><li>算法（algorithms）：各种常用算法，如sort，search，copy，erase···。</li><li>迭代器（iterator）：扮演容器与算法之间的胶合剂，是所谓的“泛型指针”。</li><li>仿函数（functors）：行为类似函数，可作为算法的某种策略（policy）。</li><li>配接器（adapters）：一种用来修饰容器或仿函数或迭代器接口的东西。</li><li>配置器（allocators）：负责空间配置与管理。</li></ol><h3 id="空间配置器allocator">2 空间配置器(allocator)</h3>]]></content>
    
    
    <categories>
      
      <category>C++</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C++ STL源码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>算法训练之 -- 二分查找</title>
    <link href="/posts/42877/"/>
    <url>/posts/42877/</url>
    
    <content type="html"><![CDATA[<h3 id="二分查找">1 二分查找</h3><h4 id="思路">1. 思路</h4><p>​ <strong>题目：</strong>给定一个 <code>n</code>个元素有序的（升序）整型数组 <code>nums</code> 和一个目标值<code>target</code> ，写一个函数搜索 <code>nums</code> 中的<code>target</code>，如果目标值存在返回下标，否则返回<code>-1</code>。<ahref="https://leetcode.cn/problems/binary-search/">704. 二分查找 -力扣（LeetCode）</a></p><blockquote><p>二分存在两种搜索的方法，（1）左闭右闭，（2）左闭右开。尽量使用一种写法，推荐使用第一种。</p><p><strong>左闭右闭：</strong><code>right</code>的长度为<code>len(nums) - 1</code>，while 循环中的判断为<code>left&lt;=right</code>，并且当更新<code>right</code>的长度时，使用<code>mid - 1</code>。</p><p><strong>左闭右开：</strong><code>right</code>的长度为<code>len(nums)</code>，while 循环中的判断为<code>left&lt;right</code>，并且当更新<code>right</code>的长度时，使用<code>mid</code>。</p></blockquote><h4 id="解法">2. 解法</h4><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">search</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        l = <span class="hljs-number">0</span><br>        r = <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> l &lt;= r:      <span class="hljs-comment"># 左闭右闭</span><br>            mid = (l+r)//<span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> nums[mid] == target:<br>                <span class="hljs-keyword">return</span> mid<br>            <span class="hljs-keyword">if</span> nums[mid] &gt; target:<br>                r = mid - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> nums[mid] &lt;target:<br>                l = mid + <span class="hljs-number">1</span><br>                <br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">search</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> target)</span> </span>&#123;<br>        <span class="hljs-type">int</span> l = <span class="hljs-number">0</span>, r = nums.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span>(l&lt;=r)&#123; <span class="hljs-comment">// 左闭右闭</span><br>            <span class="hljs-type">int</span> mid = l + (r - l) / <span class="hljs-number">2</span>;<br>            <span class="hljs-keyword">if</span>(nums[mid] &gt; target)&#123;<br>                r = mid - <span class="hljs-number">1</span>;<br>            &#125;<br>            <span class="hljs-keyword">if</span>(nums[mid] &lt; target)&#123;<br>                l = mid + <span class="hljs-number">1</span>;<br>            &#125;<br>            <span class="hljs-keyword">if</span>(nums[mid] == target)&#123;<br>                <span class="hljs-keyword">return</span> mid;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h4 id="变种">3. 变种</h4><p><strong>(1)题目：</strong>给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。<ahref="https://leetcode.cn/problems/search-insert-position/description/">35.搜索插入位置 - 力扣（LeetCode）</a></p><blockquote><p>由于数组中可能存在没有<code>target</code>的情况，而这种情况需要返回<code>target</code>可以插入的索引。</p><p>如果<code>while(l&lt;=r)</code> 则我们需要改变 <code>l</code>的索引，如果使用第二种二分<code>while(l&lt;r)</code>，则不需要做出改变。</p></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 第一种二分</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">searchInsert</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        l = <span class="hljs-number">0</span><br>        r = <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> l &lt;= r:<br>            mid = l + (r - l) // <span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> nums[mid] == target:<br>                <span class="hljs-keyword">return</span> mid<br>            <span class="hljs-keyword">if</span> nums[mid] &gt; target:<br>                r = mid - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> nums[mid] &lt; target:<br>                l = mid + <span class="hljs-number">1</span><span class="hljs-comment"># 改变 l 的索引，否则遇到 l = r 时回进入死循环</span><br>        <span class="hljs-keyword">return</span> l <br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 第二种二分</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">searchInsert</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> target)</span> </span>&#123;<br>        <span class="hljs-type">int</span> l = <span class="hljs-number">0</span>, r = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">while</span>(l &lt; r)&#123;<span class="hljs-comment">// l &lt; r 则不会遇到死循环的情况</span><br>            <span class="hljs-type">int</span> mid =  l + (r - l) / <span class="hljs-number">2</span>;<br>            <span class="hljs-keyword">if</span>(nums[mid] == target)<br>                <span class="hljs-keyword">return</span> mid;<br>            <span class="hljs-keyword">if</span>(nums[mid] &gt; target)<br>                r = mid;<br>            <span class="hljs-keyword">if</span>(nums[mid] &lt; target)<br>                l = mid + <span class="hljs-number">1</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> l;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>(2) 题目:</strong>给你一个按照非递减顺序排列的整数数组<code>nums</code>，和一个目标值<code>target</code>。请你找出给定目标值在数组中的开始位置和结束位置。如果数组中不存在目标值<code>target</code>，返回<code>[-1, -1]</code>。你必须设计并实现时间复杂度为<code>O(log n)</code> 的算法解决此问题。<ahref="https://leetcode.cn/problems/find-first-and-last-position-of-element-in-sorted-array/description/">34.在排序数组中查找元素的第一个和最后一个位置 - 力扣（LeetCode）</a></p><blockquote><p>思路：寻找<code>target</code>的起始位置和结束位置。其实就是从左边开始二分查找，找到第一个target，<code>letfidx = mid, r = mid - 1</code>；然后从右边开始二分，找到最后一个target，<code>rightidx = mid, l = mid + 1</code>。</p></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">searchRange</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        l, r = <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span><br>        left = right = -<span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span>(l &lt;= r):<br>            mid = (l + r) // <span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> nums[mid] == target:<br>                left = mid<br>                r = mid - <span class="hljs-number">1</span> <span class="hljs-comment"># 寻找第一个target，需要往左边移动 ！！！</span><br>            <span class="hljs-keyword">if</span> nums[mid] &lt; target:<br>                l = mid + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> nums[mid] &gt; target:<br>                r = mid - <span class="hljs-number">1</span><br>        <span class="hljs-comment"># left 定位好了</span><br><br>        l = left <span class="hljs-keyword">if</span> left != -<span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>        r = <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span>(l &lt;= r):<br>            mid = (l + r) // <span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> nums[mid] == target:<br>                right = mid<br>                l = mid + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> nums[mid] &lt; target:<br>                l = mid + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> nums[mid] &gt; target:<br>                r = mid - <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">return</span> [left, right]<br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">searchRange</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> target)</span> </span>&#123;<br>        <span class="hljs-type">int</span> l = <span class="hljs-number">0</span>, r = nums.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span> left = <span class="hljs-number">-1</span>, right = <span class="hljs-number">-1</span>;<br>        <span class="hljs-keyword">while</span>(l&lt;=r)&#123;<br>            <span class="hljs-type">int</span> mid = (l + r) / <span class="hljs-number">2</span>;<br>            <span class="hljs-keyword">if</span>(nums[mid] == target)&#123;<br>                left = mid;<br>                r = mid - <span class="hljs-number">1</span>;<br>            &#125;<br>            <span class="hljs-keyword">if</span>(nums[mid] &lt; target)<br>                l = mid + <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">if</span>(nums[mid] &gt; target)<br>                r = mid - <span class="hljs-number">1</span>;<br>        &#125;<br><br>        l = (left != <span class="hljs-number">-1</span>) ? left : <span class="hljs-number">0</span>;<br>        r = nums.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span>(l &lt;= r)&#123;<br>            <span class="hljs-type">int</span> mid = (l + r) / <span class="hljs-number">2</span>;<br>            <span class="hljs-keyword">if</span>(nums[mid] == target)&#123;<br>                right = mid;<br>                l = mid + <span class="hljs-number">1</span>;<br>            &#125;<br>            <span class="hljs-keyword">if</span>(nums[mid] &lt; target)<br>                l = mid + <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">if</span>(nums[mid] &gt; target)<br>                r = mid - <span class="hljs-number">1</span>;<br>        &#125;<br><br>        vector&lt;<span class="hljs-type">int</span>&gt; ans&#123;left, right&#125;;<br><br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>(3) 题目：</strong> 给你一个非负整数 <code>x</code>，计算并返回 <code>x</code> 的 <strong>算术平方根</strong>。由于返回类型是整数，结果只保留 <strong>整数部分</strong>，小数部分将被 <strong>舍去 。</strong></p><p><strong>注意：</strong>不允许使用任何内置指数函数和算符，例如<code>pow(x, 0.5)</code> 或者 <code>x ** 0.5</code> 。<ahref="https://leetcode.cn/problems/sqrtx/description/">69. x 的平方根 -力扣（LeetCode）</a></p><blockquote><p>思路：由于不能使用math函数库，因此可以使用二分的方法，通过<code>mid**2</code>来判断，从而得到<code>ans</code>的值。因为<span class="math inline">\(k^2 &lt;= x\)</span>，所以通过二分查找来找到 <code>k</code>，然后通过移动左右边界来定位<code>mid</code>。</p></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">mySqrt</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        l, r, ans = <span class="hljs-number">0</span>, x, -<span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> l &lt;= r:<br>            mid = l + (r - l) // <span class="hljs-number">2</span><span class="hljs-comment"># 防止溢出</span><br>            <span class="hljs-keyword">if</span> mid ** <span class="hljs-number">2</span> &lt;= x:<span class="hljs-comment"># 定位k</span><br>                ans = mid<br>                l = mid + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                r = mid - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">mySqrt</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> </span>&#123;<br>        <span class="hljs-type">int</span> l = <span class="hljs-number">0</span>, r = x, ans = <span class="hljs-number">-1</span>;<br>        <span class="hljs-keyword">while</span>(l &lt;= r)&#123;<br>            <span class="hljs-type">int</span> mid = l + (r - l) / <span class="hljs-number">2</span>; <span class="hljs-comment">// 防止溢出</span><br>            <span class="hljs-keyword">if</span>((<span class="hljs-type">long</span> <span class="hljs-type">long</span> )mid * mid &lt;= x)&#123; <span class="hljs-comment">// 大数 需要长整型</span><br>                ans = mid;<br>                l = mid + <span class="hljs-number">1</span>;<br>            &#125;<span class="hljs-keyword">else</span>&#123;<br>                r = mid - <span class="hljs-number">1</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>(4) 题目：</strong>给你一个满足下述两条属性的<code>m x n</code> 整数矩阵：</p><ul><li>每行中的整数从左到右按非严格递增顺序排列。</li><li>每行的第一个整数大于前一行的最后一个整数。</li></ul><p>给你一个整数 <code>target</code> ，如果 <code>target</code>在矩阵中，返回 <code>true</code> ；否则，返回 <code>false</code> 。<ahref="https://leetcode.cn/problems/search-a-2d-matrix/description/">74.搜索二维矩阵 - 力扣（LeetCode）</a></p><blockquote><p>思路：对于二维有序的矩阵，进行元素搜索时也可以使用二分。可以使用二次二分进行查找，也可以使用一次二分进行查找。</p><ul><li>两次二分查找：就是先对<code>行或列</code>进行查找，确定元素在哪<code>列或行</code>，然后对确定的那<code>列或行</code>进行第二次查找，最终找到元素。</li><li>一次二分查找：就是将二维矩阵看为一维数组，通过<code>取整取余</code>操作来判断元素位置，<code>mid / n</code>为元素的行，<code>mid % n</code>为元素列（因为每n个元素后才会换行）</li></ul></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 两次二分</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">searchMatrix</span>(<span class="hljs-params">self, matrix: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">bool</span>:<br>        n = <span class="hljs-built_in">len</span>(matrix[<span class="hljs-number">0</span>]) - <span class="hljs-number">1</span><span class="hljs-comment"># 列</span><br>        m = <span class="hljs-built_in">len</span>(matrix) - <span class="hljs-number">1</span> <span class="hljs-comment"># 行</span><br>        top = <span class="hljs-number">0</span><br>        left = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span> top &lt;= m:<br>            mid = top + (m - top) // <span class="hljs-number">2</span><br>            <span class="hljs-comment"># if matrix[mid][left] == target:</span><br>            <span class="hljs-comment">#     return True</span><br>            <span class="hljs-keyword">if</span> matrix[mid][left] &lt; target:<br>                top = mid + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> matrix[mid][left] &gt; target:<br>                m = mid - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>        top -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> left &lt;= n:<br>            mid = left + (n -left) // <span class="hljs-number">2</span><br>            <span class="hljs-comment"># if matrix[top][mid] == target:</span><br>            <span class="hljs-comment">#     return True</span><br>            <span class="hljs-keyword">if</span> matrix[top][mid] &lt; target:<br>                left = mid + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> matrix[top][mid] &gt; target:<br>                n = mid - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span> <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 一次二分</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">searchMatrix</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; matrix, <span class="hljs-type">int</span> target)</span> </span>&#123;<br>        <span class="hljs-type">int</span> m = matrix.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> n = matrix[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> left = <span class="hljs-number">0</span>, right = m * n - <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span>(left &lt;= right)&#123;<br>            <span class="hljs-type">int</span> mid = left + (right - left) / <span class="hljs-number">2</span>;<br>            <span class="hljs-keyword">if</span>(matrix[mid / n][mid % n] &gt; target)&#123;<br>                right = mid - <span class="hljs-number">1</span>;<br>            &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (matrix[mid / n][mid % n] &lt; target)&#123;<br>                left = mid + <span class="hljs-number">1</span>;<br>            &#125;<span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><strong>(5) 题目：</strong>在传递给函数之前，<code>nums</code>在预先未知的某个下标<code>k</code>（<code>0 &lt;= k &lt; nums.length</code>）上进行了<strong>旋转</strong>，使数组变为<code>[nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]]</code>（下标<strong>从 0 开始</strong> 计数）。例如， <code>[0,1,2,4,5,6,7]</code>在下标 <code>3</code> 处经旋转后可能变为 <code>[4,5,6,7,0,1,2]</code>。给你 <strong>旋转后</strong> 的数组 <code>nums</code> 和一个整数<code>target</code> ，如果 <code>nums</code> 中存在这个目标值<code>target</code> ，则返回它的下标，否则返回 <code>-1</code>。你必须设计一个时间复杂度为 <code>O(log n)</code> 的算法解决此问题。<ahref="https://leetcode.cn/problems/search-in-rotated-sorted-array/description/">33.搜索旋转排序数组 - 力扣（LeetCode）</a></p><blockquote><p><strong>思路：</strong>在常规二分查找的时候查看当前 mid为分割位置分割出来的两个部分 [l, mid] 和 [mid + 1, r]哪个部分是有序的，并根据有序的那个部分确定我们该如何改变二分查找的上下界，因为我们能够根据有序的那部分判断出target 在不在这个部分：</p><ul><li><p>如果 [l, mid - 1] 是有序数组，且 target 的大小满足[nums[l],nums[mid])，则我们应该将搜索范围缩小至 [l, mid - 1]，否则在[mid + 1, r] 中寻找。</p></li><li><p>如果 [mid, r] 是有序数组，且 target 的大小满足(nums[mid+1],nums[r]]，则我们应该将搜索范围缩小至 [mid + 1, r]，否则在[l, mid - 1] 中寻找。</p></li></ul><p><strong>PS：一定要注意等号的问题。</strong></p></blockquote><p><strong>Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">search</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        l, r = <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> l &lt;= r:<br>            mid = l + (r - l) // <span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> nums[mid] == target:<br>                    <span class="hljs-keyword">return</span> mid<br>            <span class="hljs-keyword">elif</span> nums[l] &lt;= nums[mid]:<br>                <span class="hljs-keyword">if</span> nums[l] &lt;= target <span class="hljs-keyword">and</span> target &lt; nums[mid]:<span class="hljs-comment"># 左等号</span><br>                    r = mid - <span class="hljs-number">1</span><br>                <span class="hljs-keyword">else</span>:<br>                    l = mid + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">if</span> nums[mid] &lt; target <span class="hljs-keyword">and</span> target &lt;= nums[r]:<span class="hljs-comment"># 右等号</span><br>                    l = mid + <span class="hljs-number">1</span><br>                <span class="hljs-keyword">else</span>:<br>                    r = mid - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br><br></code></pre></td></tr></table></figure><p><strong>C++</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">search</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> target)</span> </span>&#123;<br>        <span class="hljs-type">int</span> l = <span class="hljs-number">0</span>, r = nums.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span>(l &lt;= r)&#123;<br>            <span class="hljs-type">int</span> mid = l + (r - l) / <span class="hljs-number">2</span>;<br>            <span class="hljs-keyword">if</span>(nums[mid] == target)<br>                <span class="hljs-keyword">return</span> mid;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(nums[l] &lt;= nums[mid])&#123;<br>                <span class="hljs-keyword">if</span>(nums[l] &lt;= target &amp;&amp; target &lt; nums[mid]) <span class="hljs-comment">// 注意等号</span><br>                    r = mid - <span class="hljs-number">1</span>;<br>                <span class="hljs-keyword">else</span><br>                    l = mid + <span class="hljs-number">1</span>;<br>            &#125;<span class="hljs-keyword">else</span>&#123;<br>                <span class="hljs-keyword">if</span>(nums[mid] &lt; target &amp;&amp; target &lt;= nums[r]) <span class="hljs-comment">// 注意等号</span><br>                    l = mid + <span class="hljs-number">1</span>;<br>                <span class="hljs-keyword">else</span><br>                    r = mid - <span class="hljs-number">1</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>刷题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Model</title>
    <link href="/posts/47195/"/>
    <url>/posts/47195/</url>
    
    <content type="html"><![CDATA[<h3 id="pi-gan-主要结构">pi-GAN 主要结构</h3><h4 id="pi-gan-的overview">1 pi-GAN 的overview</h4><p><img src="image-20231029204458327.png" alt="image-20231029204458327" style="zoom: 67%;" /></p><p>映射网络是一个简单的 ReLU MLP，它将噪声向量 z 作为输入并输出频率 γi和相移 βi，它调节 SIREN 的每一层。</p><p><img src="image-20231029211833414.png" alt="image-20231029211833414" style="zoom:80%;" /></p><h4 id="pi-gan代码主要函数">2 pi-GAN代码主要函数</h4><p><img src="image-20231126194019676.png" alt="image-20231126194019676" style="zoom:50%;" /></p><h4 id="渐进式增长辨别器overview">3 渐进式增长辨别器overview</h4><p><img src="image-20231120165148746.png" alt="image-20231120165148746"  /></p><p><img src="image-20231120165057948.png" alt="image-20231120165057947"  /></p><h3 id="pi-gan-主要的网络">pi-GAN 主要的网络</h3><h4 id="siren">1 siren:</h4><ol type="1"><li>FiLMed-SIREN network (8个隐藏层) backbone</li></ol><p>(network): ModuleList(</p><p>(0): FiLMLayer(</p><p>(layer): Linear(in_features=3, out_features=256, bias=True))</p><p>(1): FiLMLayer(</p><p>(layer): Linear(in_features=256, out_features=256, bias=True))</p><p>(2): FiLMLayer(</p><p>(layer): Linear(in_features=256, out_features=256, bias=True))</p><p>(3): FiLMLayer(</p><p>(layer): Linear(in_features=256, out_features=256, bias=True))</p><p>(4): FiLMLayer(</p><p>(layer): Linear(in_features=256, out_features=256, bias=True))</p><p>(5): FiLMLayer(</p><p>(layer): Linear(in_features=256, out_features=256, bias=True))</p><p>(6): FiLMLayer(</p><p>(layer): Linear(in_features=256, out_features=256, bias=True))</p><p>(7): FiLMLayer(</p><p>(layer): Linear(in_features=256, out_features=256, bias=True))</p><p>)</p><ol start="2" type="1"><li>密度 颜色 输出层</li></ol><p>(final_layer): 密度输出层</p><p>Linear(in_features=256, out_features=1, bias=True)</p><p>(color_layer_sine): 颜色转换 + ray direction d</p><p>FiLMLayer(</p><p>(layer): Linear(in_features=259, out_features=256, bias=True)</p><p>)</p><p>(color_layer_linear): 颜色输出层</p><p>Sequential(</p><p>(0): Linear(in_features=256, out_features=3, bias=True)</p><p>(1): Sigmoid()</p><p>)</p><ol start="3" type="1"><li>Mapping network</li></ol><p>(mapping_network):</p><p>CustomMappingNetwork(</p><p>(network):</p><p>Sequential(</p><p>(0): Linear(in_features=256, out_features=256, bias=True)</p><p>(1): LeakyReLU(negative_slope=0.2, inplace=True)</p><p>(2): Linear(in_features=256, out_features=256, bias=True)</p><p>(3): LeakyReLU(negative_slope=0.2, inplace=True)</p><p>(4): Linear(in_features=256, out_features=256, bias=True)</p><p>(5): LeakyReLU(negative_slope=0.2, inplace=True)</p><p>(6): Linear(in_features=256, out_features=4608, bias=True)</p><p>))</p><h4 id="novel-view-synthesis-details">2 Novel View SynthesisDetails</h4><ol type="1"><li>冻结隐式表示的参数，为每层 MLP 寻找合适的 <spanclass="math inline">\(\gamma_i\)</span> 和 <spanclass="math inline">\(\beta_i\)</span>，生成辐射场，渲染出与目标图像最佳匹配。</li><li>计算 1w 次随机噪声向量输入的 <spanclass="math inline">\(\gamma\)</span> 和 <spanclass="math inline">\(\beta\)</span> 的平均值，然后启动梯度惩罚去最小化MES 图像重建 loss。</li></ol><h4 id="eg3d的overview">EG3D的overview</h4><p><img src="image-20231029204842971.png" alt="image-20231029204842971" style="zoom:80%;" /></p><p>​<img src="image-20231029204854626.png" alt="image-20231029204854626" style="zoom:80%;" /></p><h3 id="fenerf的主要结构">FENERF的主要结构</h3><h4 id="overview">1 Overview</h4><p><img src="image-20231122210056844.png" alt="image-20231122210056844" style="zoom: 50%;" /></p><figure><img src="image-20231122213829176.png" alt="image-20231122213829176" /><figcaption aria-hidden="true">image-20231122213829176</figcaption></figure><h4 id="fenerf-generator-architecture">2 FENeRF generatorarchitecture</h4><p><img src="image-20231122213913969.png" alt="image-20231122213913969" style="zoom:50%;" /></p><p><strong>FPN(Feature Pyramid Network) </strong></p><p>​ 发表于CVPR2017，用于目标检测，contribution是通过lateralconnection让高层高语义信息和低层高分辨率信息特征融合。</p><h3 id="modify">Modify</h3><ol type="1"><li>siren.py[68-71]，增加mapping network的隐藏层层数 3层 -&gt; 4层</li><li>siren.py[364-443]，增加3D特征向量到颜色输出层。</li></ol><p><img src="image-20231126193204895.png" alt="image-20231126193204895" style="zoom:50%;" /></p><p><strong>DeBug ing···</strong></p><h3 id="code-architecture">Code Architecture</h3><h4 id="discriminators.py">1 discriminators.py</h4><ol type="1"><li>ProgressiveDiscriminator() -&gt; ResidualCoordConvBlock(inplanesm,planes, downsample) -&gt; CoordConv(inplanes, planes)</li></ol><blockquote><p>ProgressiveDiscriminator：渐进式增长判别器</p><p>ResidualCoordConvBlock：渐进式增长卷积层</p><p>CoordConv：带坐标信息的卷积层计算</p></blockquote><p><strong>ResidualCoordConvBlock 网络层</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">0</span>:  <br>(network): Sequential(<br>    (<span class="hljs-number">0</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">18</span>, <span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">2</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">34</span>, <span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">3</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>  )       <br><span class="hljs-number">1</span>:<br>(network): Sequential(<br>    (<span class="hljs-number">0</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">130</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">2</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">258</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">3</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>  )<br><span class="hljs-number">2</span>:<br>(network): Sequential(<br>    (<span class="hljs-number">0</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">66</span>, <span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">2</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">130</span>, <span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">3</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>  )   <br><span class="hljs-number">3</span>:<br>(network): Sequential(<br>    (<span class="hljs-number">0</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">130</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">2</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">258</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">3</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>  )<br><span class="hljs-number">4</span>:<br>(network): Sequential(<br>    (<span class="hljs-number">0</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">258</span>, <span class="hljs-number">400</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">2</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">402</span>, <span class="hljs-number">400</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">3</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>  )<br><span class="hljs-number">5</span>:<br>(network): Sequential(<br>    (<span class="hljs-number">0</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">402</span>, <span class="hljs-number">400</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">2</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">402</span>, <span class="hljs-number">400</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">3</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>  )<br><span class="hljs-number">6</span>:<br>(network): Sequential(<br>    (<span class="hljs-number">0</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">402</span>, <span class="hljs-number">400</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">2</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">402</span>, <span class="hljs-number">400</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">3</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>  )<br><span class="hljs-number">7</span>:<br>(network): Sequential(<br>    (<span class="hljs-number">0</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">402</span>, <span class="hljs-number">400</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">2</span>): CoordConv(<br>      (addcoords): AddCoords()<br>      (conv): Conv2d(<span class="hljs-number">402</span>, <span class="hljs-number">400</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    )<br>    (<span class="hljs-number">3</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>, inplace=<span class="hljs-literal">True</span>)<br>  ) <br></code></pre></td></tr></table></figure><p><strong>AdapterBlock 网络结构</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python">(<span class="hljs-number">0</span>): AdapterBlock(<br>  (model): Sequential(<br>    (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">16</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>)<br>  )<br>)<br>(<span class="hljs-number">1</span>): AdapterBlock(<br>  (model): Sequential(<br>    (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>)<br>  )<br>)<br>(<span class="hljs-number">2</span>): AdapterBlock(<br>  (model): Sequential(<br>    (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>)<br>  )<br>)<br>(<span class="hljs-number">3</span>): AdapterBlock(<br>  (model): Sequential(<br>    (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>)<br>  )<br>)<br>(<span class="hljs-number">4</span>): AdapterBlock(<br>  (model): Sequential(<br>    (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>)<br>  )<br>)<br>(<span class="hljs-number">5</span>): AdapterBlock(<br>  (model): Sequential(<br>    (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">400</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>)<br>  )<br>)<br>(<span class="hljs-number">6</span>): AdapterBlock(<br>  (model): Sequential(<br>    (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">400</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>)<br>  )<br>)<br>(<span class="hljs-number">7</span>): AdapterBlock(<br>  (model): Sequential(<br>    (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">400</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>)<br>  )<br>)<br>(<span class="hljs-number">8</span>): AdapterBlock(<br>  (model): Sequential(<br>    (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">400</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    (<span class="hljs-number">1</span>): LeakyReLU(negative_slope=<span class="hljs-number">0.2</span>)<br>  )<br>)<br></code></pre></td></tr></table></figure><p><strong>from_RGB()的最后一层：</strong><code>(final_layer): Conv2d(400, 259, kernel_size=(2, 2), stride=(1, 1))</code></p><h4 id="siren.py">2 siren.py</h4><ol type="1"><li>TALLSIREN: forward -&gt; forward_with_frequencies_phase_shifts</li></ol><p><strong>forward input:</strong></p><p><code>position x:</code> 输入的位置信息 [img_size * img_size *num_steps]</p><p><code>z:</code> mapping network 的噪声输入 [256]</p><p><code>ray_directions:</code> 光线方向</p>]]></content>
    
    
    <categories>
      
      <category>NeRF</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NeRF</tag>
      
      <tag>源码解读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A Survey on Deep Generative 3D-aware Image Synthesis</title>
    <link href="/posts/35133/"/>
    <url>/posts/35133/</url>
    
    <content type="html"><![CDATA[<h3 id="a-survey-on-deep-generative-3d-aware-image-synthesis">A Surveyon Deep Generative 3D-aware Image Synthesis</h3><figure><img src="image-20231022164223977.png" alt="time line" /><figcaption aria-hidden="true">time line</figcaption></figure><p>INR(implicit nerual representation)</p><p>NVS(3D novel view synthesis)</p><p>NVS方法擅长从新颖的视角合成高保真和详细的图像，从而能够探索以前看不到的视角。</p><p>考虑到深度生成3D感知图像合成与基于INR的NVS之间的密切关系，利用基于INR的NVS中的进步可能会扩大3D感知图像生成中相机移动的范围。</p>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep3DSketch+_ Rapid 3D Modeling from Single Free-hand Sketches</title>
    <link href="/posts/43769/"/>
    <url>/posts/43769/</url>
    
    <content type="html"><![CDATA[<h3id="deep3dsketch-rapid-3d-modeling-from-single-free-hand-sketches">Deep3DSketch+:Rapid 3D Modeling from Single Free-hand Sketches</h3><h4 id="引言-相关工作">1 引言 &amp; 相关工作</h4><p><strong>1. 引言</strong></p><p>​本文提出了一种名为Deep3DSketch+的新型3D建模方法，该方法可以从单个手绘草图中生成高保真度的3D模型。Deep3DSketch+采用了端到端的神经网络结构，包括==轻量级生成网络==和==结构感知的对抗训练方法==。该方法还引入了笔画增强模块==(SEM)==，以提高网络的结构特征提取能力。</p><p><strong>2. 相关工作</strong></p><p>​现有的手绘草图3D建模方法可以分为两类：端到端方法和交互式方法。交互式方法需要进行顺序步骤分解或特定的绘画手势或注释。本文提出的Deep3DSketch+方法采用了端到端的神经网络结构，不需要输入多个草图或视图信息，可以从单个手绘草图中生成高保真度的3D模型。</p><p>​基于手绘草图的建模和传统的单目3D重建有很大的区别，草图的稀疏性和抽象性以及缺乏纹理需要额外的线索来产生高质量的3D形状。<code>需要解决</code>。</p><h4 id="方法-模型">2 方法 &amp; 模型</h4><p><strong>1. Overview:</strong></p><figure><img src="image-20231015163031452.png" alt="overview" /><figcaption aria-hidden="true">overview</figcaption></figure><p><strong>2. View-aware and Structure-aware 3D Modeling</strong></p><p><code>Mesh Generation G:</code> 主干为编码器-解码器结构</p><p><code>Encoder E:</code>由于草图是稀疏且模糊的输入形式，编码器E首先将输入的草图转换为 <em>latentshape code</em> <span class="math inline">\(z_s\)</span>，这样可以在涉及语义类别和概念形状的粗略级别上概括草图。</p><p><code>Decoder D:</code>级联的上采样块组成的解码器D用于计算模板网格的顶点偏移，并通过以增加的空间分辨率逐渐推断3D形状信息来使其变形以得到具有精细细节的输出网格<span class="math inline">\(M_Θ = D{(z_s)}\)</span>。</p><p>接下来，利用可微分渲染器渲染所生成的网格 <spanclass="math inline">\(M_Θ\)</span>，来生成轮廓 <spanclass="math inline">\(S_Θ\)</span>。该网络是端到端的训练，通过近似梯度的微分渲染器的监督渲染。</p><p><strong>3. Shape discriminator and Multi-view Sampling</strong></p><p>​由于草图的稀疏性质和单视图轮廓约束的唯一监督，编码器-解码器结构化生成器G不能有效地获得高质量的3D形状。必须使用额外的线索来关注细粒度和逼真的对象结构。因此引入==形状匹配与多视点采样==。</p><p>​该辨别器为CNN网络，它在训练过程中==引入来自真实的数据集的3D形状==，以迫使网格生成器G生成逼真的形状，同时在推理过程中保持生成过程的效率。具体地说，将从预测网格生成的轮廓和从手动设计的网格渲染的轮廓输入到神经网络。同时，随机采样N个相机姿态从姿态分布p中，保证生成的网格细节合理、逼真。</p><p><strong>4. Stroke EnhancementModule</strong>(新模块，但是大概率用不上)</p><figure><img src="image-20231015171503579.png" alt="image-20231015171503579" /><figcaption aria-hidden="true">image-20231015171503579</figcaption></figure><p>​由于输入草图和投影轮廓是单一颜色的，不能有效地获得深度预测结果。因此通过引入笔划增强模块（SEM）来充分利用单色信息进行特征提取。SEM由一个位置感知注意力模块组成，该模块将广泛的上下文信息编码到局部特征中以学习特征的空间相互依赖性。<span class="math display">\[s_{i j}=\frac{\exp \left(B_{i} * C_{j}\right)}{\sum_{i=1}^{W} \exp\left(B_{i} * C_{j}\right)}\]</span> 来自轮廓 $A R^{c×n×m} $ 的局部特征被送到卷积层形成两个局部特征<span class="math inline">\(B,~C \in R^{C\times W}\)</span>，其中 <spanclass="math inline">\(W~ = ~M \times N\)</span>为像素的数量，而另一个卷积层用于形成特征图 $D R^{C N M} $。C和B的转置进行矩阵乘法，然后由 <em>softmax</em> 层生成注意力图 <spanclass="math inline">\(S \in R^{W \times W}\)</span>，从而增强了利用由轮廓表示的关键结构信息的能力。注意力图用于通过原始特征和所有位置上的特征的加权和来产生输出F:<span class="math display">\[F_{j} ~ = ~ \lambda\sum_{i=1}^{W}(s_jD_j) ~ + ~ A_j\]</span> <strong>5. Loss Function</strong></p><p>​ 损失函数来自三个组件，包括有：multi-scale <em>mIoU loss</em> <spanclass="math inline">\(\mathcal{L}_{sp}\)</span>，<em>flattenloss</em>，<em>laplacian smooth loss</em> <spanclass="math inline">\(\mathcal{L}_{r}\)</span>，<em>structure-aware GANloss</em> <span class="math inline">\(\mathcal{L}_{sd}\)</span>。 <spanclass="math display">\[\mathcal{L}_{sp} ~=~ \sum_{i=1}^{N} \lambda_{si} \mathcal{L}^i_{iou} \\\mathcal{L}_{iou}(S_1, ~ S_2) ~= ~1~ - ~\frac{\left \| S_1\otimes S_2\right \|_1 }{\left \| S_1 \otimes S_2-S_1 \otimes S_2 \right \|_1 }\]</span> S1和S2是渲染的轮廓。</p><p>​ 非饱和GAN损失： <span class="math display">\[\begin{aligned}\mathcal{L}_{s d} &amp; =\mathbf{E}_{\mathbf{z}_{\mathbf{v}} \simp_{z_{v}}, \xi \sim p_{\xi}}\left[f\left(C N N_{\theta_{D}}(R(M,\xi))\right)\right] \\&amp; +\mathbf{E}_{\mathbf{z}_{\mathbf{v r}} \sim p_{z_{v r}}, \xi \simp_{\xi}}\left[f\left(-C N N_{\theta_{D}}\left(R\left(M_{r},\xi\right)\right)\right)\right] \\&amp; \text { wheref }(u)=-\log (1+\exp (-u))\end{aligned}\]</span> ​ 总损失函数Loss计算为三个分量的加权和： <spanclass="math display">\[Loss = \mathcal{L}_{sp}+\mathcal{L}_{r}+\lambda_{sd}\mathcal{L}_{sd}\]</span></p><h4 id="实验-分析">3 实验 &amp; 分析</h4><p><strong>1. 消融实验</strong></p><p>​ 对形状鉴别器(SD)与笔划增强模块进行效用实验。</p><figure><img src="image-20231015180807656.png" alt="image-20231015180807656" /><figcaption aria-hidden="true">image-20231015180807656</figcaption></figure><blockquote><p>随机视点采样与形状识别（SD）相结合，以真实的形状作为输入，允许神经网络从多个角度“看到”真实的形状，从而能够预测合理的结构信息，这些信息甚至不存在于草图中（由于视点约束，可能无法表示）。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>略读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pi-GAN_ Periodic Implicit Generative Adversarial Networks for 3D-Aware</title>
    <link href="/posts/39032/"/>
    <url>/posts/39032/</url>
    
    <content type="html"><![CDATA[<h3id="pi-gan-periodic-implicit-generative-adversarial-networks-for-3d-aware">pi-GAN:Periodic Implicit Generative Adversarial Networks for 3D-Aware</h3><h4 id="提出的方法贡献相关工作">1 提出的方法，贡献，相关工作</h4><p><strong>1. 方法</strong></p><p>​所提出的方法利用==基于<em>SIREN</em>==的神经辐射场表示来鼓励多视图一致性，从而允许从较宽的范围进行渲染相机姿势范围并提供可解释的3D 结构。<em>SIREN</em>隐式场景表示利用周期性激活函数，比<em>ReLU</em>隐式表示更能表示精细细节，并使<em>π-GAN</em>能够渲染比以前的工作更清晰的图像。</p><p>​使用映射网络通过==特征线性调制<em>FiLM</em>==来调节<em>SIREN</em>中的层。这一方法可以更广泛地应用于<em>GAN</em>之外的<em>SIREN</em>架构。其次，受2D卷积<em>GAN</em>先前成功的启发，引入了==渐进式增长策略==，以加速训练并抵消3D GAN 增加的计算复杂性。</p><p><strong>2. 贡献</strong></p><ul><li>引入基于 SIREN 的隐式 GAN 作为卷积 GAN 架构的可行替代方案。</li><li>提出了一个以 FiLM调节和渐进式增长判别器作为关键组件的映射网络，以通过我们新颖的基于 SIREN的隐式 GAN 实现高质量结果。</li><li>证明视图一致性和显式相机控制是依赖于底层神经辐射场表示和经典渲染的方法的优势。</li><li>根据 CelebA 、Cats 和 CARLA 数据集上的无监督 2D 数据进行 3D感知图像合成，取得了最先进的结果。</li></ul><h4 id="方法-模型">2 方法 &amp; 模型</h4><p><strong>1. Overview: </strong></p><p><img src="image-20231013161535382.png" alt="image-20231013161535382" style="zoom:80%;" /></p><p>​ 相比于直接从输入的<em>noise, z</em>生成2D图像，π-GAN的生成器 <spanclass="math inline">\(G_{θG} (z, \xi)\)</span> 产生一个以 z为条件的隐式辐射场。该辐射场是使用体积渲染来渲染的，以根据某个相机姿势<span class="math inline">\(\xi\)</span> 生成 2D 图像。</p><p><strong>2. SIREN-Based Implicit Radiance Field</strong></p><p>​使用隐式神经辐射场(SIREN)表示3D对象，该神经辐射场被参数化为多层感知机(MLP)，输入为空间3D坐标x 和视图方向 d；输出为密度 <span class="math inline">\(\sigma\)</span>以及视图相关颜色 <span class="math inline">\((r,g,b)=c(x,d)\)</span>。然后，利用StyleGAN的映射网络，通过<em>FiLM</em>将<em>SIREN</em>调节到早上向量z 上。而映射网络采用简单的<em>ReLU MLP</em>，输入为噪声向量 z 输出为频率<span class="math inline">\(\gamma_i\)</span> 和相移 <spanclass="math inline">\(\beta_i\)</span> ，做为FiLM SIREN的输入。</p><p>​<code>优势：</code>这种插入的映射网络相比基于串联的调节更具有表现力，提高了图像质量。</p><blockquote><p>FiLM：feature-wise linear modulation(特征线性调制)</p></blockquote><p>​ 将FiLM SIREN 骨干网络形式化表示为： <span class="math display">\[\begin{aligned}\Phi(\mathbf{x})= &amp; \phi_{n-1} \circ \phi_{n-2} \circ \ldots \circ\phi_{0}(\mathbf{x}), \\&amp; \phi_{i}\left(\mathbf{x}_{i}\right)=\sin\left(\boldsymbol{\gamma}_{i} \cdot\left(\mathbf{W}_{i}\mathbf{x}_{i}+\mathbf{b}_{i}\right)+\boldsymbol{\beta}_{i}\right),\end{aligned}\]</span> 其中，<span class="math inline">\(\phi_{i}\)</span> 为MLP的第i 层，它由一个仿射变换定义，包括权重矩阵 <spanclass="math inline">\(W_i\)</span> 和偏置 <spanclass="math inline">\(b_i\)</span> 组成，同时作用于输入 <spanclass="math inline">\(x_i\)</span>。</p><p>​ 将隐式体积密度和颜色定义为： <span class="math display">\[\begin{aligned}\sigma(\mathbf{x}) &amp; =\mathbf{W}_{\sigma}\Phi(\mathbf{x})+\mathbf{b}_{\sigma}\end{aligned}\]</span></p><p><span class="math display">\[\begin{aligned}\mathbf{c}(\mathbf{x}, \mathbf{d}) &amp; =\mathbf{W}_{c}\phi_{c}\left([\Phi(\mathbf{x}), \mathbf{d}]^{T}\right)+\mathbf{b}_{c}\end{aligned}\]</span></p><p>其中，<span class="math inline">\(\mathbf{W}_{\sigma/c}\)</span> 和<span class="math inline">\(b_{\sigma/c}\)</span>为额外的权重和偏差参数。</p><p>==<strong>NeRF的MLP网络：</strong>==</p><p><img src="image-20231014160022990.png" style="zoom:80%;" /></p><p>​原始的NeRF它的MLP网络为8层，都是使用的ReLU激活函数；然后一个额外特征层输出<span class="math inline">\(\sigma\)</span> ，一个特征层输出 RGB信息。而 pi-gan 提出的网络通过<em>FiLM</em> 调制，在每个层的后面把<em>SIREN</em> 加进去，得到一个新的 MLP 网络，从而提高图像质量。</p><blockquote><p>SIREN网络是指一个用于表示辐射场的神经网络。SIREN(SinusoidalRepresentationNetworks)，它是一种特殊类型的神经网络结构。这种网络使用周期性的正弦激活函数，通常被用于表示连续的函数或场景中的信号。</p></blockquote><p><strong>3. Discriminator</strong></p><p>​ 采用参数为 <span class="math inline">\(\theta_{D}\)</span>逐渐增长的卷积判别器 <span class="math inline">\(D_{\theta{D}}\)</span>，开始训练时，采用低分率和高批量大小进行训练，生成器生成粗糙的形状。随着训练的进行，提高图像分辨率并向鉴别器添加新层以处理更高分辨率并区分精细细节。</p><blockquote><p>由于计算复杂性随着图像大小呈二次方增长，因此从低分辨率开始的渐进式增长允许在训练开始时使用更大的批量大小。大批量有助于稳定训练，同时还可以提高每次迭代的图像吞吐量。渐进式增长及其支持的更大批量大小有助于确保生成图像的质量和多样性。</p><p>PS：神经渲染采用与 NeRF 相同的渲染公式。</p></blockquote><h4 id="实验-分析">3 实验 &amp; 分析</h4><p><strong>1. 训练</strong></p><p>​ 在训练时，从分布 <span class="math inline">\(p_{\xi}\)</span>中随机采样相机姿势 <span class="math inline">\(\xi\)</span>。每个数据集的姿势分布都是先验已知的，对于 CelebA 和 Cats近似为高斯分布，对于 CARLA近似为均匀分布。==将相机位置限制在单位球体的表面，并将相机指向原点==。在训练时，沿球体的俯仰和偏航是从根据数据集调整的分布中采样的。真实图像I 是从具有分布 <span class="math inline">\(p_{I}\)</span>的训练集中采样的。使用带有 R1 正则化的非饱和 GAN 损失函数： <spanclass="math display">\[\mathcal{L}(\theta , \phi ) = E_{z \sim p_{z, ~ \xi \simp_{\xi}}}[f(D_{\theta G}G_{\theta G}(z, \xi)]~ + ~ E_{I\sim p_{D}}[f(-D_{\theta D}(I)) + \lambda |\bigtriangledownD_{\theta  D}(I)|^2], \\where \quad f(u) = -log(1+exp(-u))\]</span> 生成器尝试最小化等式，而判别器同时尝试最大化等式。使用 Adam优化器，β1 = 0，β2 = 0.9。</p><p><strong>2. 结果对比</strong></p><p><code>Baseline:</code> HoloGAN, Generative Radiance Fields(GRAF)</p><p><img src="image-20231015082031213.png" alt="image-20231015082031213" style="zoom:80%;" /></p><p><code>评价指标:</code> Frechet Inception Distance(FID), KernelIncerption Distance(KID), Inception Score</p><p><strong>3. 消融实验</strong></p><p>​对==正弦激活==和==映射网络调节==进行消融，来体现它们在网络中的作用。将==正弦激活==的辐射场与==ReLU激活==和位置编码的辐射场进行比较。将通过==映射网络和FiLM条件调节==的辐射场与通过==级联调节==的辐射场进行比较。</p><figure><img src="/image-20231015102018486.png" alt="image-20231015102018486" /><figcaption aria-hidden="true">image-20231015102018486</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>精度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion</title>
    <link href="/posts/7366/"/>
    <url>/posts/7366/</url>
    
    <content type="html"><![CDATA[<h3id="shape-pose-and-appearance-from-a-single-image-via-bootstrapped-radiance-field-inversion">Shape,Pose, and Appearance from a Single Image via Bootstrapped Radiance FieldInversion</h3><h4 id="一提出的方法与贡献">一、提出的方法与贡献</h4><p><strong>1.方法：</strong></p><p>​作者提出了一种新的方法，将无条件生成模型与混合反演范式相结合，从单个图像中恢复三维信息。具体来说，他们使用神经辐射场（NeRF）来表示三维场景，并使用编码器产生潜在表示和姿态的第一个猜测。然后，他们通过优化来细化这些初始估计，以获得更准确的重建。</p><p><strong>2.贡献：</strong></p><ul><li>引入了一个基于NeRF的端到端单视图三维重建管道。在这种情况下，我们成功地展示了CMR基准下自然图像的<spanclass="math inline">\(360^◦\)</span>对象重建。</li><li>提出了一种用于NeRF的混合反演方案，以加快预训练的3D感知生成器的反转。</li><li>受姿态估计文献的启发，我们提出了一种基于PnP的姿态估计器，它利用我们的框架并且不需要额外的数据假设。</li></ul><h4 id="二模型与模块">二、模型与模块</h4><p><strong>1. Unconditional generatorpre-training（无条件生成器预训练框架）</strong></p><figure><img src="image-20230904201413230.png" alt="image-20230904201413230" /><figcaption aria-hidden="true">image-20230904201413230</figcaption></figure><p><code>思想：</code>主要思想来自EG3D的主干网络，三平面编码。<code>该部分被框架使用基于NeRF的生成器G与2D图像鉴别器相结合。</code></p><p><code>模块：</code>StyleGAN2，SDF representation，Attention-basedcolor mapping，Path Length Regularization revisited。</p><blockquote><p>StyleGAN2：生成模型，SDF representation：3D表示，</p><p><strong>Attention-based color mapping：提高颜色泛化性, Path LengthRegularizationrevisited：使三平面解码器不正则化，提高学习率。</strong></p></blockquote><p><strong>2. Bootstrapping and poseestimation（自举和姿态估计）</strong></p><figure><img src="image-20230904201324234.png" alt="image-20230904201324234" /><figcaption aria-hidden="true">image-20230904201324234</figcaption></figure><p><code>思想：</code>主要思想来自NOCS，<code>改进：是使用从无条件生成器生成的数据来训练编码器而不是手工数据。</code></p><p><code>实现：</code>1）冻结G并训练图像编码器E，联合估计对象的姿势及其潜在代码（自举）的初始猜测。2）对于姿态估计，我们采用了一种原则性的方法来预测屏幕空间中的规范映射通过透视n点(PnP)算法。<code>输入真实图像，将预测的规范映射转换为点云，并运行PnP求解器来恢复所有姿态参数(视图矩阵和焦距)。</code></p><p><code>模块：</code>SegFormer</p><blockquote><p><strong>训练SegFormer网络来从RGB图像中预测规范图和latent codew</strong></p></blockquote><p><strong>SegFormer分割网络图：</strong></p><figure><img src="image-20230904201508184.png" alt="image-20230904201508184" /><figcaption aria-hidden="true">image-20230904201508184</figcaption></figure><p><strong>3. Reconstruction via hybrid GANinversion（通过混合GAN反演重建）</strong></p><figure><img src="image-20230904202404525.png" alt="image-20230904202404525" /><figcaption aria-hidden="true">image-20230904202404525</figcaption></figure><p>通过基于梯度的优化(混合反演)改进了几个步骤的姿态和潜在代码。损失函数：VGG</p><p><code>模块：</code>adaptive discriminator augmentation(ADA)</p><blockquote><p>有助于减少梯度的方差，使我们能够进一步提高学习率。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NeRF</tag>
      
      <tag>精读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Efficient Geometry-aware 3D Generative Adversarial Networks</title>
    <link href="/posts/52856/"/>
    <url>/posts/52856/</url>
    
    <content type="html"><![CDATA[<h3id="efficient-geometry-aware-3d-generative-adversarial-networks">EfficientGeometry-aware 3D Generative Adversarial Networks</h3><h5 id="一提出的方法贡献相关工作">一、提出的方法、贡献、相关工作</h5><p><strong>1.方法：</strong></p><p>​设计了一种混合显式-隐式3D感知网络，该网络使用内存高效的<code>三平面表示显式地</code>存储由轻量级<code>隐式特征解码器聚合</code>的轴对齐平面上的特征，以实现高效的体绘制，提高了3D基础渲染的计算效率。使用了一些偏离3D基础渲染的图像空间近似，同时引入了一种双重判别策略，该策略保持神经渲染和最终输出之间的一致性，以规范其视图不一致的趋势。</p><blockquote><p>显式表示可以进行快速评估，但是需要很大的内存，使得这种方式难以扩展到高分辨率或复杂场景。隐式表示虽然在内存效率和场景复杂性方面有优势，但是这种方法使用大型的全连接网络进行评估，使得训练速度缓慢。因此，显式和隐式表示提供了互补的好处。</p></blockquote><figure><img src="1.png" alt="3-plane" /><figcaption aria-hidden="true">3-plane</figcaption></figure><p><strong>2.贡献：</strong></p><ul><li>引入了一个基于三平面的3DGAN框架，该框架既高效又富有表现力，以实现高分辨率几何感知图像合成。</li><li>开发了一种3DGAN训练策略，通过双重判别和生成器姿势条件促进多视图一致性，同时忠实地建模现实世界数据集中存在的姿势相关属性分布（例如表达式）。</li><li>展示了在FFHQ和AFHQCats数据集上无条件3D感知图像合成的最新结果，以及完全从2D野外图像中学习的高质量3D几何图形。</li></ul><p><strong>3.相关工作：</strong></p><p>​ 1）Neural scene representation and rendering(神经场景表示和渲染)</p><p>​设计了一种新的混合显式隐式3D感知网络，该网络使用内存高效的三平面表示显式地存储由轻量级隐式特征解码器聚合的轴对齐平面上的特征，以实现高效的体绘制</p><p>​ 2）Generative 3D-aware image synthesis(生成式3D感知图像合成)</p><p>​ 具有基于3D的先验偏差的高效3DGAN架构对于成功生成高分辨率视图一致图像和高质量3D形状至关重要。所以作者采用了以下方法：</p><p>​ a. 直接利用基于2D CNN特征生成器，即<code>StyleGAN2</code>。</p><p>​ b.三平面表示使得该论文的方法能利用神经体渲染作为先验偏差，在计算上比完全隐式3D网络更有效。</p><p>​ c. 在神经渲染后采用基于2DCNN的向上采样，同时引入双重辨别器去避免上采样层带来的视图不一致。</p><h5 id="二模型与模块">二、模型与模块</h5><p><strong>1. Tri-plane hybrid 3Drepresentation(Tri-plane混合3D表示)</strong></p><p><code>思想：</code>hybrid explicit-implicit tri-planerepresentation(混合显式-隐式三平面表示)。</p><p><code>实现：</code>沿着三个轴对齐的正交特征平面对齐显式特征，每个特征平面的分辨率均为N×N×C，N为空间维度，C为通道数。通过将3D位置投影到三个特征平面中来查询任何3D位置点<code>x</code>，通过双线性插值检索相应的特征向量<spanclass="math inline">\((F_{xy} ~,~ F_{xz}~ , ~F_{yz})\)</span>，然后通过求和来汇总这三个特征向量。最后将这个汇总的特征F输入到一个小型解码器(MLP)来解码为颜色和密度。</p><p><code>模块：</code>小型MLP网络。</p><p><strong>2. 3D GAN framework(3D GAN框架)</strong></p><p><code>思想：</code>训练一个3DGAN，用于从2D照片中进行集合感知图像合成，而无需任何显式3D或者多视图监督。同时使用现成的姿态检测器，将每个训练图像与一组相机内参和外参相关联(<code>Deep3DFaceReconstruction</code>)。</p><p><code>实现/Overview:</code></p><figure><img src="2.png" alt="overview" /><figcaption aria-hidden="true">overview</figcaption></figure><blockquote><p>​ a. 一个基于姿态条件的StyleGAN2特征生成器和映射网络。</p><p>​ b. 一个具有轻量级特征解码器的三平面3D表示。</p><p>​ c. 一个神经体素渲染器。</p><p>​ d. 一个超分辨率模块。</p><p>​ e. 一个基于姿态条件的具有双重辨别的StyleGAN2辨别器。</p></blockquote><p>​这个架构巧妙地将特征生成和神经渲染解耦，使得可以利用强大的StyleGAN2生成器进行3D场景的泛化。此外，轻量级的三平面3D表示既能够表达丰富的信息，又能够在实时中实现高质量的3D感知视图合成。同时，采用两阶段训练策略加速训练速度。第一个阶段：使用减少<spanclass="math inline">\((64^2)\)</span>神经渲染分辨率进行训练；第二个阶段：在完全<spanclass="math inline">\((128^2)\)</span>神经渲染分辨率上的短期微调。</p><p><strong>3. CNN generator backbone andrendering(CNN生成器主干和渲染)</strong></p><p><code>思想：</code>由<code>StyleGAN2 CNN生成器生成三平面表示的特征</code>。随机潜在代码和相机参数首先由映射网络处理以产生中间潜在代码，然后调制单独合成网络的卷积核。</p><p><code>实现：</code>改变StyleGAN2主干网络的输出形状，不是生成三通道RGB图像，而是生成一个256×256×96的特征图像。从三平面采样特征，并融汇从三个平面采样的特征，输入到轻量级解码器(MLP，64个神经元的单个隐藏层，激活函数：softplus)。</p><p><code>模块：</code>StyleGAN2、MLP</p><p><strong>4. Super resolution(超分辨率)</strong></p><p><code>思想：</code>使用中等分辨率<spanclass="math inline">\((128^2)\)</span>进行体渲染，并依靠图像空间卷积上采样神经渲染到<spanclass="math inline">\((256^2 ~ or ~ 512^2)\)</span>图像大小。</p><p><code>实现：</code>由StyleGAN2调制卷积层的两个块组成。1）上采样，将128×128×3分辨率提高到512×512×3的分辨率。2）调整32通道特征图到最终的RGB图像。</p><p><strong>5. Dual discrimination(双重辨别器)</strong></p><p><code>思想：</code>使用StyleGAN2的辨别器，并进行了两次修改。</p><p><code>实现：</code>1）将特征图解释为低分辨率RGB图像。双重辨别器确保低分辨率RGB图像与高分辨率图像的一致性，通过双线性上采样成同样512×512×3图像并与调整后的<spanclass="math inline">\((I^+_{RGB})\)</span>进行连接变成6通道图像。2）将输入的3通道RGB图像与其适当模糊后的图像进行连接，变成6通道图像作为辨别器的输入。</p><p><code>模块：</code>StyleGAN2-ADA策略</p><blockquote><p>​StyleGAN2-ADA策略：将渲染相机的内外矩阵(P)传递给鉴别器作为条件标签。这种调节引入了额外的信息，指导生成器学习正确的3D先验。</p></blockquote><p><strong>6. Modeling pose-correlatedattributes(建模姿态相关属性)</strong></p><p><code>思想：</code>引入了<code>generator pose conditioning(生成器姿势条件)</code>作为建模和解耦训练图像中观察到的姿势与其他属性之间的相关性的一种手段。</p><p><code>实现：</code>按照StyleGAN2-ADA条件生成策略，提出一个主干映射网络，不仅提供一个潜在代码z，同时提供相机参数P作为输入。</p><h5 id="三其他细节">三、其他细节</h5><p><strong>1. Pose Estimators(姿态估计)</strong></p><p>​用水平翻转的方法来扩充数据集，并使用现成的姿态估计来提取近似的相机外部参数。</p><blockquote><p>现成的姿态估计方法：</p><p>1）https://github.com/Microsoft/Deep3DFaceReconstruction，用来生成脸的数据集的姿态(FFHQ)。</p><p>2）https://github.com/kairess/cat_hipsterizer，用来生成猫的数据集的姿态(AFHQv2Cats)。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>精读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pix2NeRF_ Unsupervised Conditional π-GAN for Single Image to Neural Radiance Fields Translation</title>
    <link href="/posts/9076/"/>
    <url>/posts/9076/</url>
    
    <content type="html"><![CDATA[<h3id="pix2nerf-unsupervised-conditional-π-gan-for-single-image-to-neural-radiance-fields-translation">Pix2NeRF:Unsupervised Conditional π-GAN for Single Image to Neural RadianceFields Translation</h3><h4 id="提出的方法-贡献相关工作">1 提出的方法， 贡献，相关工作</h4><p><strong>1. 方法</strong></p><p>基于π-GAN模型，用于无条件3D感知图像合成的生成模型，它讲随机latentcode映射到一类对象的辐射场。作者同时优化两个目标:（1）π-GAN目标，以利用其高保真度的3D感知生成能力。（2）一个经过精心设计的重建目标，包括一个与π-GAN生成器耦合的编码器，形成一个自动编码器。</p><p>引入了将给定图像映射到latentspace的编码器，并对其做了些优化：（1）训练π-GAN和添加的编码器将生成的图像映射回latentspace。（2）将编码器与π-GAN的生成器结合形成带条件的GAN模型，同时使用对抗和重建损失对其进行训练。</p><p><strong>2. 贡献</strong></p><p>（1）提出Pix2NeRF，第一个无监督的单视图NeRF模型，可以从图像中学习场景辐射场，并且不需要3D信息，多视图或者姿态监督。</p><p>（2）提出基于NeRF的GAN反演。</p><p><strong>3. 相关工作</strong></p><p>作者的工作可以分类为特定类别的3D感知神经新视图合成方法，该方法基于NeRF和π-GAN。</p><ul><li>神经辐射场</li><li>基于NeRF的GAN</li><li>少样本NeRF</li></ul><h4 id="模型与模块">2 模型与模块</h4><p><strong>1. 总体架构</strong></p><p>​Pix2NeRF由三个神经网络组成，一个生成器G、一个辨别器D，共同组成生成对抗网络，一个编码器E，与生成器G共同组成一个自动编码器。</p><p>​ 生成器约束：output view pose d and latent code z。</p><p>​ G：生成器，D：辨别器，E：编码器，I：RGB image，z：latentcode，d：pose，p：prior distribution l：logit predict distribution。</p><figure><img src="1.png" alt="1" /><figcaption aria-hidden="true">1</figcaption></figure><p><strong>1.1 Overview</strong></p><p>​论文中的方法将编码器和生成器输入映射的图像的潜在表示解耦为内容<code>z</code>和姿态<code>d</code>，并对这两个部分进行单独处理。</p><p><img src="2.png" alt="1" style="zoom:80%;" /></p><p>​Pix2NeRF从一张输入的图像中解耦姿态和内容，并且生成一个内容的辐射场，该辐射场包括（1）解耦姿态下的输入一致性，（2）来自<spanclass="math inline">\(~p_d~\)</span>不同姿态下的一致性雨逼真性。为了完成这些目标，设计了几个训练目标：</p><ul><li>Generator（生成器）</li><li>Discriminator（辨别器）</li><li>GAN inversion（GAN反演）</li><li>Reconstruction（重建）</li><li>Conditional adversarial training（条件对抗训练）</li></ul><p><strong>2. GAN generator objective（GAN生成器）</strong></p><p>​ 对latent code <span class="math inline">\(z_{rand} \simp_{z}\)</span> 和随机姿态<span class="math inline">\(d_{rand} \simp_d\)</span> 成对采样，然后通过生成器去生成假的生成图像：<spanclass="math inline">\(I_{gen} ~ = ~G(z_{rand},~d_{rand})\)</span>，最后输入到冻结的辨别器中：<spanclass="math inline">\(l_{gen}, ~ d_{gen} ~ = ~D^*(I_{gen})\)</span>。（左上）</p><p>​ 使用 <code>MSE</code> 作为生成的姿态 <spanclass="math inline">\(d_{gen}\)</span> 和随机姿态输入 <spanclass="math inline">\(d_{rand}\)</span>之间的损失函数，同时生成器G的损失函数如下： <spanclass="math display">\[\begin{aligned}\mathcal{L}_{\mathrm{GAN}}(G)=\underset{\substack{z_{\text {rand }} \simp_{\mathrm{z}} \\d_{\text {rand }} \simp_{d}}}{\mathbb{E}}  [\text{softplus}\left(-l_{\text {gen}}\right)+\left.\lambda_{\text {pos }}\left\|d_{\text {rand }}-d_{\text{gen}}\right\|_{2}^{2}\right]\end{aligned}\]</span> 其中 $ _{pos}$ 为微调权重因子。</p><p><strong>3. GAN discriminator objective（GAN辨别器）</strong></p><p>​ 对latent code <span class="math inline">\(z_{rand} \simp_{z}\)</span> 和随机姿态<span class="math inline">\(d_{rand} \simp_d\)</span> 成对采样，然后通过冻结的生成器去生成假的生成图像：<spanclass="math inline">\(I_{gen} ~ = ~G^*(z_{rand},~d_{rand})\)</span>，然后辨别器D通过 <spanclass="math inline">\(G^*\)</span> 生成的的图像和真实图像 <spanclass="math inline">\(I_{real} \sim p_{real}\)</span>来进行训练。（左下） <span class="math display">\[l_{real},~ d_{real} ~=~D(I_{real}), \\l_{gen}, ~ d_{gen} ~=~ D(I_{gen}).\]</span> ​ 考虑已知姿态的 <code>MSE</code> 监督而修改的鉴别器的损失函数<span class="math inline">\(\mathcal{L}_{GAN}(D)\)</span> 可以表示为：<span class="math display">\[\begin{aligned}\mathcal{L}_{\mathrm{GAN}}(D)~ = ~\underset{I_{\text {real}} \simp_{\text {real}}}{\mathbb{E}}{\left[\operatorname{softplus}\left(-l_{\text {real}}\right)\right]~ +~} \\\underset{\substack{z_{\text {rand }} \sim p_{\mathrm{z}} \\d_{\text {rand}} \sim p_{d}}}{\mathbb{E}}{\left[\operatorname{softplus}\left(l_{\text {gen}}\right)~ + ~\right.}\left.\lambda_{\text {pos}}\left\|d_{\text {rand}}-d_{\text{gen}}\right\|_{2}^{2}\right]\end{aligned}\]</span> 其中 $ _{pos}$ 为微调权重因子。</p><p><strong>4. GAN inversion objective（GAN反演）</strong></p><p>​ 联合优化编码器 E 和辨别器 D，并冻结生成器G。目的是确保采样的内容和姿态与编码器从生成的图像中提取的内容和姿态之间的一致性。（左下）<span class="math display">\[z_{pred}, ~ d_{pred} ~ = ~E(I_{gen})\]</span> GAN反演使用 <code>MSE</code> 损失函数： <spanclass="math display">\[\begin{array}{r}\mathcal{L}_{\mathrm{GAN}^{-1}}(E)=\underset{\substack{z_{\text {rand }}\sim p_{\mathrm{z}} \\d_{\text {rand }} \sim p_{d}}}{\mathbb{E}}\left[\left\|z_{\text {pred}}-z_{\text {rand }}\right\|_{2}^{2} ~+ ~\right.\left.\left\|d_{\text {pred }}-d_{\text {rand }}\right\|_{2}^{2}\right]\end{array}\]</span> <strong>5. Reconstruction objective（重建）</strong></p><p>​ 通过使用编码器 E 提取其 latent code和姿势预测来在真实图像上调节生成器G，然后使用预测的姿势渲染其视图，<code>目的为促进图像空间中结构的的一致性，并使得图像更加清晰</code>。（右上）<span class="math display">\[z_{pred}, ~ d_{pred} ~ = ~ E(I_{real}) \\I_{recon} ~ = ~ G(z_{pred}, ~ d_{pred})\]</span> 重建损失函数，基于 <code>MSE</code> 改进： <spanclass="math display">\[\begin{array}{r}\mathcal{L}_{\text {recon }}(G, E)=\underset{\begin{array}{c}{I_{real} } \sim { p_{real} }\end{array}}{\mathbb{E}}\left[\left\|I_{\text {recon }}-I_{\text {real}}\right\|_{2}^{2} ~ + ~\right. \\\lambda_{\text {ssim }} \mathcal{L}_{\text {ssim }}\left(I_{\text {recon}}, I_{\text {real }}\right) ~ + \\\left.\lambda_{\text {vgg }} \mathcal{L}_{\text {vgg }}\left(I_{\text{recon }}, I_{\text {real }}\right)\right]\end{array}\]</span> 其中 <span class="math inline">\(\mathcal{L}_{ssim}\)</span>为SSIM损失，<span class="math inline">\(\lambda_{ssim}\)</span>为SSIM损失的权重因子；<spanclass="math inline">\(\mathcal{L}_{vgg}\)</span> 为 VGG 感知损失，<spanclass="math inline">\(\lambda_{vgg}\)</span> 为其权重因子。</p><p><strong>6. Conditional adversarialobjective（条件对抗网络）</strong></p><p>​重建目标旨在提高由编码器E提取的单个视图的良好重建质量。这可能会导致网络组合趋向于预测微不重要的姿势，或者对从<span class="math inline">\(p_d\)</span>提取的其他姿势的重建进行不切实际的预测。为了缓解这一问题，当生成器在随机姿势下渲染出图像<span class="math inline">\(I_{real}\)</span> 时，进一步应用对抗目标。<span class="math display">\[l_{cond}, ~ d_{cond} ~=~D^*(G(z_{pred}, ~d_{rand}))\]</span> 损失函数为： <span class="math display">\[\mathcal{L}_{cond}(G, ~E) ~=~\underset{\substack{\substack{I_{real}\sim p_{real}} \\d_{rand} \sim p_d}}{\mathbb{E}}\left[\operatorname{softplus}(-l_{cond}) \right]\]</span> <strong>7. Encoder warm-up（编码器预热）</strong></p><p>​重建损失可能很容易占主导地位，导致模型过度拟合于输入视图，同时失去了表示3D的能力。因此，作者引入了一种简单的“预热”策略来应对这个问题。在训练协议的前半部分迭代中，冻结编码器，同时优化重建和条件对抗损失，并且仅优化生成器用于这两个目标。这作为生成器的预热，大致学习编码器输出与编码图像之间的对应关系。然后解冻编码器，使其能够进一步提炼其学习到的表示。在预热阶段之后，编码器和生成器直接形成了一个经过预训练的自动编码器，能够生成接近真实3D表示的结果，避免了繁琐的早期重建目标，这在与GAN目标相平衡非常困难的情况下尤为重要。作者通过消融研究展示了这一策略的必要性，并与仅为重建损失分配较小权重的情况进行了比较。</p><p><strong>8. Training and Inference（训练与推测）</strong></p><p>​ 判别器和 GAN 反演目标在每次迭代时都会进行优化；GAN生成器目标在偶次迭代时进行优化；重建和条件对抗目标在奇数迭代期间通过加权因子<span class="math inline">\(λrecon\)</span> 联合优化： <spanclass="math display">\[\mathcal{L}_{odd} ~=~ \mathcal{L}_{cond} ~ + ~\lambda_{recon}\mathcal{L}_{recon}\]</span> ​ 在推理阶段，Pix2NeRF 只需要一个输入图像，可以将其输入编码器E，然后输入生成器G，再加上任意选择的姿势以进行新颖的视图合成。同时，可以从先验分布 <spanclass="math inline">\(p_z\)</span> 中对其进行采样，而不是从编码器中获取latent code z，以使模型像 π-GAN 一样合成新颖的样本。</p><h4 id="实验">3 实验</h4><p><strong>1.数据集</strong></p><p>CelebA：200k张==人脸照片==，使用==aligned==的版本，并且采用中心裁剪，裁剪出大致脸部面积，使用8k张照片作为测试集。</p><p>CARLA：包含 16 个==汽车模型==的 10k 图像，使用 Carla驾驶模拟器以随机纹理渲染。</p><p>ShapeNet-SRN：该数据集包含来自 ShapeNet 的 50个渲染视图，其中每个实例都有阿基米德螺旋相机姿势。由于 ShapeNet-SRN数据集的验证和测试集中不包括下半球，因此作者过滤训练集以仅包含上半球。作者使用==椅子==分割来与之前的多视图方法进行比较。</p><p><strong>2.技术细节</strong></p><p><code>baseline：</code>==π-GAN（Pytorch）==,重用其生成器和鉴别器架构。</p><p><code>参数：</code>选择 latent code 先验分布 <spanclass="math inline">\(p_z\)</span> 作为 [-1, 1]上的多元均匀分布。使用鉴别器架构作为编码器主干，并且在latent code头部的末尾添加==tanh==，所有的模型使用Adam优化器进行300k迭代。CelebA模型在==resolution=64×64，batchsize=48==，每条射线采样24个点的参数下进行训练，其辨别器、生成器、编码器的学习率分别为==2e-4,6e-5,2e-4==。对于其他模型在==resolution=32×32==，每条射线采样96个点的参数下进行训练，学习率分别为==4e-5,4e-4,4e-4==.</p><p><strong>3.结果对比</strong></p><p><img src="3.png" alt="3" style="zoom:80%;" /></p><p><strong>4.消融实验</strong></p><p>通过逐个去除关键组件并在完整模型相同的设置下训练模型，来验证设计选择。</p><p>主要对比的模型组件有：==Naive GAN inversion, Auto-encoder, No GANinversion, No conditional adversarial objective, Warm-up==</p><p><code>Naive GAN inversion:</code>在朴素的GAN反演中，使用一个预先训练好的GAN，冻结其权重，并训练一个编码器将图像映射到它们对应的latent code。结果表明，编码器可以学习从图像到 latent code的近似映射。</p><p><code>Auto-encoder:</code>利用 π-GAN的架构作为自动编码器，并将==latentspace==从pipeline中删除，只训练重建和条件对抗模型。得到的结果虽然又不错的质量，但是明显能观察到3D不一致现象。</p><p><code>No GAN inversion:</code>将==GANinversion==从pipeline中删除之后，视觉结果变得模糊。这一步可能是 π-GAN训练和重建之间的联系，影响整体性能。</p><p><code>No conditional adversarial objective:</code>停用条件对抗损失并重新训练，导致渲染变得不完整，有明显的伪影，并且一致性降低。</p><p><code>Warm-up:</code>分别训练三个模型，==没有warm-up，没有unfreezing编码器（始终预热），为重建分配较低的权重而不是预热==。没有warm-up策略，导致过拟合输入视图，并且无法在新颖姿态中产生有意义的内容；没有解冻编码器，则蒸馏相对弱，导致细节很少；使用较低的重建权重而不是预热，使新试图合成的模式崩溃。</p><h4 id="其他">4 其他</h4><ol type="1"><li>利用 2D GAN前馈反转等更成熟的编码器架构，例如Pixel2style，可能会显着提高 Pix2NeRF的性能。</li></ol>]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NeRF</tag>
      
      <tag>精度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>每周总结(23.09.18-23.09.24)</title>
    <link href="/posts/51013/"/>
    <url>/posts/51013/</url>
    
    <content type="html"><![CDATA[<div align='center'><H3>Weekly report</div><p><strong>Date: 23.09.18-23.09.24</strong></p><h3 id="paper">Paper</h3><p><strong>Title:</strong><code>Pix2NeRF: Unsupervised Conditional π-GAN for Single Image to Neural Radiance Fields Translation</code></p><h4 id="method-contribution-related-work">1 Method, Contribution,Related Work</h4><p><strong>1. Method</strong></p><p>​ Based on the π-GAN model, it is a generative model for unconditional3D perceptual image synthesis, which speaks of random latent codemapping to the radiation field of a class of objects. The authorsoptimize two goals at the same time: (1) π-GAN targets to take advantageof their high-fidelity 3D perception generation capabilities. (2) Awell-designed reconstruction target consisting of an encoder coupled toa π-GAN generator to form an autoencoder.</p><p>An encoder that maps a given image to a latent space is introducedand optimized: (1) The π-GAN is trained and the added encoder maps thegenerated image back to latent space. (2) Combine the encoder with agenerator of π-GAN to form a conditional GAN model, and train it usingadversarial and reconstruction losses.</p><p><strong>2. Contribution</strong></p><ol type="1"><li><p>The Pix2NeRF, the first unsupervised single-view NeRF model, canlearn the scene radiation field from the image, and does not require 3Dinformation, multi-view or attitude supervision.</p></li><li><p>A GAN inversion based on NeRF is proposed.</p></li></ol><p><strong>3. Related Work</strong></p><p>​ The author's work can be categorized into specific types of 3Dperception neural new view synthesis methods, which are based on NeRFand π-GAN.</p><ul><li>Neural Radiance Fields</li><li>NeRF-based GAN</li><li>Few-shot NeRF</li></ul><h4 id="model-and-modules">2 Model and Modules</h4><p><strong>1. Overall Architecture</strong></p><p>​ Pix2NeRF consists of three neural networks: a generator G, adiscriminator D, which together form a Generative Adversarial Network(GAN), and an encoder E, which works in conjunction with the generator Gto create an autoencoder.</p><p>​ Constraints on the generator: It generates output for view pose (d)and latent code (z).</p><p>​ G: Generator, D: Discriminator, E: Encoder, I: RGB image, z: latentcode, d: pose, p: prior distribution, l: logit predict.</p><figure><img src="1.png" alt="arc" /><figcaption aria-hidden="true">arc</figcaption></figure><p><strong>1.1 Overview</strong></p><p>​ The method in the paper decouples the latent representation of theinput images for the encoder and generator into content <code>z</code>and pose <code>d</code>, and processes these two parts separately.</p><p><img src="2.png?80*80" alt="overview" /> Pix2NeRF decouples pose andcontent from a single input image, generating a content radiance fieldthat includes (1) pose-consistency under decoupled poses and (2) realismconsistency across different poses from <spanclass="math display">\[p_d\]</span>. To achieve these objectives,several training objectives were designed:</p><ul><li>Generator（生成器）</li><li>Discriminator（辨别器）</li><li>GAN inversion（GAN反演）</li><li>Reconstruction（重建）</li><li>Conditional adversarial training（条件对抗训练）</li></ul><p><strong>2. GAN generator objective（GAN生成器）</strong></p><p>​ Sampling pairs of latent code <span class="math inline">\(z_{rand}\sim p_{z}\)</span> and random poses <spanclass="math inline">\(d_{rand} \sim p_d\)</span>, and then generatingfake images using the generator: <span class="math inline">\(I_{gen} ~ =~ G(z_{rand},~d_{rand})\)</span>, finally inputting them into the frozendiscriminator: <span class="math inline">\(l_{gen}, ~ d_{gen} ~ = ~D^*(I_{gen})\)</span> (top-left).</p><p>Using <code>MSE</code> as the loss function between the generatedpose <span class="math inline">\(d_{gen}\)</span> and the random poseinput <span class="math inline">\(d_{rand}\)</span>, the loss functionfor the generator G is as follows: <span class="math display">\[\begin{aligned}\mathcal{L}_{\mathrm{GAN}}(G)=\underset{\substack{z_{\text {rand }} \simp_{\mathrm{z}} \\d_{\text {rand }} \simp_{d}}}{\mathbb{E}}  [\text{softplus}\left(-l_{\text {gen}}\right)+\left.\lambda_{\text {pos }}\left\|d_{\text {rand }}-d_{\text{gen}}\right\|_{2}^{2}\right]\end{aligned}\]</span> where $ _{pos}$ is the fine-tuning weight factor.</p><p><strong>3. GAN discriminator objective（GAN辨别器）</strong></p><p>Sampling pairs of latent code <span class="math inline">\(z_{rand}\sim p_{z}\)</span> and random poses <spanclass="math inline">\(d_{rand} \sim p_d\)</span>, and then generatingfake images using the frozen generator: <spanclass="math inline">\(I_{gen} ~ = ~ G^*(z_{rand},~d_{rand})\)</span>,and training the discriminator D using images generated by <spanclass="math inline">\(G^*\)</span> and real images <spanclass="math inline">\(I_{real} \sim p_{real}\)</span> (bottom-left).<span class="math display">\[l_{real},~ d_{real} ~=~D(I_{real}), \\l_{gen}, ~ d_{gen} ~=~ D(I_{gen}).\]</span> The modified discriminator's GAN loss function <spanclass="math inline">\(\mathcal{L}_{GAN}(D)\)</span>, considering theknown pose <code>MSE</code> supervision, can be expressed as: <spanclass="math display">\[\begin{aligned}\mathcal{L}_{\mathrm{GAN}}(D)~ = ~\underset{I_{\text {real}} \simp_{\text {real}}}{\mathbb{E}}{\left[\operatorname{softplus}\left(-l_{\text {real}}\right)\right]~ +~} \\\underset{\substack{z_{\text {rand }} \sim p_{\mathrm{z}} \\d_{\text {rand}} \sim p_{d}}}{\mathbb{E}}{\left[\operatorname{softplus}\left(l_{\text {gen}}\right)~ + ~\right.}\left.\lambda_{\text {pos}}\left\|d_{\text {rand}}-d_{\text{gen}}\right\|_{2}^{2}\right]\end{aligned}\]</span> Where $ _{pos}$ is the fine-tuning weight factor.</p><p><strong>4. GAN inversion objective（GAN反演）</strong></p><p>​ Jointly optimizing the encoder E and discriminator D while freezingthe generator G, the goal is to ensure consistency between the sampledcontent and pose and the content and pose extracted by the encoder fromthe generated images (bottom-left). <span class="math display">\[z_{pred}, ~ d_{pred} ~ = ~E(I_{gen})\]</span> GAN inversion is performed using the <code>MSE</code> lossfunction: <span class="math display">\[\begin{array}{r}\mathcal{L}_{\mathrm{GAN}^{-1}}(E)=\underset{\substack{z_{\text {rand }}\sim p_{\mathrm{z}} \\d_{\text {rand }} \sim p_{d}}}{\mathbb{E}}\left[\left\|z_{\text {pred}}-z_{\text {rand }}\right\|_{2}^{2} ~+ ~\right.\left.\left\|d_{\text {pred }}-d_{\text {rand }}\right\|_{2}^{2}\right]\end{array}\]</span> <strong>5. Reconstruction objective（重建）</strong></p><p>​ By using the encoder E to extract its latent code and posepredictions, adjusting the generator G on real images, and renderingtheir views using the predicted poses, the goal is to promote structuralconsistency in the image space and make the images clearer(top-right).</p><p><span class="math display">\[z_{pred}, ~ d_{pred} ~ = ~ E(I_{real}) \\I_{recon} ~ = ~ G(z_{pred}, ~ d_{pred})\]</span></p><p>The reconstruction loss function, improved based on <code>MSE</code>,is as follows:</p><p><span class="math display">\[\begin{array}{r}\mathcal{L}_{\text {recon }}(G, E)=\underset{\begin{array}{c}{I_{real} } \sim { p_{real} }\end{array}}{\mathbb{E}}\left[\left\|I_{\text {recon }}-I_{\text {real}}\right\|_{2}^{2} ~ + ~\right. \\\lambda_{\text {ssim }} \mathcal{L}_{\text {ssim }}\left(I_{\text {recon}}, I_{\text {real }}\right) ~ + \\\left.\lambda_{\text {vgg }} \mathcal{L}_{\text {vgg }}\left(I_{\text{recon }}, I_{\text {real }}\right)\right]\end{array}\]</span></p><p>Where <span class="math inline">\(\mathcal{L}_{ssim}\)</span> is theSSIM loss, and <span class="math inline">\(\lambda_{ssim}\)</span> isthe weight factor for the SSIM loss, while <spanclass="math inline">\(\mathcal{L}_{vgg}\)</span> is the VGG perceptualloss, and <span class="math inline">\(\lambda_{vgg}\)</span> is itsweight factor.</p><p><strong>6. Conditional adversarialobjective（条件对抗网络）</strong></p><p>​ The reconstruction objective aims to improve the quality ofwell-reconstructed individual views extracted by the encoder E. This maylead to a tendency for the network to predict unimportant poses or makeunrealistic predictions for the reconstruction of other poses extractedfrom <span class="math inline">\(p_d\)</span>. To mitigate this issue,an additional adversarial objective is applied when the generatorrenders an image <span class="math inline">\(I_{real}\)</span> underrandom poses:</p><p><span class="math display">\[l_{cond}, ~ d_{cond} ~=~D^*(G(z_{pred}, ~d_{rand}))\]</span></p><p>The loss function for this conditional adversarial objective is:</p><p><span class="math display">\[\mathcal{L}_{cond}(G, ~E) ~=~\underset{\substack{\substack{I_{real}\sim p_{real}} \\d_{rand} \sim p_d}}{\mathbb{E}}\left[\operatorname{softplus}(-l_{cond}) \right]\]</span></p><p>​ This additional adversarial objective helps in ensuring that thegenerated images under random poses are realistic and maintainconsistency with the real image distribution.</p><p><strong>7. Encoder warm-up（编码器预热）</strong></p><p>​ The reconstruction loss can easily dominate and lead to overfittingto input views, potentially causing the model to lose its ability torepresent 3D structures. To address this issue, the authors introduced asimple "pre-warmup" strategy. In the first half of the trainingiterations, the encoder is frozen while optimizing both thereconstruction and conditional adversarial losses. Only the generator isoptimized for these two objectives. This serves as a "pre-warmup" forthe generator to roughly learn the correspondence between encoderoutputs and encoded images. Subsequently, the encoder is unfrozen,allowing it to further refine its learned representations. After thepre-warmup phase, the encoder and generator form a pretrainedautoencoder that can generate representations close to real 3Drepresentations, avoiding the cumbersome early reconstruction objective,which can be challenging to balance with the GAN objective.</p><p>The authors demonstrated the necessity of this strategy throughablation studies and compared it to cases where only a small weight wasallocated to the reconstruction loss. This strategy helps strike abalance between representation learning and reconstruction, ensuringthat the model can effectively capture 3D structures while generatingrealistic images.</p><p><strong>8. Training and Inference（训练与推测）</strong></p><p>​ The discriminator and GAN inversion objectives are optimized at eachiteration, while the GAN generator objective is optimized every otheriteration. The reconstruction and conditional adversarial objectives arejointly optimized during odd-numbered iterations with a weighting factor<span class="math inline">\(λ_{recon}\)</span>:</p><p><span class="math display">\[\mathcal{L}_{odd} ~=~ \mathcal{L}_{cond} ~ + ~\lambda_{recon}\mathcal{L}_{recon}\]</span></p><p>​ During the inference phase, Pix2NeRF requires only one input image.This image can be fed into the encoder E, then into the generator G,followed by an arbitrary choice of pose for novel view synthesis.Additionally, sampling from the prior distribution <spanclass="math inline">\(p_z\)</span> can be done instead of obtaining thelatent code z from the encoder. This allows the model to synthesizenovel samples similar to π-GAN.</p><h4 id="experiment">3 Experiment</h4><p><strong>1. Datasets</strong></p><p>CelebA: 200,000 images of ==human faces==, using the <em>aligned</em>version and employing center cropping to capture the approximate facialarea. 8,000 of these images are utilized as a test set.</p><p>CARLA: Comprising 10,000 images with 16 different ==car models==,generated using the CARLA driving simulator with random texturerendering.</p><p>ShapeNet-SRN: This dataset consists of 50 rendering views fromShapeNet, with each instance having an Archimedean spiral camera pose.The training set is filtered by the authors to include only the upperhemisphere since the validation and test sets of the ShapeNet-SRNdataset do not include the lower hemisphere. The authors utilize==chair== segmentation for comparison with previous multi-viewmethods.</p><p><strong>2. Technical details</strong></p><p><code>Baseline:</code> ==π-GAN (PyTorch)==, reusing its generator anddiscriminator architecture.</p><p><code>Parameters:</code> The latent code prior distribution <spanclass="math inline">\(p_z\)</span> is chosen as a multivariate uniformdistribution on [-1, 1]. The discriminator architecture is used as theencoder backbone, and a ==tanh== activation function is added at the endof the latent code head. All models are optimized using the Adamoptimizer for 300,000 iterations. For the CelebA model, training is doneat a resolution of 64x64 with a batch size of 48, and each ray samples24 points. The learning rates for the discriminator, generator, andencoder are set to ==2e-4, 6e-5, and 2e-4==, respectively. For othermodels, training is conducted at a resolution of 32x32, with each raysampling 96 points. The learning rates are set to ==4e-5, 4e-4, and4e-4== for the discriminator, generator, and encoder, respectively.</p><p><strong>3. Comparison of Results</strong></p><figure><img src="3.png?80*80" alt="result" /><figcaption aria-hidden="true">result</figcaption></figure><p><strong>4. Ablation studies</strong></p><p>​ The primary model components compared are: <em>Naive GAN inversion,Auto-encoder, No GAN inversion, No conditional adversarial objective,Warm-up</em>.</p><p><code>Naive GAN inversion:</code>In the naive GAN inversion, apre-trained GAN is used, its weights are frozen, and an encoder istrained to map images to their corresponding latent codes. The resultsshow that the encoder can learn an approximate mapping from images tolatent codes.</p><p><code>Auto-encoder:</code>The architecture of π-GAN is used as anauto-encoder, and the ==latent space is removed from the pipeline==.Only reconstruction and conditional adversarial models are trained. Theresults yield good quality, but noticeable 3D inconsistencies areobserved.</p><p><code>No GAN inversion:</code> After ==removing GAN inversion fromthe pipeline==, the visual results become blurry. This step may be theconnection between π-GAN training and reconstruction, affecting overallperformance.</p><p><code>No conditional adversarial objective:</code> Disabling theconditional adversarial loss and retraining results in incompleterendering, noticeable artifacts, and reduced consistency.</p><p><code>Warm-up:</code> Three models are trained separately withdifferent warm-up strategies: ==no warm-up, no unfreezing of the encoder(always warm), and assigning lower weights for reconstruction instead ofwarming up==. Without a warm-up strategy, it leads to overfitting ofinput views and an inability to generate meaningful content in novelposes. Not unfreezing the encoder results in relatively weakdistillation with few details. Using lower reconstruction weightsinstead of warming up causes the breakdown of patterns in newlyattempted synthesis.</p><h4 id="other">4 Other</h4><ol type="1"><li>Leveraging more mature encoder architectures like Pixel2Style2Pixelin 2D GAN forward inversion may significantly improve the performance ofPix2NeRF.</li></ol>]]></content>
    
    
    <categories>
      
      <category>每周回顾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结&amp;反思</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>每周总结(23.09.04-23.09.10)</title>
    <link href="/posts/38005/"/>
    <url>/posts/38005/</url>
    
    <content type="html"><![CDATA[<div align='center'><H3>Weekly report</div><p><strong>Date: 23.09.04-23.09.10</strong></p><h3 id="paper">Paper</h3><p><strong>Title:</strong><code>Efficient Geometry-aware 3D Generative Adversarial Networks</code></p><h5 id="method-contribution-related-work.">1 Method, Contribution,Related Work.</h5><p><strong>1.1 Method:</strong></p><p>​ A hybrid explicit-implicit 3D perception network has been designed,utilizing a <em>memory-efficient three-plane representation</em> toexplicitly store features on axis-aligned planes aggregated by a<em>lightweight implicit feature decoder</em>. This approach aims toachieve efficient volume rendering and enhance the computationalefficiency of 3D foundational rendering. It incorporates certain imagespace approximations deviating from traditional 3D foundationalrendering, while introducing a dual-discriminative strategy thatmaintains consistency between neural rendering and the final output toregulate tendencies of view inconsistency.</p><blockquote><p>Explicit representation allows for fast evaluation but requiressubstantial memory, making it challenging to scale to high resolutionsor complex scenes. Implicit representation, while advantageous in termsof memory efficiency and scene complexity, employs large fully connectednetworks for evaluation, leading to slow training speeds. Hence,explicit and implicit representations offer complementary benefits.</p></blockquote><figure><img src="1.png" alt="三平面模型" /><figcaption aria-hidden="true">三平面模型</figcaption></figure><p><strong>1.2 Contribution:</strong></p><ul><li>Introduced a three-plane-based 3D GAN framework that is bothefficient and expressive, enabling high-resolution geometric perceptionimage synthesis.</li><li>Developed a 3D GAN training strategy that promotes multi-viewconsistency through dual-discrimination and generator pose conditioning,while faithfully modeling pose-related attribute distributions presentin real-world datasets, such as expressions.</li><li>Demonstrated the latest results in unconditional 3D perception imagesynthesis on the FFHQ and AFHQ Cats datasets, as well as high-quality 3Dgeometric graphics learned entirely from 2D outdoor images.</li></ul><p><strong>1.3 Related Work:</strong></p><ol type="1"><li>Neural scene representation and rendering</li></ol><p>​ A new hybrid explicit-implicit 3D perception network has beendesigned, which utilizes a memory-efficient three-plane representationto explicitly store features on axis-aligned planes aggregated by alightweight implicit feature decoder, aiming to achieve efficient volumerendering.</p><ol start="2" type="1"><li>Generative 3D-aware image synthesis</li></ol><p>​ An efficient 3D GAN architecture with a 3D-based prior bias iscrucial for successfully generating high-resolution, view-consistentimages, and high-quality 3D shapes. Therefore, the authors adopted thefollowing approaches:</p><ul><li>Directly leverage a 2D CNN feature generator, namely<em>StyleGAN2</em>.</li><li>The three-plane representation allows this paper's approach toutilize neural volume rendering as a prior bias, making itcomputationally more efficient than fully implicit 3D networks.</li><li>Employing an up-sampling based on 2D CNNs after neural renderingwhile introducing dual discriminators to mitigate view inconsistenciesbrought about by the up-sampling layers.</li></ul><h4 id="model-and-modules">2 Model and Modules</h4><p><strong>2.1 Tri-plane hybrid 3D represnetation</strong></p><p><code>IDEA:</code>Hybrid explicit-implicit tri-planerepresentation.</p><p><code>Implement:</code>Align explicit features along threeaxis-aligned orthogonal feature planes, each with a resolution of N×N×C,where N represents spatial dimensions and C stands for the number ofchannels. To query any 3D position point <em>x</em>, project it onto thethree feature planes to retrieve the corresponding feature vector <spanclass="math inline">\((F_{xy} ~~,~~ F_{xz}~ , ~ F_{yz})\)</span> throughbilinear interpolation and then aggregate these three feature vectors bysummation. Finally, feed this aggregated feature F into a small decoder(MLP) to decode it into color and density.</p><p><strong>2.2 3D GAN framework</strong></p><p><code>IDEA:</code>Train a 3D GAN for collective perception imagesynthesis from 2D photos without the need for any explicit 3D ormulti-view supervision. Simultaneously, use a pre-trained pose detectorto associate each training image with a set of camera intrinsics andextrinsics(<em>Deep3DFaceReconstruction</em>).</p><p><code>Implement &amp;&amp; Overview:</code></p><figure><img src="2.jpg" alt="Overview" /><figcaption aria-hidden="true">Overview</figcaption></figure><blockquote><ol type="a"><li><p>A pose-conditioned StyleGAN2 feature generator and mappingnetwork.</p></li><li><p>Three-plane 3D representation with a lightweight featuredecoder.</p></li><li><p>A neural voxel renderer.</p></li><li><p>A super-resolution module.</p></li><li><p>A pose-conditioned StyleGAN2 discriminator with dualdiscrimination.</p></li></ol></blockquote><p>​ This architecture cleverly decouples feature generation and neuralrendering, enabling the utilization of the powerful StyleGAN2 generatorfor generalizing 3D scenes. Furthermore, the lightweight three-plane 3Drepresentation can effectively convey rich information and achievehigh-quality 3D perception view synthesis in real-time. Additionally, atwo-stage training strategy is employed to accelerate training speed.The first stage involves training with reduced <spanclass="math inline">\((64^2)\)</span> neural rendering resolution, whilethe second stage consists of short-term fine-tuning at full <spanclass="math inline">\((128^2)\)</span> neural rendering resolution.</p><p><strong>2.3 CNN generator backbone and rendering</strong></p><p><code>IDEA:</code>The features of the <em>three-plane representationare generated by the StyleGAN2 CNN generator</em>. Random latent codesand camera parameters are first processed by the mapping network toproduce intermediate latent codes, which are then used to modulate theconvolution kernels of the separately synthesized network.</p><p><code>Implement:</code>Change the output shape of the StyleGAN2backbone network to generate a feature map of dimensions 256×256×96instead of generating a three-channel RGB image. Sample features fromthe three planes and merge the features sampled from these three planes,which are then fed into a lightweight decoder (MLP) with a single hiddenlayer of 64 neurons and the activation function being<em>softplus</em>.</p><p><code>Module:</code> StyleGAN2, MLP</p><p><strong>2.4 Super resolution</strong></p><p><code>IDEA:</code> Perform volume rendering at intermediateresolution <span class="math inline">\((128^2)\)</span> and rely onimage space convolutional upsampling for rendering to image sizes of<span class="math inline">\((256^2 ~ or ~ 512^2)\)</span>.</p><p><code>Implement:</code> Comprised of two blocks modulating theconvolutional layers in StyleGAN2:</p><ul><li>Upsampling, increasing the resolution from 128×128×3 to512×512×3.</li><li>Adapting the 32-channel feature map to the final RGB image.</li></ul><p><strong>2.5 Dual discrimination</strong></p><p><code>IDEA:</code>Utilize the StyleGAN2 discriminator and made it twomodifications.</p><p><code>Implement:</code> A) Interpret the feature map as alow-resolution RGB image. The dual discriminator ensures consistencybetween low-resolution RGB images and high-resolution images byupsampling them using bilinear interpolation to the same 512×512×3 sizeand concatenating them with the adjusted <spanclass="math inline">\((I^+_{RGB})\)</span>, resulting in a 6-channelimage. B) Concatenate the input 3-channel RGB image with itsappropriately blurred counterpart to form a 6-channel image as the inputto the discriminator.</p><p><code>Module:</code>StyleGAN2-ADA strategy</p><blockquote><p>StyleGAN2-ADA Strategy: Pass the camera's intrinsic and extrinsicmatrices (P) to the discriminator as conditional labels. This modulationintroduces additional information to guide the generator in learning thecorrect 3D priors.</p></blockquote><p><strong>2.6 Modeling pose-correlated attributions</strong></p><p><code>IDEA:</code>Introduced <em>generator pose conditioning</em> asa means to model and decouple the correlation between observed poses andother attributes in the training images.</p><p><code>Implement:</code>Following the StyleGAN2-ADA conditionalgeneration strategy, propose a backbone mapping network that not onlyprovides a latent code z but also takes camera parameters P asinput.</p><h4 id="other-details">3 Other details</h4><p><strong>3.1 Pose Estimators</strong></p><p>​ Augment the dataset using horizontal flipping and utilizepre-existing pose estimation to extract approximate camera extrinsicparameters.</p><blockquote><p>Pre-existing pose estimation methods:</p><ol type="1"><li>https://github.com/Microsoft/Deep3DFaceReconstruction for generatingpose data for faces (FFHQ).</li><li>https://github.com/kairess/cat_hipsterizer for generating pose datafor cats (AFHQv2 Cats).</li></ol></blockquote><h3 id="other-work">Other Work</h3><p>​ To read the code of this paper, especially the pose estimators andrun these code in the two links. Then I've been learning about StyleGAN2to understand methods in this paper better.Summray</p><p>​阅读了一篇论文<code>Efficient Geometry-aware 3D Generative Adversarial Networks</code>，并将上次的论文重新总结了一下。去了解运行了姿态估计的代码，并且去了解了StyleGAN2的一些思想，和StyleGAN2-ADA自适应增强等一些知识。</p><h3 id="paper-1">Paper</h3><h4id="title-efficient-geometry-aware-3d-generative-adversarial-networks"><strong>Title:</strong><code>Efficient Geometry-aware 3D Generative Adversarial Networks</code></h4><h5 id="一提出的方法贡献相关工作">一、提出的方法、贡献、相关工作</h5><p><strong>1.方法：</strong></p><p>​设计了一种混合显式-隐式3D感知网络，该网络使用内存高效的<code>三平面表示显式地</code>存储由轻量级<code>隐式特征解码器聚合</code>的轴对齐平面上的特征，以实现高效的体绘制，提高了3D基础渲染的计算效率。使用了一些偏离3D基础渲染的图像空间近似，同时引入了一种双重判别策略，该策略保持神经渲染和最终输出之间的一致性，以规范其视图不一致的趋势。</p><blockquote><p>显式表示可以进行快速评估，但是需要很大的内存，使得这种方式难以扩展到高分辨率或复杂场景。隐式表示虽然在内存效率和场景复杂性方面有优势，但是这种方法使用大型的全连接网络进行评估，使得训练速度缓慢。因此，显式和隐式表示提供了互补的好处。</p></blockquote><figure><img src="1.png" alt="三平面模型" /><figcaption aria-hidden="true">三平面模型</figcaption></figure><p><strong>2.贡献：</strong></p><ul><li>引入了一个基于三平面的3DGAN框架，该框架既高效又富有表现力，以实现高分辨率几何感知图像合成。</li><li>开发了一种3DGAN训练策略，通过双重判别和生成器姿势条件促进多视图一致性，同时忠实地建模现实世界数据集中存在的姿势相关属性分布（例如表达式）。</li><li>展示了在FFHQ和AFHQCats数据集上无条件3D感知图像合成的最新结果，以及完全从2D野外图像中学习的高质量3D几何图形。</li></ul><p><strong>3.相关工作：</strong></p><p>​ 1）Neural scene representation and rendering(神经场景表示和渲染)</p><p>​设计了一种新的混合显式隐式3D感知网络，该网络使用内存高效的三平面表示显式地存储由轻量级隐式特征解码器聚合的轴对齐平面上的特征，以实现高效的体绘制</p><p>​ 2）Generative 3D-aware image synthesis(生成式3D感知图像合成)</p><p>​ 具有基于3D的先验偏差的高效3DGAN架构对于成功生成高分辨率视图一致图像和高质量3D形状至关重要。所以作者采用了以下方法：</p><p>​ a. 直接利用基于2D CNN特征生成器，即<code>StyleGAN2</code>。</p><p>​ b.三平面表示使得该论文的方法能利用神经体渲染作为先验偏差，在计算上比完全隐式3D网络更有效。</p><p>​ c. 在神经渲染后采用基于2DCNN的向上采样，同时引入双重辨别器去避免上采样层带来的视图不一致。</p><h5 id="二模型与模块">二、模型与模块</h5><p><strong>1. Tri-plane hybrid 3Drepresentation(Tri-plane混合3D表示)</strong></p><p><code>思想：</code>hybrid explicit-implicit tri-planerepresentation(混合显式-隐式三平面表示)。</p><p><code>实现：</code>沿着三个轴对齐的正交特征平面对齐显式特征，每个特征平面的分辨率均为N×N×C，N为空间维度，C为通道数。通过将3D位置投影到三个特征平面中来查询任何3D位置点<code>x</code>，通过双线性插值检索相应的特征向量<spanclass="math inline">\((F_{xy} ~,~ F_{xz}~ , ~F_{yz})\)</span>，然后通过求和来汇总这三个特征向量。最后将这个汇总的特征F输入到一个小型解码器(MLP)来解码为颜色和密度。</p><p><code>模块：</code>小型MLP网络。</p><p><strong>2. 3D GAN framework(3D GAN框架)</strong></p><p><code>思想：</code>训练一个3DGAN，用于从2D照片中进行集合感知图像合成，而无需任何显式3D或者多视图监督。同时使用现成的姿态检测器，将每个训练图像与一组相机内参和外参相关联(<code>Deep3DFaceReconstruction</code>)。</p><p><code>实现/Overview:</code></p><figure><img src="2.jpg" alt="Overview" /><figcaption aria-hidden="true">Overview</figcaption></figure><blockquote><p>​ a. 一个基于姿态条件的StyleGAN2特征生成器和映射网络。</p><p>​ b. 一个具有轻量级特征解码器的三平面3D表示。</p><p>​ c. 一个神经体素渲染器。</p><p>​ d. 一个超分辨率模块。</p><p>​ e. 一个基于姿态条件的具有双重辨别的StyleGAN2辨别器。</p></blockquote><p>​这个架构巧妙地将特征生成和神经渲染解耦，使得可以利用强大的StyleGAN2生成器进行3D场景的泛化。此外，轻量级的三平面3D表示既能够表达丰富的信息，又能够在实时中实现高质量的3D感知视图合成。同时，采用两阶段训练策略加速训练速度。第一个阶段：使用减少<spanclass="math inline">\((64^2)\)</span>神经渲染分辨率进行训练；第二个阶段：在完全<spanclass="math inline">\((128^2)\)</span>神经渲染分辨率上的短期微调。</p><p><strong>3. CNN generator backbone andrendering(CNN生成器主干和渲染)</strong></p><p><code>思想：</code>由<code>StyleGAN2 CNN生成器生成三平面表示的特征</code>。随机潜在代码和相机参数首先由映射网络处理以产生中间潜在代码，然后调制单独合成网络的卷积核。</p><p><code>实现：</code>改变StyleGAN2主干网络的输出形状，不是生成三通道RGB图像，而是生成一个256×256×96的特征图像。从三平面采样特征，并融汇从三个平面采样的特征，输入到轻量级解码器(MLP，64个神经元的单个隐藏层，激活函数：softplus)。</p><p><code>模块：</code>StyleGAN2、MLP</p><p><strong>4. Super resolution(超分辨率)</strong></p><p><code>思想：</code>使用中等分辨率<spanclass="math inline">\((128^2)\)</span>进行体渲染，并依靠图像空间卷积上采样神经渲染到<spanclass="math inline">\((256^2 ~ or ~ 512^2)\)</span>图像大小。</p><p><code>实现：</code>由StyleGAN2调制卷积层的两个块组成。1）上采样，将128×128×3分辨率提高到512×512×3的分辨率。2）调整32通道特征图到最终的RGB图像。</p><p><strong>5. Dual discrimination(双重辨别器)</strong></p><p><code>思想：</code>使用StyleGAN2的辨别器，并进行了两次修改。</p><p><code>实现：</code>1）将特征图解释为低分辨率RGB图像。双重辨别器确保低分辨率RGB图像与高分辨率图像的一致性，通过双线性上采样成同样512×512×3图像并与调整后的<spanclass="math inline">\((I^+_{RGB})\)</span>进行连接变成6通道图像。2）将输入的3通道RGB图像与其适当模糊后的图像进行连接，变成6通道图像作为辨别器的输入。</p><p><code>模块：</code>StyleGAN2-ADA策略</p><blockquote><p>​StyleGAN2-ADA策略：将渲染相机的内外矩阵(P)传递给鉴别器作为条件标签。这种调节引入了额外的信息，指导生成器学习正确的3D先验。</p></blockquote><p><strong>6. Modeling pose-correlatedattributes(建模姿态相关属性)</strong></p><p><code>思想：</code>引入了<code>generator pose conditioning(生成器姿势条件)</code>作为建模和解耦训练图像中观察到的姿势与其他属性之间的相关性的一种手段。</p><p><code>实现：</code>按照StyleGAN2-ADA条件生成策略，提出一个主干映射网络，不仅提供一个潜在代码z，同时提供相机参数P作为输入。</p><h5 id="三其他细节">三、其他细节</h5><p><strong>1. Pose Estimators(姿态估计)</strong></p><p>​用水平翻转的方法来扩充数据集，并使用现成的姿态估计来提取近似的相机外部参数。</p><blockquote><p>现成的姿态估计方法：</p><p>1）https://github.com/Microsoft/Deep3DFaceReconstruction，用来生成脸的数据集的姿态(FFHQ)。</p><p>2）https://github.com/kairess/cat_hipsterizer，用来生成猫的数据集的姿态(AFHQv2Cats)。</p></blockquote><h4id="titileshape-pose-and-appearance-from-a-single-image-via-bootstrapped-radiance-field-inversion">Titile：<code>Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion</code></h4><h5 id="一提出的方法与贡献">一、提出的方法与贡献</h5><p><strong>1.方法：</strong></p><p>​作者提出了一种新的方法，将无条件生成模型与混合反演范式相结合，从单个图像中恢复三维信息。具体来说，他们使用神经辐射场（NeRF）来表示三维场景，并使用编码器产生潜在表示和姿态的第一个猜测。然后，他们通过优化来细化这些初始估计，以获得更准确的重建。</p><p><strong>2.贡献：</strong></p><ul><li>引入了一个基于NeRF的端到端单视图三维重建管道。在这种情况下，我们成功地展示了CMR基准下自然图像的<spanclass="math inline">\(360^◦\)</span>对象重建。</li><li>提出了一种用于NeRF的混合反演方案，以加快预训练的3D感知生成器的反转。</li><li>受姿态估计文献的启发，我们提出了一种基于PnP的姿态估计器，它利用我们的框架并且不需要额外的数据假设。</li></ul><h5 id="二模型与模块-1">二、模型与模块</h5><p><strong>1. Unconditional generatorpre-training（无条件生成器预训练框架）</strong></p><figure><img src="3.png" alt="无条件生成器" /><figcaption aria-hidden="true">无条件生成器</figcaption></figure><p><code>思想：</code>主要思想来自EG3D的主干网络，三平面编码。<code>该部分被框架使用基于NeRF的生成器G与2D图像鉴别器相结合。</code></p><p><code>模块：</code>StyleGAN2，SDF representation，Attention-basedcolor mapping，Path Length Regularization revisited。</p><blockquote><p>StyleGAN2：生成模型，SDF representation：3D表示，</p><p><strong>Attention-based color mapping：提高颜色泛化性, Path LengthRegularizationrevisited：使三平面解码器不正则化，提高学习率。</strong></p></blockquote><p><strong>2. Bootstrapping and poseestimation（自举和姿态估计）</strong></p><figure><img src="4.png" alt="姿态估计" /><figcaption aria-hidden="true">姿态估计</figcaption></figure><p><code>思想：</code>主要思想来自NOCS，<code>改进：是使用从无条件生成器生成的数据来训练编码器而不是手工数据。</code></p><p><code>实现：</code>1）冻结G并训练图像编码器E，联合估计对象的姿势及其潜在代码（自举）的初始猜测。2）对于姿态估计，我们采用了一种原则性的方法来预测屏幕空间中的规范映射通过透视n点(PnP)算法。<code>输入真实图像，将预测的规范映射转换为点云，并运行PnP求解器来恢复所有姿态参数(视图矩阵和焦距)。</code></p><p><code>模块：</code>SegFormer</p><blockquote><p><strong>训练SegFormer网络来从RGB图像中预测规范图和latent codew</strong></p></blockquote><p><strong>SegFormer分割网络图：</strong></p><figure><img src="5.png" alt="分割网络" /><figcaption aria-hidden="true">分割网络</figcaption></figure><p><strong>3. Reconstruction via hybrid GANinversion（通过混合GAN反演重建）</strong></p><figure><img src="6.png" alt="混合反演" /><figcaption aria-hidden="true">混合反演</figcaption></figure><p>通过基于梯度的优化(混合反演)改进了几个步骤的姿态和潜在代码。损失函数：VGG</p><p><code>模块：</code>adaptive discriminator augmentation(ADA)</p><blockquote><p>有助于减少梯度的方差，使我们能够进一步提高学习率。</p></blockquote><h3 id="other-work-1">Other Work</h3><p>​阅读这篇论文的代码，特别是姿态估计器的部分，并在这两个链接中运行这些代码。然后，我一直在学习关于StyleGAN2，以更好地理解这篇论文中的方法。</p>]]></content>
    
    
    <categories>
      
      <category>每周回顾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结&amp;反思</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>每周总结(23.08.28-23.09.03)</title>
    <link href="/posts/36354/"/>
    <url>/posts/36354/</url>
    
    <content type="html"><![CDATA[<div align="center"><H3>Weekly report</div><p><strong>Date: 23.08.28-23.09.03</strong></p><h4 id="paper">1.Paper</h4><p><strong>Title:</strong><code>Efficient Geometry-aware 3D Generative Adversarial Networks</code></p><p>​这篇论文介绍了一种高效的几何感知3D生成对抗网络（GANs）方法，该方法可以使用单视角2D照片集合生成高质量的多视角一致图像和3D形状。该方法采用了混合显式-隐式网络架构，可以实现实时合成高分辨率的多视角一致图像和高质量的3D几何形状。该方法还提出了双重歧视和生成器姿势调节来减少表情扭曲，提高多视角一致性。作者在ShapeNet和CelebA数据集上进行了实验，结果表明该方法在多视角一致性和3D形状质量方面优于现有方法，并且可以合成具有逼真面部表情和姿势的高质量图像。此外，作者还讨论了该方法的一些局限性和可能的改进方向。</p><p><strong>Framework:</strong></p><p><img src="23.08.28-23.09.03/image-20231009220945991.png" alt="image-20231009220945991" style="zoom:80%;" /></p><p>​设计了一种新的混合显式隐式3D感知网络，该网络使用内存高效的三平面表示显式地将特征存储在由轻量级隐式特征解码器聚合的轴对齐平面上，以实现高效的体绘制。（还没看完，代码跑通了）</p><p><strong>Title:</strong><code>Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion</code></p><p>​这篇论文介绍了一种从单一图像中重建对象的形状、姿态和外观的新方法。该方法利用了近期在NeRF表示方面的进展，并将问题构建为一个3D感知的GAN反演任务。通过学习一个编码器来加速这个过程，编码器提供了解决方案的初步猜测，并包括了一个有原则的姿态估计技术。该方法在合成和真实基准测试中都达到了最先进的性能，并且在小数据集上表现出了高效和有效的特点。在未来，作者希望将这种方法扩展到更高的分辨率，并通过利用额外视图或形状先验的半监督来改进重建表面质量。他们还希望探索从数据中自动推断姿态分布的方法。</p><p><strong>Framework:</strong></p><p>​对论文的框架进行分析，作者使用EG3D中提出的的三平面表示方法设计了一个无条件生成器预训练模型，提高渲染速度的同时保证了图像的分辨率。同时论文中使用3DGAN反演的方法来进行迭代优化，将反演出来的图像与真实图像进行损失计算，从而对模型进行调整。并且对生成的图像和真实图像做了图像增强处理，加快收敛。因为模型中使用了PnP(Perspective-n-point)方法用于从2D图像中估计物体姿态，这种设计虽然能够获得较为准确的物体姿态，但是会导致训练的速度很慢，同时还要求及其高的GPU缓存。</p>]]></content>
    
    
    <categories>
      
      <category>每周回顾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结&amp;反思</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>每周总结(23.08.14-23.08.20)</title>
    <link href="/posts/22085/"/>
    <url>/posts/22085/</url>
    
    <content type="html"><![CDATA[<div align="center"><H3>Weekly report</div><p><strong>Date: 23.08.14-23.08.20</strong></p><h4 id="paper">1.Paper</h4><p><strong>Title:</strong><code>Pix2NeRF: Unsupervised Conditional π-GAN for Single Image to Neural Radiance Fields Translation</code></p><p><strong>Summary:</strong></p><p>​ Pix2NeRF consists of two main components: a generative model and areconstruction objective. The generative model uses a combination of agenerative adversarial network (GAN) and an autoencoder to encode inputimages into vector representations in latent space and generatehigh-quality 3D-aware images. The reconstruction objective uses acombination of reconstruction error and MSE supervision to penalize thegenerator and learn a "canonical" 3D space. These two componentstogether form the Pix2NeRF method for generating Neural Radiance Fields(NeRF) based on a single input image. Overall, Pix2NeRF is an excitingnew approach to generating high-quality 3D-aware images and has thepotential to be used in a wide range of applications.</p><p><strong>Framework:</strong></p><p>​ The framework of the paper consists of two parts: a generative modeland a reconstruction objective. The generative model uses a combinationof a generative adversarial network (GAN) and an autoencoder to encodeinput images into vector representations in latent space and generatehigh-quality 3D-aware images. The reconstruction objective uses acombination of reconstruction error and MSE supervision to penalize thegenerator G and learn a "canonical" 3D space. These two componentstogether form the Pix2NeRF method for generating Neural Radiance Fields(NeRF) based on a single input image.</p><p><strong>Generative mode and Reconstruction objective: </strong></p><p>​ The generative model uses a combination of a generative adversarialnetwork (GAN) and an autoencoder. The goal of the GAN is to train thegenerator G and discriminator D to generate high-quality 3D-awareimages. The goal of the autoencoder is to encode input images intovector representations in latent space, which can be used for imagereconstruction or generating new viewpoints. We use the π-GAN objectiveto optimize the training of the generator G and discriminator D, toimprove the 3D consistency of the generated images. Specifically, thegenerator G is trained to "fool" the discriminator D by progressivelygenerating realistic images. The generator G and discriminator D aretrained together to generate high-quality 3D-aware images.</p><p>​ The reconstruction objective uses a combination of reconstructionerror and MSE supervision to penalize the generator G and learn a"canonical" 3D space. The reconstruction error refers to the differencebetween the generated 3D-aware image and the ground truth image. The MSEsupervision penalizes the generator G if the image pose recovered by thediscriminator does not correspond to the sampled pose. This helps tolearn a "canonical" 3D space, especially when the pose distribution ofreal data is noisy. These two components together form the Pix2NeRFmethod for generating Neural Radiance Fields (NeRF) based on a singleinput image.</p><p><strong>The steps of Pix2NeRF:</strong></p><blockquote><ol type="1"><li>Extract 2D features from a single input image.</li><li>Encode the 2D features into vector representations in latent spaceusing a combination of a generative adversarial network (GAN) and anautoencoder.</li><li>Sample random vectors from the latent space and use the generator togenerate 3D-aware images.</li><li>Penalize the generator using a combination of reconstruction errorand MSE supervision to learn a "canonical" 3D space.</li><li>Repeat steps 3 and 4 until the difference between the generated3D-aware image and the ground truth image is minimized.</li><li>Use the generated NeRF model to generate new viewpoints orreconstruct the input image.</li></ol></blockquote><p>In summary, the steps of Pix2NeRF are: extract 2D features, encodeinto vector representations in latent space, generate 3D-aware images,learn a "canonical" 3D space, and generate new viewpoints or reconstructthe input image.</p><h4 id="code">2.Code</h4><p>​ I tested the trained model of 'Shape, Pose, and Appearance from aSingle Image via Bootstrapped Radiance Field Inversion' and trained anlarger model(batch size is 16). Built the environment of this paper.</p>]]></content>
    
    
    <categories>
      
      <category>每周回顾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结&amp;反思</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>每周总结(23.08.07-23.08.13)</title>
    <link href="/posts/8519/"/>
    <url>/posts/8519/</url>
    
    <content type="html"><![CDATA[<div align="center"><H3>Weekly report</div><p><strong>Date:2023.08.07-2023.08.13</strong></p><h4 id="paper">1.Paper</h4><p><strong>Title:</strong><code>Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion</code></p><p><strong>Summary:</strong></p><p>​ This paper presents a new method for reconstructing the shape, pose,and appearance of an object from a single image. The approach leveragesrecent advances in NeRF representations and frames the problem as a3D-aware GAN inversion task. The process is accelerated by learning anencoder that provides a first guess of the solution and incorporates aprincipled pose estimation technique. The method achievesstate-of-the-art performance on both synthetic and real benchmarks andis shown to be efficient and effective on small datasets. In the future,the authors hope to scale the method to higher resolutions and improvethe reconstructed surface quality by leveraging semi-supervision onextra views or shape priors. They also hope to explore ways toautomatically infer the pose distribution from the data.</p><p><strong>Framework:</strong></p><p>​ The overall framework of this paper is an end-to-end reconstructionframework for reconstructing 3D scenes from a single 2D image. Theframework includes the following steps:</p><blockquote><ol type="1"><li>Generating 3D scenes using NeRF representation.</li><li>Converting 3D scenes to 2D images using GAN inversion.</li><li>Accelerating the reconstruction process using a hybrid inversionmethod.</li><li>Estimating the 3D pose of the object using a deep learning-basedpose estimation technique.</li><li>Providing the first guess of the solution using an encoder.</li></ol></blockquote><p><strong>NeRF representation and GAN inversion:</strong></p><ol type="1"><li>Firstly, an unconditional generator G based on NeRF representationis trained in combination with a 2D image discriminator, following theliterature on 3D-aware GANs. This framework requires minimalassumptions, namely 2D images and the corresponding posedistribution.</li></ol><figure><img src="1.png?100*100" alt="NeRF representation" /><figcaption aria-hidden="true">NeRF representation</figcaption></figure><ol start="2" type="1"><li>Then, the generator G is frozen and an image encoder E is trained tojointly estimate the pose of the object as well as an initial guess ofits latent code (bootstrapping). For pose estimation, a principledapproach is adopted that predicts a canonical map in screen spacefollowed by a Perspective-n-Point (PnP) algorithm for estimation.</li></ol><figure><img src="2.png?100*100" alt="GAN inversion" /><figcaption aria-hidden="true">GAN inversion</figcaption></figure><ol start="3" type="1"><li>Finally, NeRF representation is used to generate 3D scenes.Specifically, the generator G and the encoder E are used to generate 3Dscenes, and a hybrid inversion method is used to convert the 3D scenesto 2D images.</li></ol><figure><img src="3.png?100*100" alt="hybrid inversion" /><figcaption aria-hidden="true">hybrid inversion</figcaption></figure><p><strong>Hybrid inversion:</strong></p><p>​ The encoder E and the generator G are used to generate 3D scenes,which are then converted to 2D images using the hybrid inversionmethod.</p><p>​ The hybrid inversion method consists of two steps: the first stepinvolves generating 3D scenes using the encoder E and the generator G,which the second step involves iteratively optimizing the 3D scenerepresentation using an optimization algorithm to obtain a more accuraterepresentation.</p><p>​ This iterative optimization method can be implemented usingbackpropagation and can be seamlessly integrated with the GAN framework.By using the hybrid inversion method, this paper is able to acceleratethe reconstruction process without sacrificing reconstructionquality.</p><h4 id="code">2. Code</h4><p>​ The code from this paper has been fully implemented; however, due tothe requirement of a minimum of 160GB GPU memory in their environment, Ihad to adjust the batch size to 8 (originally 32) to successfully trainthe model. I plan to test the trained model next week and explore thepossibility of training an even larger model afterward.</p>]]></content>
    
    
    <categories>
      
      <category>每周回顾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结&amp;反思</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Summary</title>
    <link href="/posts/39277/"/>
    <url>/posts/39277/</url>
    
    <content type="html"><![CDATA[<div align= "center"><H3>Summary</div><p>​ Over the past one month, I have delved into the realm of computergraphics, exploring concepts like Camera Transformation, ProjectionTransformation, and Viewport Transformation. During this time, I alsogained insights into camera parameters, camera coordinate systems, andworld coordinate systems, developing proficiency in transformingcoordinates between them. Furthermore, I manually deduced renderingformulas to deepen my understanding. In parallel, I devoted time tostudying Deep Learning, broadening my knowledge in this fascinatingfield.</p><p>Following my theoretical endeavors, I embarked on a coding journey torestructure NeRF (Neural Radiance Fields). My aim was to rewrite theNeRF code from the Tensorflow framework to PyTorch framework. Thishands-on process not only enhanced my coding skills but also provided mewith a profound comprehension of NeRF, rendering techniques, and theworkings of Multi-Layer Perceptrons (MLP).</p><p>​ In particular, I came to understand two essential aspects of NeRF'scode:</p><p>​ Position Encoding: The authors of NeRF utilized Position Encoding toaddress challenges associated with accurately representinghigh-frequency variations in color and geometry. To achieve this, theyemployed a clever mapping of the input coordinates (x, y, z, and viewcoordinate) to a higher-dimensional space using high-frequencyfunctions. Notably, they used sine and cosine functions (sin^2(Lx) andcos^2(Lx), with L=10) to transform the three-dimensional input into asixty-dimensional space.</p><p>​ NeRF Model: In the code implementation, NeRF comprises an MLPnetwork with eight fully-connected ReLU layers. Each layer features 256dimensions, except for the fifth layer, which acts as a skip connectionand contains 316 features (256 from the previous layers and 60 from thepositional encoding). Additionally, there is an extra layer responsiblefor outputting the volume density and a 256-dimensional feature vector.This feature vector is combined with the positional encoding of theinput viewing direction (γ(d)), and the resulting combination isprocessed by an additional fully-connected ReLU layer with 128 channels.Finally, a final layer with a sigmoid activation function yields theemitted RGB radiance at position x, as viewed by a ray with directiond.</p><p>​ Loss: The loss function employed in the code is straightforward. Itcalculates the L2 loss between the rendered image and the ground truthimage, and subsequently optimizes the model based on this loss.</p><p>​ Besides, I read tow papers, named ‘Instant Neural GraphicsPrimitives with a Multiresolution Hash Encoding’ and ‘Shape, Pose, andAppearance from a Single Image via Bootstrapped Radiance FieldInversion’ respectively.</p><p>​ The paper "Instant Neural Graphics Primitives with a MultiresolutionHash Encoding" introduces a novel approach called "Instant NeuralGraphics Primitives (Instant-NGP)" with the integration of amultiresolution hash encoding. This method aims to improve theefficiency and performance of existing neural rendering algorithms.</p><p>The core idea of the paper is to utilize multiresolution hashencoding to encode the geometry and material information of scenes,enabling efficient rendering of complex 3D scenes. Instant-NGPrepresents scenes as a collection of basic graphics primitives (such asspheres, cubes, etc.) and associates each primitive with itscorresponding geometry and material information using hash encoding,resulting in an efficient scene representation and renderingprocess.</p><p>In the experimental section, the paper demonstrates the outstandingperformance of the Instant-NGP method in various 3D scene renderingtasks. Compared to traditional ray-tracing-based rendering algorithms,Instant-NGP achieves significant improvements in computation speed andmemory usage. Furthermore, Instant-NGP exhibits high scalability andversatility, making it suitable for a wide range of 3D scene renderingtasks.</p><figure><img src="1.jpg" alt="framework" /><figcaption aria-hidden="true">framework</figcaption></figure><figure><img src="2.jpg" alt="framework" /><figcaption aria-hidden="true">framework</figcaption></figure><p>​ After read the paper, I run it’s code successfully, but it’s codewritten by CUDA, I just learned how to use.</p><p>The paper "Shape, Pose, and Appearance from a Single Image viaBootstrapped Radiance Field Inversion" proposes an iterativeoptimization framework based on bootstrapped radiance field inversionfor estimating the 3D shape, pose, and appearance of objects from asingle image. The method iteratively optimizes the estimated radiancefield and object geometry while utilizing a deep neural network toestimate the object's appearance. The main advantage of this method isits ability to estimate the 3D shape, pose, and appearance of objectsfrom a single image without requiring multiple images or priorknowledge.</p><p>​ Specifically, the method first uses an initial radiance field togenerate a set of virtual images, which are then compared to theoriginal image to compute an error function. Next, the method updatesthe estimated radiance field and object geometry using the errorfunction and employs a deep neural network to estimate the object'sappearance. By iteratively optimizing the estimated radiance field andobject geometry while utilizing a deep neural network to estimate theobject's appearance, the method achieves the goal of estimating the 3Dshape, pose, and appearance of objects from a single image.</p><p>​ The method is evaluated on multiple datasets, demonstrating itseffectiveness in estimating the 3D shape, pose, and appearance ofobjects from a single image. Additionally, data augmentation techniquesand loss functions are used to improve the accuracy of theestimations.</p><p>​ The paper’s code has not run successfully, and I will debug the codein the next week.</p>]]></content>
    
    
    <categories>
      
      <category>每周回顾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结&amp;反思</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基础知识</title>
    <link href="/posts/14876/"/>
    <url>/posts/14876/</url>
    
    <content type="html"><![CDATA[<h4 id="基本方法">基本方法</h4><ol type="1"><li>np(torch).stack([], axis=)函数</li></ol><p>作用：是将一组数组沿着新的轴堆叠起来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>a = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], <br>              [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]])<br><br>b = np.array([[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>],<br>              [<span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>]])<br><br>c = np.stack([a, b], <span class="hljs-number">0</span>) <span class="hljs-comment"># axis = 0</span><br><br><span class="hljs-comment"># 按照原数组直接堆叠</span><br><span class="hljs-comment"># array([[[ 1,  2,  3],</span><br><span class="hljs-comment">#         [ 4,  5,  6]],</span><br><br><span class="hljs-comment">#         [[ 7,  8,  9],</span><br><span class="hljs-comment">#         [10, 11, 12]]])</span><br><br>c = np.stack([a, b], <span class="hljs-number">1</span>) <span class="hljs-comment"># axis = 1</span><br><br><span class="hljs-comment"># 根据列表中数组的行堆叠</span><br><span class="hljs-comment"># array([[[ 1,  2,  3],</span><br><span class="hljs-comment">#         [ 7,  8,  9]],</span><br><br><span class="hljs-comment">#        [[ 4,  5,  6],</span><br><span class="hljs-comment">#         [10, 11, 12]]])</span><br><br>c = np.stack([a, b], <span class="hljs-number">2</span>) <span class="hljs-comment"># axis = 2</span><br><br><span class="hljs-comment"># 根据列表中数组的列d</span><br><span class="hljs-comment"># array([[[ 1,  7],</span><br><span class="hljs-comment">#         [ 2,  8],</span><br><span class="hljs-comment">#         [ 3,  9]],</span><br><br><span class="hljs-comment">#        [[ 4, 10],</span><br><span class="hljs-comment">#         [ 5, 11],</span><br><span class="hljs-comment">#         [ 6, 12]]])</span><br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>np.meshgrid()</li></ol><p><code>np.meshgrid</code>是一个函数，用于生成多维网格矩阵。它接受多个一维张量作为输入，并返回与输入张量数相同的输出张量列表，每个输出张量包含相应维度中输入张量值的重复。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 二维</span><br>x = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]) <span class="hljs-comment"># 3</span><br>y = torch.tensor([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>])<span class="hljs-comment"># 2</span><br><br>X, Y = np.meshgrid(x, y)<br><span class="hljs-built_in">print</span>(X)<br><span class="hljs-comment"># tensor([[1, 2, 3],</span><br><span class="hljs-comment">#         [1, 2, 3]])</span><br><br><span class="hljs-built_in">print</span>(Y)<br><span class="hljs-comment"># tensor([[4, 4, 4],</span><br><span class="hljs-comment">#         [5, 5, 5]])</span><br><br><span class="hljs-comment"># 三维</span><br>z = torch.tensor([<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>])<br><br>X,Y,Z = np.meshgrid(x,y,z)<br><br><span class="hljs-built_in">print</span>(X.shape, Y.shape, Z.shape)<br><span class="hljs-comment"># torch.Size([2, 3, 3]) torch.Size([2, 3, 3]) torch.Size([2, 3, 3])</span><br><br><span class="hljs-built_in">print</span>(X)  <span class="hljs-comment"># 2*3*3</span><br><span class="hljs-comment"># tensor([[[1, 2, 3],</span><br><span class="hljs-comment">#          [1, 2, 3],</span><br><span class="hljs-comment">#          [1, 2, 3]],</span><br><br><span class="hljs-comment">#         [[1, 2, 3],</span><br><span class="hljs-comment">#          [1, 2, 3],</span><br><span class="hljs-comment">#          [1, 2, 3]]])</span><br><br><span class="hljs-built_in">print</span>(Y)<br><span class="hljs-comment"># tensor([[[4, 4, 4],</span><br><span class="hljs-comment">#          [5, 5, 5],</span><br><span class="hljs-comment">#          [6, 6, 6]],</span><br><br><span class="hljs-comment">#         [[4, 4, 4],</span><br><span class="hljs-comment">#          [5, 5, 5],</span><br><span class="hljs-comment">#          [6, 6, 6]]])</span><br><br><span class="hljs-built_in">print</span>(Z)<br><span class="hljs-comment"># tensor([[[6, 6, 6],</span><br><span class="hljs-comment">#          [6, 6, 6],</span><br><span class="hljs-comment">#          [6, 6, 6]],</span><br><br><span class="hljs-comment">#         [[7, 7, 7],</span><br><span class="hljs-comment">#          [7, 7, 7],</span><br><span class="hljs-comment">#          [7, 7, 7]]])</span><br><br><br></code></pre></td></tr></table></figure><ol start="3" type="1"><li>torch.meshgrid()</li></ol><p><code>torch.meshgrid</code>是一个函数，用于生成多维网格矩阵。它接受多个一维张量作为输入，并返回与输入张量数相同的输出张量列表，每个输出张量包含相应维度中输入张量值的重复。torch和numpy的作用是一样的，但是其x,y的坐标有所区别。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 二维</span><br>x = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]) <span class="hljs-comment"># 3</span><br>y = torch.tensor([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>])<span class="hljs-comment"># 2</span><br><br>X, Y = torch.meshgrid(x, y)<br><br><span class="hljs-built_in">print</span>(X) <span class="hljs-comment"># i j </span><br><br><span class="hljs-comment"># tensor([[1, 1],</span><br><span class="hljs-comment">#         [2, 2],</span><br><span class="hljs-comment">#         [3, 3]])</span><br><br><span class="hljs-built_in">print</span>(Y)<br><span class="hljs-comment"># tensor([[4, 5],</span><br><span class="hljs-comment">#         [4, 5],</span><br><span class="hljs-comment">#         [4, 5]])</span><br><br><span class="hljs-comment">#三维</span><br>z = torch.tensor([<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>]) <span class="hljs-comment"># 3   </span><br><br>X,Y,Z = torch.meshgrid(x,y,z)<br><br><span class="hljs-built_in">print</span>(X)<span class="hljs-comment"># 3*2*3</span><br><span class="hljs-comment"># tensor([[[1, 1, 1],</span><br><span class="hljs-comment">#          [1, 1, 1]],</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment">#         [[2, 2, 2],</span><br><span class="hljs-comment">#          [2, 2, 2]],</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment">#         [[3, 3, 3],</span><br><span class="hljs-comment">#          [3, 3, 3]]])</span><br><br><span class="hljs-built_in">print</span>(Y)<br><span class="hljs-comment"># tensor([[[4, 4, 4],</span><br><span class="hljs-comment">#          [5, 5, 5]],</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment">#         [[4, 4, 4],</span><br><span class="hljs-comment">#          [5, 5, 5]],</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment">#         [[4, 4, 4],</span><br><span class="hljs-comment">#          [5, 5, 5]]])</span><br><br><span class="hljs-built_in">print</span>(Z)<br><span class="hljs-comment"># tensor([[[6, 7, 8],</span><br><span class="hljs-comment">#          [6, 7, 8]],</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment">#         [[6, 7, 8],</span><br><span class="hljs-comment">#          [6, 7, 8]],</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment">#         [[6, 7, 8],</span><br><span class="hljs-comment">#          [6, 7, 8]]])</span><br></code></pre></td></tr></table></figure><ol start="4" type="1"><li>torch.norm()</li></ol><p><code>torch.norm()</code>函数用于计算张量的范数。它可以计算给定维度上的向量范数或矩阵范数，并返回一个张量。默认为2范数，可以设置p指定范数。同时可以设置<code>keepdim</code>来决定是否保留原先的维度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># Example 1: Compute the L2-norm of a vector</span><br>x = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], dtype=torch.float32)<br>l2_norm = torch.norm(x, p=<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(l2_norm)   <span class="hljs-comment"># Output: tensor(3.7417)</span><br><br><span class="hljs-comment"># Example 2: Compute the Frobenius norm of a matrix</span><br>A = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]], dtype=torch.float32)<br>fro_norm = torch.norm(A, p=<span class="hljs-string">&#x27;fro&#x27;</span>)<br><span class="hljs-built_in">print</span>(fro_norm)  <span class="hljs-comment"># Output: tensor(5.4772)</span><br><br><span class="hljs-comment"># Example 3: Compute the L1-norm of a vector along a specific dimension</span><br>B = torch.tensor([[<span class="hljs-number">1</span>, -<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [-<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, -<span class="hljs-number">6</span>]], dtype=torch.float32)<br>l1_norm = torch.norm(B, p=<span class="hljs-number">1</span>, dim=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(l1_norm)   <span class="hljs-comment"># Output: tensor([6., 15.])</span><br><br></code></pre></td></tr></table></figure><ol start="5" type="1"><li>torch.gather()</li></ol><p>作用：沿着由dim指定的轴收集数值，作为取值的索引。</p><p><code>torch.gather(input, dim, index, *, sparse_grad=False, out=None) → Tensor</code></p><blockquote><p>input (Tensor) – 目标变量，输入 dim (int) – 需要沿着取值的坐标轴index (LongTensor) – 需要取值的索引矩阵 sparse_grad (bool,optional) –如果为真，输入将是一个稀疏张量 out (Tensor, optional) – 输出</p><p>index矩阵作为当前轴的索引，剩下的轴依旧按照顺序排序[0-n]</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># dim = 0</span><br><br><span class="hljs-built_in">input</span> = [<br>    [<span class="hljs-number">0.0</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>],<br>    [<span class="hljs-number">1.0</span>, <span class="hljs-number">1.1</span>, <span class="hljs-number">1.2</span>, <span class="hljs-number">1.3</span>],<br>    [<span class="hljs-number">2.0</span>, <span class="hljs-number">2.1</span>, <span class="hljs-number">2.2</span>, <span class="hljs-number">2.3</span>]<br>]<span class="hljs-comment">#shape [3,4]</span><br><span class="hljs-built_in">input</span> = torch.tensor(<span class="hljs-built_in">input</span>)<br>length = torch.LongTensor([<br>    [<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>],<br>    [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>    [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],<br>    [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>]<br>])<span class="hljs-comment">#[4,4]</span><br>out = torch.gather(<span class="hljs-built_in">input</span>, dim=<span class="hljs-number">0</span>, index=length)<br><span class="hljs-built_in">print</span>(out)<br><br><span class="hljs-comment"># 结果</span><br><span class="hljs-comment"># tensor([[2.0000, 2.1000, 2.2000, 2.3000],</span><br><span class="hljs-comment">#         [1.0000, 1.1000, 1.2000, 1.3000],</span><br><span class="hljs-comment">#         [0.0000, 0.1000, 0.2000, 0.3000],</span><br><span class="hljs-comment">#         [0.0000, 1.1000, 2.2000, 0.3000]])</span><br><br></code></pre></td></tr></table></figure><p><span class="math display">\[取值索引矩阵=\left[\begin{array}{llll}X_{20} &amp; X_{21} &amp; X_{22} &amp; X_{23} \\X_{10} &amp; X_{11} &amp; X_{12} &amp; X_{13} \\X_{00} &amp; X_{01} &amp; X_{02} &amp; X_{03} \\X_{00} &amp; X_{11} &amp; X_{22} &amp; X_{03}\end{array}\right]\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># dim = 1</span><br><br><span class="hljs-built_in">input</span> = [<br>    [<span class="hljs-number">0.0</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>],<br>    [<span class="hljs-number">1.0</span>, <span class="hljs-number">1.1</span>, <span class="hljs-number">1.2</span>, <span class="hljs-number">1.3</span>],<br>    [<span class="hljs-number">2.0</span>, <span class="hljs-number">2.1</span>, <span class="hljs-number">2.2</span>, <span class="hljs-number">2.3</span>]<br>]<span class="hljs-comment">#shape [3,4]</span><br><span class="hljs-built_in">input</span> = torch.tensor(<span class="hljs-built_in">input</span>)<br>length = torch.LongTensor([<br>    [<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>],<br>    [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>    [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>]<br>])<span class="hljs-comment">#[3,4]</span><br>out = torch.gather(<span class="hljs-built_in">input</span>, dim=<span class="hljs-number">1</span>, index=length)<br><span class="hljs-built_in">print</span>(out)<br><br><br><span class="hljs-comment"># 结果</span><br><span class="hljs-comment"># tensor([[0.2000, 0.2000, 0.2000, 0.2000],</span><br><span class="hljs-comment">#         [1.1000, 1.1000, 1.1000, 1.1000],</span><br><span class="hljs-comment">#         [2.0000, 2.1000, 2.2000, 2.0000]])</span><br><br></code></pre></td></tr></table></figure><p><span class="math display">\[取值索引矩阵 =\left[\begin{array}{llll}\mathrm{X}_{02} &amp; \mathrm{X}_{02} &amp; \mathrm{X}_{02} &amp;\mathrm{X}_{02} \\\mathrm{X}_{11} &amp; \mathrm{X}_{11} &amp; \mathrm{X}_{11} &amp;\mathrm{X}_{11} \\\mathrm{X}_{20} &amp; \mathrm{X}_{21} &amp; \mathrm{X}_{22} &amp;\mathrm{X}_{20}\end{array}\right]\]</span></p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>每周总结(23.05.15-23.05.19)</title>
    <link href="/posts/20521/"/>
    <url>/posts/20521/</url>
    
    <content type="html"><![CDATA[<div align = "center"><H3>工作总结</div><p><strong>日期：2023.05.15-2023.05.19</strong></p><h4 id="paper">1.Paper</h4><p><strong>Title：</strong><code>NeRF++: Analyzing and Improving Neural Radiance Fields.</code></p><p><strong>总结：</strong>这篇论文主要针对神经辐射场(NeRF_方法进行了分析和改进。NeRF是一种用于3D重建和渲染的深度学习模型，它通过建立场景中每个点的颜色和密度函数来表示3D信息，并可以生成极高质量的逼真图像。但该方法在训练和测试时存在一些问题，如计算时间和内存开销大、不稳定性等。</p><blockquote><p>为此，NeRF++通过引入多项新技术对NeRF进行改进，包括：</p><ol type="1"><li>首先，文章提出了一个自适应采样策略，使得更多的采样点可以在物体表面上，从而减少了无效样本，提高了模型的精度。</li><li>其次，文章通过增加正则化项和提高网络深度，在保持模型性能的同时，显著减少了内存和计算时间的消耗。</li><li>另外，文章还提出了一种新的光源采样方法，可以在较短的时间内对复杂光照情况下的场景进行快速且准确的渲染。</li><li>最后，文章还提出了一种自动曝光控制（auto-exposurecontrol）方法，可以帮助模型更好地适应不同的场景光照情况。</li></ol><p>NeRF++的实验结果表明，该方法在精度和效率方面都有所提高，可以很好地解决NeRF方法存在的问题。这些改进使得NeRF++方法成为一个更加稳定、可扩展、适用于复杂场景的深度学习3D重建和渲染工具，具有广泛的应用前景。#### 2.Code</p></blockquote><p>继续研究学习NeRF-Pytorch代码，对其进行逐一调试分析，了解NeRF的具体运作原理与其使用的一些方法，进度：3/4。搭建NeRF++环境，并成功运行其代码，得到结果。</p><h4 id="other">3.Other</h4><ol type="1"><li><p>通过对代码的调试，学习到了一些新的知识，同时也对论文中提出的一些方法有了更加深刻的了解。</p><ul><li><p>位置编码</p><p>NeRF在将位置信息输入到MLP中进行预测前，对位置信息进行了位置编码，从而解决对图像中高频信息预测不准确，得到了结果模糊的问题。</p><p>NeRF通过一系列的[sin,cos]函数编码位置信息，将位置信息从3维增加到60维，如何再作为MLP网络的输入。</p></li><li><p>MLP网络</p><p>NeRF有一个8层的MLP网络，第一层的输入维度为60，输出为256，<code>第五层为跨越连接层</code>，其输入的维度额外增加60，输出仍然保持256，该方法可以增强模型的表示能力和泛化性能，并减少训练时间和复杂度，这8层线性连接层的激活函数都为ReLU。再经历8层连接层后，额外增加一层256特征的线性层，其输出维度为128，用来输出点的密度density，同时这一层加入方向坐标维度用来输出RGB信息。</p></li></ul></li><li><p>学习了一些YOLO目标检测的知识。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>每周回顾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结&amp;反思</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>每周总结(23.05.08-23.05.12)</title>
    <link href="/posts/48714/"/>
    <url>/posts/48714/</url>
    
    <content type="html"><![CDATA[<div align = "center"><H3>工作总结</div><p><strong>日期：2023.05.08-2023.05.12</strong></p><h4 id="paper">1.Paper</h4><p><strong>Title：</strong><code>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</code></p><p><strong>总结：</strong>NeRF是一种基于神经网络的视图综合方法，可以从有限数量的输入视图合成高质量、高分辨率的新视图。</p><blockquote><ul><li>采集输入数据：从不同角度拍摄一组图片，同时记录相机参数和深度值信息。</li><li>输入：5D坐标(3D位置坐标+2D方向坐标)</li><li>输出：通过MLP多层感知机转换成对应的($RGB$)</li><li>预测新视角：对于给定的任意视角，计算该视角与每个空间位置的交点，并利用预先训练好的神经辐射场计算颜色和透明度值。最后，基于光线投射算法，将这些颜色值合成为一张新的图像。</li></ul></blockquote><h4 id="code">2.Code</h4><p>学习NeRF-pytorch代码,已经看了1/4的代码，了解了代码的输入，数据的转换以及坐标轴的转换。</p><h4 id="other">3.Other</h4><p>学习了视图变换与相机参数的一些基本知识。</p><p>了解了视图变换，包括</p><blockquote><ul><li>相机变换(camera/view transformation)</li><li>投影变换(projection transformation)</li><li>视口变换(viewport transformation)</li></ul></blockquote><ol type="1"><li>投影变换是NeRF中的重要变换，包括</li></ol><blockquote><ul><li>正交投影(orthographic projection)</li><li>透视投影(perspection projection)</li></ul></blockquote><p>它们的变换矩阵分别如下：</p><p><strong>透视投影矩阵：</strong> <span class="math display">\[M_{persp \to -ortho} = P=\left[\begin{array}{cccc}n &amp; 0 &amp; 0&amp; 0 \\0 &amp; n &amp; 0 &amp; 0 \\0 &amp; 0 &amp; n+f &amp; -nf \\0&amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span> <strong>正交投影矩阵：</strong> <span class="math display">\[M_{orth}=\left[\begin{array}{cccc}\frac{2}{l-r} &amp; 0 &amp; 0 &amp; 0 \\0 &amp; \frac{2}{b-t}&amp; 0 &amp; 0 \\0 &amp; 0 &amp; \frac{2}{n-f} &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\left[\begin{array}{cccc}1 &amp; 0 &amp; 0 &amp; -\frac{r+l}{2} \\0 &amp; 1 &amp; 0 &amp; -\frac{t+b}{2} \\0 &amp; 0 &amp; 1 &amp; -\frac{n+f}{2} \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]=\left[\begin{array}{cccc}\frac{2}{l-r} &amp; 0 &amp; 0 &amp; -\frac{r+l}{2} \\0 &amp; \frac{2}{b-t}&amp; 0 &amp; -\frac{t+b}{2} \\0 &amp; 0 &amp; \frac{2}{n-f} &amp; -\frac{n+f}{2} \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><ol start="2" type="1"><li><p>相机参数</p><p><strong>相机外参T:</strong> <span class="math display">\[T=\left[\begin{array}{cc}R &amp; t \\0^T &amp; 1\\\end{array}\right]\]</span></p><p><strong>相机内参K:</strong> <span class="math display">\[K = \left|\begin{array}{ccc}    f_x &amp; 0 &amp; u_0 \\    0 &amp; f_y &amp; v_0 \\    0 &amp; 0  &amp; 1    \end{array}\right|\]</span></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>每周回顾</category>
      
    </categories>
    
    
    <tags>
      
      <tag>总结&amp;反思</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NeRF源码解读</title>
    <link href="/posts/15494/"/>
    <url>/posts/15494/</url>
    
    <content type="html"><![CDATA[<p>imgs : 根据 .json 文件加载到的所有图像数据。（N，H，W，4）N 代表用于train、test、val 的总数量(4:RGBβ) poses : 转置矩阵。（N，4，4）render_poses : 用于测试的 pose 。（40，4，4） i_split : [[0:train],[train:val], [val:test]]</p><p><em>γ</em>(<em>p</em>)=(sin(20<em>πp</em>),cos(20<em>πp</em>),⋯,sin(2<em>L</em>−1<em>πp</em>),cos(2<em>L</em>−1<em>πp</em>))</p><h4 id="参数">参数</h4><p>images: (138, 400, 400, 4), 图像总数, 高宽分别为400, 400,4通道(RGBA)</p><p>poses: (138, 4, 4), 138个图像对应的相机位姿(4*4的c2w变换矩阵)</p><p>render_poses: (40, 4, 4), 40个用于测试的位姿(4*4的c2w变换矩阵)</p><p>hwf: (3,), 图像的高宽和焦距</p><p>i_split: train[0:100], val[0:13], tea-st[0:25]图像的索引</p><p>include_input: 编码结果是否包括原始坐标</p><p>input_dims: 输入数据的维度</p><p>max_freq_log2: 位置编码函数最大频率 L-1</p><p>num_freqs: 位置编码函数的频率数 L</p><p>log_sampling: 频率是否使用指数增长</p><p>periodic_fns: 编码函数[sin, cos]</p><p>embed_fns: 存储编码函数</p><p>out_dim: 存储编码后的总维度</p><p>embed_fn: 位置编码器</p><p>input_ch: 编码后的总维度(作为MLP输入时的维度)</p><p>use_viewdirs: 使用完整的5D坐标</p><p>embeddirs_fn: 存储方向坐标编码函数</p><p>input_ch_views: 编码后的总维度(方向坐标)</p><p>netdepth: 网络深度 8层</p><p>netwidth: 网络宽度 256 粗糙网络(coarse network)上取 64 点,精细网络(fine network)上取 64 + 128 = 192个点, 一共256个点</p><p>input_ch: 位置坐标输入维度x 63</p><p>output_ch: 输出维度 5 (RGB + density)</p><p>skips: 跳跃连接层 第五层 输入向量维度为319</p><p>input_ch_views: 视角方向输入维度d 27</p><p>use_viewdirs: 是否使用视角方向</p><p>pst_linears: 存储MLP的8个隐藏层(包含一个跨越层，319个特征输入)</p><p>views_linears:存储一个额外的线性层(用于输入方向坐标信息，输出密度density，输入256+27，输出128)</p><p>netdepth_fine: 精细网络深度 8</p><p>netwidth_fine: 精细网络特征 256</p><p>netchunk: 网络批量处理的数量 1024<em>64 rays </em> points</p><p>N_rand: 批量大小(每个梯度的随机射线数量)</p><p>N_samples: 每条射线的粗糙网络采样点数</p><p>N_importance: 每条射线额外的精细网络采样点数</p>]]></content>
    
    
    <categories>
      
      <category>NeRF</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NeRF</tag>
      
      <tag>源码解读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>相机参数</title>
    <link href="/posts/63805/"/>
    <url>/posts/63805/</url>
    
    <content type="html"><![CDATA[<h3 id="相机坐标系">1.相机坐标系</h3><p><img src="1.jpg" /></p><p>相机中有四个坐标系</p><ul><li>世界坐标系：可以任意指定<spanclass="math inline">\(x_w\)</span>轴和<spanclass="math inline">\(y_w\)</span>轴</li><li>相机坐标系：原点位于小孔，z轴与光轴重合，<spanclass="math inline">\(x_c\)</span>轴和<spanclass="math inline">\(y_c\)</span>轴平行投影面</li><li>图像坐标系：原点位于光轴和投影面的交点，<spanclass="math inline">\(x_p\)</span>轴和<spanclass="math inline">\(y_p\)</span>轴平行投影面</li><li>像素坐标系：从小孔向投影面方向看，投影面的左上角为原点，uv轴和投影面两边重合</li></ul><p>一般来说，标定的过程分为两个部分：</p><ul><li>第一步是从世界坐标系转为相机坐标系，这一步是三维点到三维点的转换，包括R，T（相机外参，确定了相机在某个三维空间中的位置和朝向）等参数</li><li>第二部是从相机坐标系转为成像平面坐标系（像素坐标系），这一步是三维点到二维点的转换，包括K（相机内参,是对相机物理特性的近似）等参数</li></ul><h3 id="齐次坐标系">2.齐次坐标系</h3><p>齐次坐标(Homogeneouscoordinate)就是将一个原本是n维的向量用一个n+1维向量来表示，是指一个用于投影几何里的坐标系统，如同用于欧氏几何里的笛卡儿坐标一般。给出点的齐次表达式[XY H]，就可求得其二维笛卡尔坐标，即$ [ X : Y : H ] = [ : : ] = [ X : Y :1 ]$， 这个过程称为归一化处理。在几何意义上，相当于把发生在三维空间的变换限制在H=1的平面内。同时在齐次坐标系下<code>(1, 2, 3), (2, 4, 6),(4, 8, 12)</code>对应同一个欧几里得点<code>(1/3, 2/3)</code>，因此这些点是同一个点，这使得在透视空间里，两条平行线可以相交得到了解决(近大远小)。</p><p><img src="3.png?100x100" /></p><p>许多图形应用涉及到几何变换，主要包括<strong>平移、旋转、缩放</strong>。以矩阵表达式来计算这些变换时，平移是矩阵相加，旋转和缩放则是矩阵相乘，引入齐次坐标的目的主要是合并矩阵运算中的乘法和加法。引入齐次坐标后，平移、旋转、缩放可以表示为：<span class="math display">\[\begin{align}   &amp; 平移变换：    \left[\begin{array}{lll}    x^{\prime} &amp; y^{\prime} &amp; 1    \end{array}\right]=\left[\begin{array}{lll}    x &amp; y &amp; 1    \end{array}\right]\left|\begin{array}{ccc}    1 &amp; 0 &amp; 0 \\    0 &amp; 1 &amp; 0 \\    \mathrm{~d} x &amp; \mathrm{~d} y &amp; 1    \end{array}\right|    \quad \\   &amp; 旋转变换：    \left[\begin{array}{lll}    x^{\prime} &amp; y^{\prime} &amp; 1    \end{array}\right]=\left[\begin{array}{lll}    x &amp; y &amp; 1    \end{array}\right]\left|\begin{array}{ccc}    \cos{\theta} &amp; \sin{\theta} &amp; 0 \\    -\sin{\theta} &amp; \cos{\theta} &amp; 0 \\    0 &amp; 0  &amp; 1    \end{array}\right|    \quad \\   &amp; 缩放变换：    \left[\begin{array}{lll}    x^{\prime} &amp; y^{\prime} &amp; 1    \end{array}\right]=\left[\begin{array}{lll}    x &amp; y &amp; 1    \end{array}\right]\left|\begin{array}{ccc}    S_x &amp; 0 &amp; 0 \\    0 &amp; S_y &amp; 0 \\    0 &amp; 0  &amp; 1    \end{array}\right|\end{align}\]</span></p><h3 id="相机内外参数">3.相机内外参数</h3><ol type="1"><li><p>相机外部参数</p><blockquote><ul><li>3个旋转矩阵参数R(绕x,y,z轴)</li><li>3个平移矩阵参数T(沿x,y,z轴)</li></ul></blockquote><p>camera to world(c2w)：</p><p>设<span class="math inline">\(P_c\)</span>为<spanclass="math inline">\(P\)</span>在相机坐标系下的坐标，<spanclass="math inline">\(P_w\)</span>是其在世界坐标系下的坐标，可以使用一个旋转矩阵<code>R</code>和一个平移向量<code>t</code>，将<spanclass="math inline">\(P_c\)</span>变换为<spanclass="math inline">\(P_w\)</span>: <span class="math display">\[P_c = RP_w + t\]</span>其中<code>R</code>是一个3×3的旋转矩阵，<code>t</code>是3×1的平移向量，一下为齐次坐标形式：<span class="math display">\[\left[\begin{array}{c}X_{c} \\Y_{c} \\Z_{c}\end{array}\right]=\left[\begin{array}{lll}R_{11} &amp; R_{12} &amp; R_{13} \\R_{21} &amp; R_{22} &amp; R_{23} \\R_{31} &amp; R_{32} &amp; R_{33}\end{array}\right]\left[\begin{array}{l}X_{w} \\Y_{w} \\Z_{w}\end{array}\right]+\left[\begin{array}{l}t_{1} \\t_{2} \\t_{3}\end{array}\right]\quad \Rightarrow  \quad\left[\begin{array}{c}X_{c} \\Y_{c} \\Z_{c} \\1\end{array}\right]=\left[\begin{array}{cccc}R_{11} &amp; R_{12} &amp; R_{13} &amp; t_{1} \\R_{21} &amp; R_{22} &amp; R_{23} &amp; t_{2} \\R_{31} &amp; R_{32} &amp; R_{33} &amp; t_{3} \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\left[\begin{array}{c}X_{w} \\Y_{w} \\Z_{w} \\1\end{array}\right]\]</span></p><p>将旋转矩阵<code>R</code>和平移向量<code>t</code>带入： <spanclass="math display">\[\left[\begin{array}{c}X_{c} \\Y_{c} \\Z_{c} \\1\end{array}\right]=\left[\begin{array}{cc}R &amp; t \\0^T &amp; 1\\\end{array}\right]\left[\begin{array}{c}X_{w} \\Y_{w} \\Z_{w} \\1\end{array}\right]\]</span> 上面就推导出了相机的<code>外部参数T</code>: <spanclass="math display">\[T=\left[\begin{array}{cc}R &amp; t \\0^T &amp; 1\\\end{array}\right]\]</span></p></li><li><p>相机内部参数</p><p>内参矩阵K为： <span class="math display">\[K = \left|\begin{array}{ccc}    f_x &amp; 0 &amp; u_0 \\    0 &amp; f_y &amp; v_0 \\    0 &amp; 0  &amp; 1    \end{array}\right|\]</span> <span class="math inline">\(f_x=\frac{f}{d_x} \:,f_y=\frac{f}{d_y}\)</span></p><ul><li><p>f：焦距，单位毫米</p></li><li><p>dx：像素x方向宽度，单位毫米(一个像素在感光板上是多少毫米)</p></li><li><p>f/dx：使用像素来描述x轴方向焦距的长度</p></li><li><p>f/dy：使用像素来描述y轴方向焦距的长度</p></li><li><p>u0,v0,主点的实际位置，单位也是像素</p></li></ul><blockquote><p>相机中心射出的一条光线在成像平面上的投影点。它也被称为“主光轴交点”或“光心”。</p></blockquote></li></ol><h3 id="参考">参考</h3><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><ahref="https://www.cnblogs.com/wangguchangqing/p/8126333.html#autoid-0-5-0">SLAM入门之视觉里程计(2)：相机模型(内参数，外参数)</a><a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>计算机图形学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图形学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>视图变换 Viewing transformation</title>
    <link href="/posts/64372/"/>
    <url>/posts/64372/</url>
    
    <content type="html"><![CDATA[<h3 id="视图变换-viewing-transformation">1.视图变换 ViewingTransformation</h3><p>视图变换的目的是将三维空间中的点<span class="math inline">\((x, y,z)\)</span>(在世界坐标系中)映射到平面图像中(二维坐标系)，以像素为基本表示单位。类似通过相机拍照得到一张相片。视图变换主要包括三个步骤：</p><blockquote><ul><li>相机变换(camera/view transformation)</li><li>投影变换(projection transformation)</li><li>视口变换(viewport transformation)</li></ul></blockquote><figure><img src="6.png" alt="坐标系定义" /><figcaption aria-hidden="true">坐标系定义</figcaption></figure><h3 id="相机变换-camera-transformation">2.相机变换 CameraTransformation</h3><figure><img src="1.jpg?100×100" alt="相机坐标系移动" /><figcaption aria-hidden="true">相机坐标系移动</figcaption></figure><p>相机变换的目的是得到所有可是物体与相机的相对位置，通常包括平移、旋转、缩放。</p><p>规定相机拍摄方向朝向-Z，相机的位置位于e，相机的正上方用向量t来表示，相机的朝向用g表示，<spanclass="math inline">\(\overrightarrow{e}=(x_e, y_e,z_e)\)</span>。首先将相机点平移至世界坐标原点，平移矩阵为： <spanclass="math display">\[T_{\text {view }}=\left[\begin{array}{cccc}1 &amp; 0 &amp; 0 &amp; -x_{e} \\0 &amp; 1 &amp; 0 &amp; -y_{e} \\0 &amp; 0 &amp; 1 &amp; -z_{e} \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span>然后，对相机坐标进行旋转变换，使其与世界坐标系重合。需要将相机朝向g旋转到-Z轴上，t旋转到Y轴上，再通过g叉乘t的方向旋转到X。然而，这个旋转对应的旋转矩阵并不容易写出，但是如果将Z旋转到-g，将Y旋转到t，将X旋转到g叉积t的方向，直接取旋转矩阵的逆矩阵<spanclass="math inline">\(R^{-1}=(u,v,w)\)</span>即可<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="[旋转矩阵(Rotate Matrix)的性质分析](https://www.cnblogs.com/caster99/p/4703033.html)">[1]</span></a></sup>，其中<spanclass="math inline">\(u=\hat{g} \times \hat{t},v=\hat{t},w =-\hat{g}\)</span>，因此旋转矩阵的逆矩阵和旋转矩阵可以写成： <spanclass="math display">\[R_{\text {view }}^{-1}=\left[\begin{array}{cccc}x_{\hat{g} \times \hat{t}} &amp; x_{t} &amp; x_{-g} &amp; 0 \\y_{\hat{g} \times \hat{t}} &amp; y_{t} &amp; y_{-g} &amp; 0 \\z_{\hat{g} \times \hat{t}} &amp; z_{t} &amp; z_{-g} &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\quad \Rightarrow  \quadR_{\text {view }}=\left[\begin{array}{cccc}x_{\hat{g} \times \hat{t}} &amp; y_{\hat{g} \times \hat{t}}  &amp;z_{\hat{g} \times \hat{t}}  &amp; 0 \\x_{t} &amp; y_{t} &amp; z_{t} &amp; 0 \\x_{-g} &amp;  y_{-g} &amp; z_{-g} &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span> 所以最终的相机变换矩阵为：<span class="math inline">\(M_{\text{view }}=R_{\text {view }}T_{\text {view }}\)</span>。</p><blockquote><p>PS:从世界坐标系变换到相机坐标系属于刚体变换：即物体不会发生形变，只需要进行旋转和平移。</p></blockquote><h3 id="投影变换-projection-transformation">3.投影变换 ProjectionTransformation</h3><figure><img src="3.jpg?100×100" alt="投影变换" /><figcaption aria-hidden="true">投影变换</figcaption></figure><p>投影变换的目的是将相机空间中的点映射到<spanclass="math inline">\([-1, 1]^3\)</span>的立方体上，并且相机<spanclass="math inline">\(e=0\)</span>的射线穿过里立方体中心。这样的立方体叫做规范视图体(CanonicalView Volume)或者标准化设备坐标系(normalized devicecoordinates)。投影变换可以分为两个步骤进行：</p><blockquote><ul><li>正交投影(orthographic projection)</li><li>透视投影(perspection projection)</li></ul></blockquote><ol type="1"><li><p>透视投影</p><p>透视投影就是最类似人眼所看东西的方式，遵循近大远小，通过投影到平面来进行解释。</p><figure><img src="4.png?100×100" alt="透视投影" /><figcaption aria-hidden="true">透视投影</figcaption></figure><p>图中的原点代表视点，<code>Z=-n</code>表示近平面(投影平面)，<code>Z=-z</code>表示远平面，需要进行压缩。利用相似三角形可以计算出<spanclass="math inline">\(y^{&#39;}=\frac{n}{z}y,x^{&#39;}=\frac{n}{z}x\)</span>，假定透视矩阵为P，我们计算透视投影后的齐次坐标。<span class="math display">\[P\left[\begin{array}{c}x  \\y  \\z  \\1\end{array}\right]=\left[\begin{array}{c}nx  \\ny  \\?  \\z\end{array}\right]\quad \Rightarrow  \quadP=\left[\begin{array}{cccc}n &amp; 0 &amp; 0 &amp; 0 \\0 &amp; n &amp; 0 &amp; 0 \\? &amp; ? &amp; ? &amp; ? \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span>中间的<code>?</code>可以通过远平面<code>Z=-f</code>和近平面<code>Z=-n</code>的值来计算，当<code>Z=-f</code>时，前面的单独<code>?</code>为<spanclass="math inline">\(f^2\)</span>，当<code>Z=-n</code>时，前面的单独<code>?</code>为<spanclass="math inline">\(n^2\)</span>。假设第三行为<spanclass="math inline">\((0,0,A,B)\)</span>，分别带入<code>n</code>和<code>f</code>可以列出两个等式：<span class="math display">\[\begin{array}{l}A_{n}+B=n^{2} \\A_{f}+B=f^{2} \\\end{array}\quad \Rightarrow \quad\begin{array}{l}A=n+f \\B=-nf \\\end{array}\]</span></p><p>最后的透视投影的变换矩阵为： <span class="math display">\[M_{persp \to -ortho} = P=\left[\begin{array}{cccc}n &amp; 0 &amp; 0&amp; 0 \\0 &amp; n &amp; 0 &amp; 0 \\0 &amp; 0 &amp; n+f &amp; -nf \\0&amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span>通过计算可知，远平面通过透视投影矩阵的变换后，该平面会沿着Z轴的反向移动，即远离近平面。</p></li><li><p>正交投影</p><figure><img src="2.jpg?100×100" alt="正交投影" /><figcaption aria-hidden="true">正交投影</figcaption></figure><p>正交投影变换坐标的相对位置都不会改变，所有光线都是平行传播，只需将物体全部转换到<spanclass="math inline">\([-1,1]^3\)</span>的立方体中，主要的操作有平移和旋转。</p><p>通过计算可以求得立方体的中心点为<span class="math inline">\((x_0,y_0, z_0)\)</span>，其中<span class="math inline">\(x_0=-\frac{r+l}{2},y_0=-\frac{t+b}{2},z_0=-\frac{n+f}{2}\)</span>。因此平移矩阵可以表示为:<span class="math display">\[T=\left[\begin{array}{cccc}1 &amp; 0 &amp; 0 &amp; -\frac{r+l}{2} \\0 &amp; 1 &amp; 0 &amp; -\frac{t+b}{2} \\0 &amp; 0 &amp; 1 &amp; -\frac{n+f}{2} \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span>接下来就需要求缩放矩阵，-1到1的间距为2，而物体在各个轴上的间距分别为<spanclass="math inline">\(\:l-r,b-t,n-f\)</span>，因此，在各个轴方向的缩放因子可以表示为<spanclass="math inline">\(S_x=\frac{2}{l-r},S_y=\frac{2}{b-t},S_z=\frac{2}{n-f}\)</span>。所以缩放矩阵可以表示为：<span class="math display">\[S=\left[\begin{array}{cccc}\frac{2}{l-r} &amp; 0 &amp; 0 &amp; 0 \\0 &amp; \frac{2}{b-t}&amp; 0 &amp; 0 \\0 &amp; 0 &amp; \frac{2}{n-f} &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span>计算完两个矩阵之后，可以知道最终的正交投影矩阵为两个矩阵的乘积<spanclass="math inline">\(M_{orth}=S \times T\)</span>: <spanclass="math display">\[M_{orth}=\left[\begin{array}{cccc}\frac{2}{l-r} &amp; 0 &amp; 0 &amp; 0 \\0 &amp; \frac{2}{b-t}&amp; 0 &amp; 0 \\0 &amp; 0 &amp; \frac{2}{n-f} &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\left[\begin{array}{cccc}1 &amp; 0 &amp; 0 &amp; -\frac{r+l}{2} \\0 &amp; 1 &amp; 0 &amp; -\frac{t+b}{2} \\0 &amp; 0 &amp; 1 &amp; -\frac{n+f}{2} \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]=\left[\begin{array}{cccc}\frac{2}{l-r} &amp; 0 &amp; 0 &amp; -\frac{r+l}{2} \\0 &amp; \frac{2}{b-t}&amp; 0 &amp; -\frac{t+b}{2} \\0 &amp; 0 &amp; \frac{2}{n-f} &amp; -\frac{n+f}{2} \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span> 3.投影变换矩阵</p><p>通过上述的两个矩阵的乘积可以得出最终的变换矩阵<spanclass="math inline">\(M_{per} = M_{orhto}M_{persp \to -ortho}\)</span><span class="math display">\[M_{per} =\left[\begin{array}{cccc}\frac{2n}{l-r} &amp; 0 &amp; -\frac{l+r}{l-r} &amp; 0 \\0 &amp; \frac{2n}{b-t}&amp; -\frac{b+t}{b-t} &amp; 0 \\0 &amp; 0 &amp; \frac{n+f}{n-f} &amp; -\frac{2nf}{n-f} \\0 &amp; 0 &amp; 1 &amp; 0\end{array}\right]\]</span></p><h3 id="视口变换-viewport-transformation">4.视口变换 viewporttransformation</h3><p>经过上述变换，可以将任意三维空间中的物体投影到标准立方体上，但是之后还需要投影到<spanclass="math inline">\(2\times2\)</span>的二维平面(栅格图像)上进行显示，高度为H，宽度为W，单位为像素。所以，需要将标准立方体中的中的点，转换到屏幕上，所以还是需要先平移，再缩放，形式同正交矩阵：<span class="math display">\[M_{viewport}=\left[\begin{array}{cccc}\frac{W}{2} &amp; 0 &amp; 0 &amp; \frac{W}{2} \\0 &amp; \frac{H}{2}&amp; 0 &amp; \frac{H}{2} \\0 &amp; 0 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end{array}\right]\]</span></p><blockquote><p>栅格图像(RasterImage)，也称为位图(Bitmap)，是由像素阵列组成的数字图像。在栅格图像中，每个像素都包含一个特定的颜色值或灰度值，以描述图像中相应位置的颜色和亮度。与矢量图形不同，栅格图像是像素化图像，它通常使用像素阵列来表示图像。每个像素都具有一个X和Y坐标，并包含一个或多个数字值来表示其颜色信息。这些数字值通常使用8位或更高位深度来表示，以提供足够的精度来描述图像细节。</p></blockquote></li></ol><blockquote><p>PS:NeRF中只需要进行投影变换。因为NeRF将相对于世界坐标的相机坐标点作为MLP的输入，它也没有使用视口变换，因为信息是从多层感知器(MLP)中隐式查询而不是从测量对象构建的。</p></blockquote><h3 id="参考">参考</h3><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><ahref="https://www.cnblogs.com/caster99/p/4703033.html">旋转矩阵(RotateMatrix)的性质分析</a><a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><ahref="https://zhuanlan.zhihu.com/p/144323332">计算机图形学基础变换矩阵总结(缩放，旋转，位移)</a><a href="#fnref:2" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>计算机图形学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图形学</tag>
      
      <tag>NeRF</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hello-blog</title>
    <link href="/posts/39849/"/>
    <url>/posts/39849/</url>
    
    <content type="html"><![CDATA[<h4 id="开启博客之旅">开启博客之旅~</h4><p>终于把我的博客搭好了，五一假期也结束了，那就开启新的学习之旅吧。享受最后的两年校园时光，做想做的，学想学的，愿毕业时自信又阳光！！！</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
