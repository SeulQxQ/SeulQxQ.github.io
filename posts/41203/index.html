<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="dark"><head><meta charset="UTF-8"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@500&display=swap" rel="stylesheet"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="SeulQxQ"><meta name="keywords" content="总结，学习，进步！"><meta name="description" content="1 Generation 1. Mapping Network 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878"><meta property="og:type" content="article"><meta property="og:title" content="EpiGRAF源码分析"><meta property="og:url" content="http://seulqxq.top/posts/41203/index.html"><meta property="og:site_name" content="Seul"><meta property="og:description" content="1 Generation 1. Mapping Network 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://seulqxq.top/img/index/14.png"><meta property="article:published_time" content="2024-01-09T14:11:04.000Z"><meta property="article:modified_time" content="2024-01-20T08:07:22.639Z"><meta property="article:author" content="SeulQxQ"><meta property="article:tag" content="3D GAN"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://seulqxq.top/img/index/14.png"><title>EpiGRAF源码分析 - Seul</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css"><link rel="stylesheet" href="/css/cloudedGlass.css"><link rel="stylesheet" href="/css/selection.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"seulqxq.top",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:50,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:"❡"},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:1},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><header><div class="header-inner" style="height:90vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>SeulQxQ&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url('/img/index/14.png') no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.2)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="EpiGRAF源码分析"></span></div><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> SeulQxQ </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2024-01-09 22:11" pubdate>2024年1月9日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 13k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 106 分钟</span></div></div><div class="scroll-down-bar"><i class="iconfont icon-arrowdown"></i></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar category-bar" style="margin-right:-1rem"><div class="category-list"><div class="category row nomargin-x"><a class="category-item list-group-item category-item-action col-10 col-md-11 col-xm-11" title="源码解读" id="heading-0607a1f4631b6ebfab5dd48e9412f72a" role="tab" data-toggle="collapse" href="#collapse-0607a1f4631b6ebfab5dd48e9412f72a" aria-expanded="true">源码解读 <span class="list-group-count">(4)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-0607a1f4631b6ebfab5dd48e9412f72a" role="tabpanel" aria-labelledby="heading-0607a1f4631b6ebfab5dd48e9412f72a"><div class="category-post-list"><a href="/posts/10285/" title="GNERF 源码" class="list-group-item list-group-item-action"><span class="category-post">GNERF 源码</span> </a><a href="/posts/41203/" title="EpiGRAF源码分析" class="list-group-item list-group-item-action active"><span class="category-post">EpiGRAF源码分析</span> </a><a href="/posts/27470/" title="pi-GAN源码分析" class="list-group-item list-group-item-action"><span class="category-post">pi-GAN源码分析</span> </a><a href="/posts/15494/" title="NeRF源码解读" class="list-group-item list-group-item-action"><span class="category-post">NeRF源码解读</span></a></div></div></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">EpiGRAF源码分析</h1><div class="markdown-body"><h3 id="generation">1 Generation</h3><h4 id="mapping-network">1. Mapping Network</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@persistence.persistent_class</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MappingNetwork</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">        z_dim,                         <span class="hljs-comment"># Input latent (Z) dimensionality, 0 = no latent.</span></span><br><span class="hljs-params">        c_dim,                         <span class="hljs-comment"># Conditioning label (C) dimensionality, 0 = no label.</span></span><br><span class="hljs-params">        w_dim,                         <span class="hljs-comment"># Intermediate latent (W) dimensionality.</span></span><br><span class="hljs-params">        num_ws,                        <span class="hljs-comment"># Number of intermediate latents to output, None = do not broadcast.</span></span><br><span class="hljs-params">        num_layers            = <span class="hljs-number">2</span>,        <span class="hljs-comment"># Number of mapping layers.</span></span><br><span class="hljs-params">        embed_features        = <span class="hljs-literal">None</span>,     <span class="hljs-comment"># Label embedding dimensionality, None = same as w_dim.</span></span><br><span class="hljs-params">        layer_features        = <span class="hljs-literal">None</span>,     <span class="hljs-comment"># Number of intermediate features in the mapping layers, </span></span><br><span class="hljs-params">        activation            = <span class="hljs-string">&#x27;lrelu&#x27;</span>,  <span class="hljs-comment"># Activation function: &#x27;relu&#x27;, &#x27;lrelu&#x27;, etc.</span></span><br><span class="hljs-params">        lr_multiplier         = <span class="hljs-number">0.01</span>,     <span class="hljs-comment"># Learning rate multiplier for the mapping layers.</span></span><br><span class="hljs-params">        w_avg_beta            = <span class="hljs-number">0.998</span>,    <span class="hljs-comment"># Decay for tracking the moving average of W during training, </span></span><br><span class="hljs-params">        camera_cond           = <span class="hljs-literal">False</span>,    <span class="hljs-comment"># Camera conditioning</span></span><br><span class="hljs-params">        camera_raw_scalars    = <span class="hljs-literal">False</span>,    <span class="hljs-comment"># Should we use raw camera angles as input or preprocess them with </span></span><br><span class="hljs-params">        camera_cond_drop_p    = <span class="hljs-number">0.0</span>,      <span class="hljs-comment"># Camera conditioning dropout</span></span><br><span class="hljs-params">        camera_cond_noise_std = <span class="hljs-number">0.0</span>,      <span class="hljs-comment"># Camera conditioning noise std.</span></span><br><span class="hljs-params">        mean_camera_pose      = <span class="hljs-literal">None</span>,     <span class="hljs-comment"># Average camera pose for use at test time.</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">if</span> camera_cond:<br>            <span class="hljs-keyword">if</span> camera_raw_scalars:<br>                self.camera_scalar_enc = ScalarEncoder1d(coord_dim=<span class="hljs-number">2</span>, x_multiplier=<span class="hljs-number">0.0</span>, const_emb_dim=<span class="hljs-number">0</span>, <br>                                                         use_raw=<span class="hljs-literal">True</span>)<br>            <span class="hljs-keyword">else</span>:<br>                self.camera_scalar_enc = ScalarEncoder1d(coord_dim=<span class="hljs-number">2</span>, x_multiplier=<span class="hljs-number">64.0</span>, const_emb_dim=<span class="hljs-number">0</span>)<br>            c_dim = c_dim + self.camera_scalar_enc.get_dim()<br>            <span class="hljs-keyword">assert</span> self.camera_scalar_enc.get_dim() &gt; <span class="hljs-number">0</span><br>        <span class="hljs-keyword">else</span>:<br>            self.camera_scalar_enc = <span class="hljs-literal">None</span><br><br>        self.z_dim = z_dim<br>        self.c_dim = c_dim<br>        self.w_dim = w_dim<br>        self.num_ws = num_ws<br>        self.num_layers = num_layers<br>        self.w_avg_beta = w_avg_beta<br>        self.camera_cond_drop_p = camera_cond_drop_p<br>        self.camera_cond_noise_std = camera_cond_noise_std<br><br>        <span class="hljs-keyword">if</span> embed_features <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            embed_features = w_dim<br>        <span class="hljs-keyword">if</span> self.c_dim == <span class="hljs-number">0</span>:<br>            embed_features = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> layer_features <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            layer_features = w_dim<br>        features_list = [z_dim + embed_features] + [layer_features] * (num_layers - <span class="hljs-number">1</span>) + [w_dim]<br><br>        <span class="hljs-keyword">if</span> self.c_dim &gt; <span class="hljs-number">0</span>:<br>            self.embed = FullyConnectedLayer(self.c_dim, embed_features)<br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_layers):<br>            in_features = features_list[idx]<br>            out_features = features_list[idx + <span class="hljs-number">1</span>]<br>            layer = FullyConnectedLayer(in_features, out_features, activation=activation, <br>                                        lr_multiplier=lr_multiplier)<br>            <span class="hljs-built_in">setattr</span>(self, <span class="hljs-string">f&#x27;fc<span class="hljs-subst">&#123;idx&#125;</span>&#x27;</span>, layer)<br><br>        <span class="hljs-keyword">if</span> num_ws <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> w_avg_beta <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            self.register_buffer(<span class="hljs-string">&#x27;w_avg&#x27;</span>, torch.zeros([w_dim]))<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> mean_camera_pose <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            self.register_buffer(<span class="hljs-string">&#x27;mean_camera_pose&#x27;</span>, mean_camera_pose)<br>        <span class="hljs-keyword">else</span>:<br>            self.mean_camera_pose = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, z, c, camera_angles: torch.Tensor=<span class="hljs-literal">None</span>, truncation_psi=<span class="hljs-number">1</span>, truncation_cutoff=<span class="hljs-literal">None</span>, </span><br><span class="hljs-params">                update_emas=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">not</span> self.camera_scalar_enc <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>) <span class="hljs-keyword">and</span> (<span class="hljs-keyword">not</span> self.training) <span class="hljs-keyword">and</span> (camera_angles <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>):<br>            camera_angles = self.mean_camera_pose.unsqueeze(<span class="hljs-number">0</span>).repeat(<span class="hljs-built_in">len</span>(z), <span class="hljs-number">1</span>) <span class="hljs-comment"># [batch_size, 3]</span><br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.camera_scalar_enc <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-comment"># Using only yaw and pitch for conditioning (roll is always zero)</span><br>            camera_angles = camera_angles[:, [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]] <span class="hljs-comment"># [batch_size, 2]</span><br>            <span class="hljs-keyword">if</span> self.training <span class="hljs-keyword">and</span> self.camera_cond_noise_std &gt; <span class="hljs-number">0</span>:<br>                camera_angles = camera_angles + self.camera_cond_noise_std * torch.randn_like(camera_angles) * <br>                camera_angles.std(dim=<span class="hljs-number">0</span>, keepdim=<span class="hljs-literal">True</span>) <span class="hljs-comment"># [batch_size, 2]</span><br>            <br>            <span class="hljs-comment"># [batch_size, 2]</span><br>            camera_angles = camera_angles.sign() * ((camera_angles.<span class="hljs-built_in">abs</span>() % (<span class="hljs-number">2.0</span> * np.pi)) / (<span class="hljs-number">2.0</span> * np.pi)) <br>            camera_angles_embs = self.camera_scalar_enc(camera_angles) <span class="hljs-comment"># [batch_size, fourier_dim]</span><br>            <br>            <span class="hljs-comment"># [batch_size, fourier_dim]</span><br>            camera_angles_embs = F.dropout(camera_angles_embs, p=self.camera_cond_drop_p, training=self.training) <br>            <br>            <span class="hljs-comment"># [batch_size, c_dim]</span><br>            c = torch.zeros(<span class="hljs-built_in">len</span>(camera_angles_embs), <span class="hljs-number">0</span>, device=camera_angles_embs.device) <span class="hljs-keyword">if</span> c <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> c<br>            c = torch.cat([c, camera_angles_embs], dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># [batch_size, c_dim + angle_emb_dim]</span><br><br>        <span class="hljs-comment"># Embed, normalize, and concat inputs.</span><br>        x = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">with</span> torch.autograd.profiler.record_function(<span class="hljs-string">&#x27;input&#x27;</span>):<br>            <span class="hljs-keyword">if</span> self.z_dim &gt; <span class="hljs-number">0</span>:<br>                misc.assert_shape(z, [<span class="hljs-literal">None</span>, self.z_dim])<br>                x = normalize_2nd_moment(z.to(torch.float32))<br>            <span class="hljs-keyword">if</span> self.c_dim &gt; <span class="hljs-number">0</span>:<br>                misc.assert_shape(c, [<span class="hljs-literal">None</span>, self.c_dim])<br>                y = normalize_2nd_moment(self.embed(c.to(torch.float32)))<br>                x = torch.cat([x, y], dim=<span class="hljs-number">1</span>) <span class="hljs-keyword">if</span> x <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> y<br><br>        <span class="hljs-comment"># Main layers.</span><br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.num_layers):<br>            layer = <span class="hljs-built_in">getattr</span>(self, <span class="hljs-string">f&#x27;fc<span class="hljs-subst">&#123;idx&#125;</span>&#x27;</span>)<br>            x = layer(x)<br><br>        <span class="hljs-comment"># Update moving average of W.</span><br>        <span class="hljs-keyword">if</span> update_emas <span class="hljs-keyword">and</span> self.w_avg_beta <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">with</span> torch.autograd.profiler.record_function(<span class="hljs-string">&#x27;update_w_avg&#x27;</span>):<br>                self.w_avg.copy_(x.detach().mean(dim=<span class="hljs-number">0</span>).lerp(self.w_avg, self.w_avg_beta))<br><br>        <span class="hljs-comment"># Broadcast.</span><br>        <span class="hljs-keyword">if</span> self.num_ws <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">with</span> torch.autograd.profiler.record_function(<span class="hljs-string">&#x27;broadcast&#x27;</span>):<br>                x = x.unsqueeze(<span class="hljs-number">1</span>).repeat([<span class="hljs-number">1</span>, self.num_ws, <span class="hljs-number">1</span>])<br><br>        <span class="hljs-comment"># Apply truncation.</span><br>        <span class="hljs-keyword">if</span> truncation_psi != <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">with</span> torch.autograd.profiler.record_function(<span class="hljs-string">&#x27;truncate&#x27;</span>):<br>                <span class="hljs-keyword">assert</span> self.w_avg_beta <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span><br>                <span class="hljs-keyword">if</span> self.num_ws <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> truncation_cutoff <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                    x = self.w_avg.lerp(x, truncation_psi)<br>                <span class="hljs-keyword">else</span>:<br>                    x[:, :truncation_cutoff] = self.w_avg.lerp(x[:, :truncation_cutoff], truncation_psi)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">extra_repr</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&#x27;z_dim=<span class="hljs-subst">&#123;self.z_dim:d&#125;</span>, c_dim=<span class="hljs-subst">&#123;self.c_dim:d&#125;</span>, w_dim=<span class="hljs-subst">&#123;self.w_dim:d&#125;</span>, num_ws=<span class="hljs-subst">&#123;self.num_ws:d&#125;</span>&#x27;</span><br></code></pre></td></tr></table></figure><h4 id="systhesis-network">2. Systhesis network</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@persistence.persistent_class</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SynthesisBlocksSequence</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">        w_dim,                      <span class="hljs-comment"># Intermediate latent (W) dimensionality.</span></span><br><span class="hljs-params">        in_resolution,              <span class="hljs-comment"># Which resolution do we start with?</span></span><br><span class="hljs-params">        out_resolution,             <span class="hljs-comment"># Output image resolution.</span></span><br><span class="hljs-params">        in_channels,                <span class="hljs-comment"># Number of input channels.</span></span><br><span class="hljs-params">        out_channels,               <span class="hljs-comment"># Number of input channels.</span></span><br><span class="hljs-params">        channel_base    = <span class="hljs-number">32768</span>,    <span class="hljs-comment"># Overall multiplier for the number of channels.</span></span><br><span class="hljs-params">        channel_max     = <span class="hljs-number">512</span>,      <span class="hljs-comment"># Maximum number of channels in any layer.</span></span><br><span class="hljs-params">        num_fp16_res    = <span class="hljs-number">4</span>,        <span class="hljs-comment"># Use FP16 for the N highest resolutions.</span></span><br><span class="hljs-params">        **block_kwargs,             <span class="hljs-comment"># Arguments for SynthesisBlock.</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-keyword">assert</span> in_resolution == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> (in_resolution &gt;= <span class="hljs-number">4</span> <span class="hljs-keyword">and</span> math.log2(in_resolution).is_integer())<br>        <span class="hljs-keyword">assert</span> out_resolution &gt;= <span class="hljs-number">4</span> <span class="hljs-keyword">and</span> math.log2(out_resolution).is_integer()<br>        <span class="hljs-keyword">assert</span> in_resolution &lt; out_resolution<br><br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        self.w_dim = w_dim<br>        self.out_resolution = out_resolution<br>        self.in_channels = in_channels<br>        self.out_channels = out_channels<br>        self.num_fp16_res = num_fp16_res<br><br>        in_resolution_log2 = <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> in_resolution == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> (<span class="hljs-built_in">int</span>(np.log2(in_resolution)) + <span class="hljs-number">1</span>)<br>        out_resolution_log2 = <span class="hljs-built_in">int</span>(np.log2(out_resolution))<br>        self.block_resolutions = [<span class="hljs-number">2</span> ** i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(in_resolution_log2, out_resolution_log2 + <span class="hljs-number">1</span>)]<br>        out_channels_dict = &#123;res: <span class="hljs-built_in">min</span>(channel_base // res, channel_max) <span class="hljs-keyword">for</span> res <span class="hljs-keyword">in</span> self.block_resolutions&#125;<br>        fp16_resolution = <span class="hljs-built_in">max</span>(<span class="hljs-number">2</span> ** (out_resolution_log2 + <span class="hljs-number">1</span> - num_fp16_res), <span class="hljs-number">8</span>)<br><br>        self.num_ws = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> block_idx, res <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.block_resolutions):<br>            cur_in_channels = out_channels_dict[res // <span class="hljs-number">2</span>] <span class="hljs-keyword">if</span> block_idx &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> in_channels<br>            cur_out_channels = out_channels_dict[res]<br>            use_fp16 = (res &gt;= fp16_resolution)<br>            is_last = (res == self.out_resolution)<br>            block = SynthesisBlock(cur_in_channels, cur_out_channels, w_dim=w_dim, resolution=res,<br>                img_channels=self.out_channels, is_last=is_last, use_fp16=use_fp16, **block_kwargs)<br>            self.num_ws += block.num_conv<br>            <span class="hljs-keyword">if</span> is_last:<br>                self.num_ws += block.num_torgb<br>            <span class="hljs-built_in">setattr</span>(self, <span class="hljs-string">f&#x27;b<span class="hljs-subst">&#123;res&#125;</span>&#x27;</span>, block)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, ws, x: torch.Tensor=<span class="hljs-literal">None</span>, **block_kwargs</span>):<br>        block_ws = []<br>        <span class="hljs-keyword">with</span> torch.autograd.profiler.record_function(<span class="hljs-string">&#x27;split_ws&#x27;</span>):<br>            misc.assert_shape(ws, [<span class="hljs-literal">None</span>, self.num_ws, self.w_dim])<br>            ws = ws.to(torch.float32)<br>            w_idx = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">for</span> res <span class="hljs-keyword">in</span> self.block_resolutions:<br>                block = <span class="hljs-built_in">getattr</span>(self, <span class="hljs-string">f&#x27;b<span class="hljs-subst">&#123;res&#125;</span>&#x27;</span>)<br>                block_ws.append(ws.narrow(<span class="hljs-number">1</span>, w_idx, block.num_conv + block.num_torgb))<br>                w_idx += block.num_conv<br><br>        img = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">for</span> res, cur_ws <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.block_resolutions, block_ws):<br>            block = <span class="hljs-built_in">getattr</span>(self, <span class="hljs-string">f&#x27;b<span class="hljs-subst">&#123;res&#125;</span>&#x27;</span>)<br>            x, img = block(x, img, cur_ws, **block_kwargs)<br>        <span class="hljs-keyword">return</span> img<br><br></code></pre></td></tr></table></figure><h4 id="tri_plane_renderer-triplanemlp">3. tri_plane_renderer &amp;&amp; TriPlaneMLP</h4><blockquote><p>三平面渲染，以及三平面的MLP解码网络</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tri_plane_renderer</span>(<span class="hljs-params">x: torch.Tensor, coords: torch.Tensor, ray_d_world: torch.Tensor, mlp: <span class="hljs-type">Callable</span>, scale: <span class="hljs-built_in">float</span>=<span class="hljs-number">1.0</span></span>) -&gt; torch.Tensor:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Computes RGB\sigma values from a tri-plane representation + MLP</span><br><span class="hljs-string"></span><br><span class="hljs-string">    x: [batch_size, feat_dim * 3, h, w]</span><br><span class="hljs-string">    coords: [batch_size, h * w, num_steps, 3]</span><br><span class="hljs-string">    ray_d_world: [batch_size, h * w, 3] --- ray directions in the world coordinate system</span><br><span class="hljs-string">    mlp: additional transform to apply on top of features</span><br><span class="hljs-string">    scale: additional scaling of the coordinates</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">assert</span> x.shape[<span class="hljs-number">1</span>] % <span class="hljs-number">3</span> == <span class="hljs-number">0</span>, <span class="hljs-string">f&quot;We use 3 planes: <span class="hljs-subst">&#123;x.shape&#125;</span>&quot;</span><br>    coords = coords.view(coords.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>, <span class="hljs-number">3</span>) <span class="hljs-comment"># [batch_size, h * w * num_points, 3]</span><br>    batch_size, raw_feat_dim, h, w = x.shape<br>    num_points = coords.shape[<span class="hljs-number">1</span>]<br>    feat_dim = raw_feat_dim // <span class="hljs-number">3</span><br>    misc.assert_shape(coords, [batch_size, <span class="hljs-literal">None</span>, <span class="hljs-number">3</span>])<br><br>    x = x.view(batch_size * <span class="hljs-number">3</span>, feat_dim, h, w) <span class="hljs-comment"># [batch_size * 3, feat_dim, h, w]</span><br>    coords = coords / scale <span class="hljs-comment"># [batch_size, num_points, 3]</span><br>    coords_2d = torch.stack([<br>        coords[..., [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]], <span class="hljs-comment"># z/y plane</span><br>        coords[..., [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>]], <span class="hljs-comment"># z/x plane</span><br>        coords[..., [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]], <span class="hljs-comment"># y/x plane</span><br>    ], dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># [batch_size, 3, num_points, 2]</span><br>    coords_2d = coords_2d.view(batch_size * <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, num_points, <span class="hljs-number">2</span>) <span class="hljs-comment"># [batch_size * 3, 1, num_points, 2]</span><br>    <span class="hljs-comment"># assert ((coords_2d.min().item() &gt;= -1.0 - 1e-8) and (coords_2d.max().item() &lt;= 1.0 + 1e-8))</span><br>    <span class="hljs-comment"># x : [batch_size, 3, feat_dim, num_points]</span><br>    x = F.grid_sample(x, grid=coords_2d, mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>, align_corners=<span class="hljs-literal">True</span>).view(batch_size, <span class="hljs-number">3</span>, feat_dim, <br>                                                                                   num_points) <br>    x = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># [batch_size, 3, num_points, feat_dim]</span><br>    x = mlp(x, coords, ray_d_world) <span class="hljs-comment"># [batch_size, num_points, out_dim]</span><br><br>    <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TriPlaneMLP</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, cfg: DictConfig, out_dim: <span class="hljs-built_in">int</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.cfg = cfg<br>        self.out_dim = out_dim<br><br>        <span class="hljs-keyword">if</span> self.cfg.tri_plane.mlp.n_layers == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">assert</span> self.cfg.tri_plane.feat_dim == (self.out_dim + <span class="hljs-number">1</span>), <br>            										<span class="hljs-string">f&quot;Wrong dims: <span class="hljs-subst">&#123;self.cfg.tri_plane.feat_dim&#125;</span>, <span class="hljs-subst">&#123;self.out_dim&#125;</span>&quot;</span><br>            self.model = nn.Identity()<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> self.cfg.tri_plane.get(<span class="hljs-string">&#x27;posenc_period_len&#x27;</span>, <span class="hljs-number">0</span>) &gt; <span class="hljs-number">0</span>:<br>                self.pos_enc = ScalarEncoder1d(<span class="hljs-number">3</span>, x_multiplier=self.cfg.tri_plane.posenc_period_len, <br>                                               const_emb_dim=<span class="hljs-number">0</span>)<br>            <span class="hljs-keyword">else</span>:<br>                self.pos_enc = <span class="hljs-literal">None</span><br><br>            backbone_input_dim = self.cfg.tri_plane.feat_dim + (<span class="hljs-number">0</span> <span class="hljs-keyword">if</span> self.pos_enc <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <br>                                                                self.pos_enc.get_dim())<br>            backbone_out_dim = <span class="hljs-number">1</span> + (self.cfg.tri_plane.mlp.hid_dim <span class="hljs-keyword">if</span> self.cfg.tri_plane.has_view_cond <span class="hljs-keyword">else</span> <br>                                    self.out_dim)<br>            <span class="hljs-comment"># (n_hid_layers + 2)</span><br>            self.dims = [backbone_input_dim] + [self.cfg.tri_plane.mlp.hid_dim] * (self.cfg.tri_plane.mlp.n_layers <br>                                                                                   - <span class="hljs-number">1</span>) + [backbone_out_dim] <br>            activations = [<span class="hljs-string">&#x27;lrelu&#x27;</span>] * (<span class="hljs-built_in">len</span>(self.dims) - <span class="hljs-number">2</span>) + [<span class="hljs-string">&#x27;linear&#x27;</span>]<br>            <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(self.dims) &gt; <span class="hljs-number">2</span>, <br>            					<span class="hljs-string">f&quot;We cant have just a linear layer here: nothing to modulate. Dims: <span class="hljs-subst">&#123;self.dims&#125;</span>&quot;</span><br>            layers = [FullyConnectedLayer(self.dims[i], self.dims[i+<span class="hljs-number">1</span>], activation=a) <span class="hljs-keyword">for</span> i, a <span class="hljs-keyword">in</span> <br>                      <span class="hljs-built_in">enumerate</span>(activations)]<br>            self.model = nn.Sequential(*layers)<br><br>            <span class="hljs-keyword">if</span> self.cfg.tri_plane.has_view_cond:<br>                self.ray_dir_enc = ScalarEncoder1d(coord_dim=<span class="hljs-number">3</span>, const_emb_dim=<span class="hljs-number">0</span>, x_multiplier=<span class="hljs-number">8</span>, use_cos=<span class="hljs-literal">False</span>, <br>                                                   use_raw=<span class="hljs-literal">True</span>)<br>                self.color_network = nn.Sequential(<br>                    FullyConnectedLayer(backbone_out_dim - <span class="hljs-number">1</span> + self.ray_dir_enc.get_dim(), <span class="hljs-number">32</span>, <br>                                        activation=<span class="hljs-string">&#x27;lrelu&#x27;</span>),<br>                    FullyConnectedLayer(<span class="hljs-number">32</span>, self.out_dim, activation=<span class="hljs-string">&#x27;linear&#x27;</span>),<br>                )<br>            <span class="hljs-keyword">else</span>:<br>                self.ray_dir_enc = <span class="hljs-literal">None</span><br>                self.color_network = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: torch.Tensor, coords: torch.Tensor, ray_d_world: torch.Tensor</span>) -&gt; torch.Tensor:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Params:</span><br><span class="hljs-string">            x: [batch_size, 3, num_points, feat_dim] --- volumetric features from tri-planes</span><br><span class="hljs-string">            coords: [batch_size, num_points, 3] --- coordinates, assumed to be in [-1, 1]</span><br><span class="hljs-string">            ray_d_world: [batch_size, h * w, 3] --- camera ray&#x27;s view directions</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        batch_size, _, num_points, feat_dim = x.shape<br>        x = x.mean(dim=<span class="hljs-number">1</span>).reshape(batch_size * num_points, feat_dim) <span class="hljs-comment"># [batch_size * num_points, feat_dim]</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.pos_enc <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            misc.assert_shape(coords, [batch_size, num_points, <span class="hljs-number">3</span>])<br>            <span class="hljs-comment"># pos_embs: [batch_size, num_points, pos_emb_dim]</span><br>            pos_embs = self.pos_enc(coords.reshape(batch_size * num_points, <span class="hljs-number">3</span>)) <br>            x = torch.cat([x, pos_embs], dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># [batch_size, num_points, feat_dim + pos_emb_dim]</span><br>        x = self.model(x) <span class="hljs-comment"># [batch_size * num_points, backbone_out_dim]</span><br>        x = x.view(batch_size, num_points, self.dims[-<span class="hljs-number">1</span>]) <span class="hljs-comment"># [batch_size, num_points, backbone_out_dim]</span><br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.color_network <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            num_pixels, view_dir_emb = ray_d_world.shape[<span class="hljs-number">1</span>], self.ray_dir_enc.get_dim()<br>            num_steps = num_points // num_pixels<br>            ray_dir_embs = self.ray_dir_enc(ray_d_world.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)) <span class="hljs-comment"># [batch_size * h * w, view_dir_emb]</span><br>            <span class="hljs-comment"># ray_dir_embs: [batch_size, h * w, 1, view_dir_emb]</span><br>            ray_dir_embs = ray_dir_embs.reshape(batch_size, num_pixels, <span class="hljs-number">1</span>, view_dir_emb) <br>            ray_dir_embs = ray_dir_embs.repeat(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, num_steps, <span class="hljs-number">1</span>) <span class="hljs-comment"># [batch_size, h * w, num_steps, view_dir_emb]</span><br>            <span class="hljs-comment"># ray_dir_embs: [batch_size, h * w * num_steps, view_dir_emb]</span><br>            ray_dir_embs = ray_dir_embs.reshape(batch_size, num_points, view_dir_emb) <br>            density = x[:, :, [-<span class="hljs-number">1</span>]] <span class="hljs-comment"># [batch_size, num_points, 1]</span><br>            <span class="hljs-comment"># color_feats [batch_size, num_points, backbone_out_dim - 1]</span><br>            color_feats = F.leaky_relu(x[:, :, :-<span class="hljs-number">1</span>], negative_slope=<span class="hljs-number">0.1</span>) <br>            <span class="hljs-comment"># color_feats: [batch_size, num_points, backbone_out_dim - 1 + view_dir_emb]</span><br>            color_feats = torch.cat([color_feats, ray_dir_embs], dim=<span class="hljs-number">2</span>) <br>            <span class="hljs-comment"># color_feats: [batch_size * num_points, backbone_out_dim - 1 + view_dir_emb]</span><br>            color_feats = color_feats.view(batch_size * num_points, self.dims[-<span class="hljs-number">1</span>] - <span class="hljs-number">1</span> + view_dir_emb) <br>            colors = self.color_network(color_feats) <span class="hljs-comment"># [batch_size * num_points, out_dim]</span><br>            colors = colors.view(batch_size, num_points, self.out_dim) <span class="hljs-comment"># [batch_size * num_points, out_dim]</span><br>            y = torch.cat([colors, density], dim=<span class="hljs-number">2</span>) <span class="hljs-comment"># [batch_size, num_points, out_dim + 1]</span><br>        <span class="hljs-keyword">else</span>:<br>            y = x<br><br>        misc.assert_shape(y, [batch_size, num_points, self.out_dim + <span class="hljs-number">1</span>])<br><br>        <span class="hljs-keyword">return</span> y<br></code></pre></td></tr></table></figure></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/" class="category-chain-item">源码解读</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/3D-GAN/">#3D GAN</a></div></div><div class="license-box my-3"><div class="license-title"><div>EpiGRAF源码分析</div><div>http://seulqxq.top/posts/41203/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>SeulQxQ</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2024年1月9日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/posts/24066/" title="算法训练之 -- 链表理论基础"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">算法训练之 -- 链表理论基础</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/posts/57631/" title="算法训练之 -- 蓝桥杯技巧"><span class="hidden-mobile">算法训练之 -- 蓝桥杯技巧</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",(function(){Fluid.utils.createScript("https://lib.baomitu.com/valine/1.5.1/Valine.min.js",(function(){var i=Object.assign({appId:"Qx9xEhNNylULQaxbl3lPUT12-gzGzoHsz",appKey:"bPPbrUlDDvOhU5HNAawchAXO",path:"window.location.pathname",placeholder:"留下你的足迹叭，如果愿意话，也可以留下昵称和邮箱哟~ ^_^",avatar:"monsterid",meta:["nick","mail","link"],requiredFields:[],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:null,emojiMaps:null,enableQQ:!0},{el:"#valine",path:window.location.pathname});new Valine(i),Fluid.utils.waitElementVisible("#valine .vcontent",(()=>{var i="#valine .vcontent img:not(.vemoji)";Fluid.plugins.imageCaption(i),Fluid.plugins.fancyBox(i)}))}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><font size="2"><font color="#FFFFFF"><div class="text-center py-3"><div><span id="timeDate">载入天数...</span> <span id="times">载入时分...</span><script>var now=new Date;function createtime(){var n=new Date("05/01/2023 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),document.getElementById("timeDate").innerHTML="🚀 For&nbsp"+dnum+"&nbspdays",document.getElementById("times").innerHTML=hnum+"&nbsphours&nbsp"+mnum+"&nbspminutes&nbsp😊"}setInterval("createtime()",250)</script></div><div class="text-center py-1"><div><font size="3"><font color="#FFFFFF"><span>Copyright © 2023</span> <a href="https://SeulQxQ.github.io" target="_blank" rel="nofollow noopener"><font size="3"><font color="#FFFFFF"><span>👉 SeulQxQ's Dream</span></font></font></a><br></font></font></div></div></div></font></font></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://cdn.staticfile.org/anchor-js/4.2.0/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach((t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")}))},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script src="/js/backgroundize.js"></script></body></html>