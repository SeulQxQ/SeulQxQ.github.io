<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="dark"><head><meta charset="UTF-8"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@500&display=swap" rel="stylesheet"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="SeulQxQ"><meta name="keywords" content="总结，学习，进步！"><meta name="description" content="1. train.py 1. load_images(images, curriculum, device)： 加载图像数据，批量加载。 2. z_sampler(shape, device, dist)：生成随机噪声，每次生成25张图像的噪声。 3. train(rank, world_size, opt)：开始正式训练 1）生成器和辨别器的初始化： 12345678910111213"><meta property="og:type" content="article"><meta property="og:title" content="pi-GAN源码分析"><meta property="og:url" content="http://seulqxq.top/posts/27470/index.html"><meta property="og:site_name" content="Seul"><meta property="og:description" content="1. train.py 1. load_images(images, curriculum, device)： 加载图像数据，批量加载。 2. z_sampler(shape, device, dist)：生成随机噪声，每次生成25张图像的噪声。 3. train(rank, world_size, opt)：开始正式训练 1）生成器和辨别器的初始化： 12345678910111213"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://seulqxq.top/img/index/32.jpg"><meta property="article:published_time" content="2024-01-03T14:11:04.000Z"><meta property="article:modified_time" content="2024-01-10T02:22:22.608Z"><meta property="article:author" content="SeulQxQ"><meta property="article:tag" content="3D GAN"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://seulqxq.top/img/index/32.jpg"><title>pi-GAN源码分析 - Seul</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css"><link rel="stylesheet" href="/css/cloudedGlass.css"><link rel="stylesheet" href="/css/selection.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"seulqxq.top",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:50,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:"❡"},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:1},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><header><div class="header-inner" style="height:90vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>SeulQxQ&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url('/img/index/32.jpg') no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.2)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="pi-GAN源码分析"></span></div><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> SeulQxQ </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2024-01-03 22:11" pubdate>2024年1月3日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 25k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 212 分钟</span></div></div><div class="scroll-down-bar"><i class="iconfont icon-arrowdown"></i></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar category-bar" style="margin-right:-1rem"><div class="category-list"><div class="category row nomargin-x"><a class="category-item list-group-item category-item-action col-10 col-md-11 col-xm-11" title="源码解读" id="heading-0607a1f4631b6ebfab5dd48e9412f72a" role="tab" data-toggle="collapse" href="#collapse-0607a1f4631b6ebfab5dd48e9412f72a" aria-expanded="true">源码解读 <span class="list-group-count">(3)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-0607a1f4631b6ebfab5dd48e9412f72a" role="tabpanel" aria-labelledby="heading-0607a1f4631b6ebfab5dd48e9412f72a"><div class="category-post-list"><a href="/posts/41203/" title="EpiGRAF源码分析" class="list-group-item list-group-item-action"><span class="category-post">EpiGRAF源码分析</span> </a><a href="/posts/27470/" title="pi-GAN源码分析" class="list-group-item list-group-item-action active"><span class="category-post">pi-GAN源码分析</span> </a><a href="/posts/15494/" title="NeRF源码解读" class="list-group-item list-group-item-action"><span class="category-post">NeRF源码解读</span></a></div></div></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">pi-GAN源码分析</h1><div class="markdown-body"><h3 id="train.py">1. train.py</h3><pre><code class="hljs">1. load_images(images, curriculum, device)： 加载图像数据，批量加载。
2. z_sampler(shape, device, dist)：生成随机噪声，每次生成25张图像的噪声。
3. train(rank, world_size, opt)：开始正式训练</code></pre><p><strong>1）生成器和辨别器的初始化：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># generator : ImplicitGenerator3d  由generators进入generator.py</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">返回：pixels, torch.cat([pitch, yaw], -1)</span><br><span class="hljs-string">pixels: rgb_final</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>generator = <span class="hljs-built_in">getattr</span>(generators, metadata[<span class="hljs-string">&#x27;generator&#x27;</span>])(SIREN, metadata[<span class="hljs-string">&#x27;latent_dim&#x27;</span>]).to(device) <span class="hljs-comment"># latent_dim = 256</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">return: prediction, latent, position</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-comment"># discriminator : ProgressiveEncoderDiscriminator  由discriminators进入discriminator.py</span><br>discriminator = <span class="hljs-built_in">getattr</span>(discriminators, metadata[<span class="hljs-string">&#x27;discriminator&#x27;</span>])().to(device) <span class="hljs-comment"># 判别器</span><br><br><span class="hljs-comment"># 用于对生成器 generator 的参数进行指数移动平均处理 </span><br><span class="hljs-comment"># decay: 决定了历史权重在平均中的影响大小</span><br>ema = ExponentialMovingAverage(generator.parameters(), decay=<span class="hljs-number">0.999</span>)<br>ema2 = ExponentialMovingAverage(generator.parameters(), decay=<span class="hljs-number">0.9999</span>)<br></code></pre></td></tr></table></figure><p><strong>2）训练辨别器：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-comment"># TRAIN DISCRIMINATOR 训练判别器</span><br><span class="hljs-keyword">with</span> torch.cuda.amp.autocast():<br>    <span class="hljs-comment"># Generate images for discriminator training</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-comment"># 随机噪声 z [9, 256]</span><br>        z = z_sampler((real_imgs.shape[<span class="hljs-number">0</span>], metadata[<span class="hljs-string">&#x27;latent_dim&#x27;</span>]), device=device, dist=metadata[<span class="hljs-string">&#x27;z_dist&#x27;</span>]) <br>        logging.info(<span class="hljs-string">f&quot;train discriminator z.shape: <span class="hljs-subst">&#123;z.shape&#125;</span>&quot;</span>) <span class="hljs-comment"># [9, 256]</span><br>        <span class="hljs-comment"># real_imgs.shape[0] == z.shape[0] --&gt; batch_size(9)</span><br>        split_batch_size = z.shape[<span class="hljs-number">0</span>] // metadata[<span class="hljs-string">&#x27;batch_split&#x27;</span>] <br>        gen_imgs_film = []<br>        gen_imgs = []<br>        gen_positions = []<br>        <span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(metadata[<span class="hljs-string">&#x27;batch_split&#x27;</span>]):   <span class="hljs-comment"># 循环 batch_split 次</span><br>            subset_z = z[split * split_batch_size:(split+<span class="hljs-number">1</span>) * split_batch_size] <span class="hljs-comment"># subset_z [3, 256]</span><br><br>            <span class="hljs-comment"># g_imgs --&gt; pixels [batch_split, 3(RGB), img_size, img_size], </span><br>            <span class="hljs-comment"># g_pos -&gt; torch.cat([pitch, yaw], -1) [batch_size, 2]</span><br>            <span class="hljs-comment"># --&gt; generator.py --&gt; ImplicitGenerator3d --&gt; forward()</span><br>            g_imgs, g_pos = generator_ddp(subset_z, **metadata) <br>            gen_imgs.append(g_imgs)<br>            gen_positions.append(g_pos)<br>            gen_imgs = torch.cat(gen_imgs, axis=<span class="hljs-number">0</span>)  <span class="hljs-comment"># [9, 3, 32, 32] [batch_size, channels, img_size, img_size]</span><br>            gen_positions = torch.cat(gen_positions, axis=<span class="hljs-number">0</span>) <span class="hljs-comment"># [9, 2] [batch_size, 2]</span><br><br>            real_imgs.requires_grad = <span class="hljs-literal">True</span><br><br>            <span class="hljs-comment"># prediction [batch_size, 1]</span><br>            <span class="hljs-comment"># 真实图像的 预测结果</span><br>            <span class="hljs-comment"># --&gt; discriminator.py --&gt; ProgressiveEncoderDiscriminator --&gt; forward()</span><br>            r_preds, _, _ = discriminator_ddp(real_imgs, alpha, **metadata) <br><br>            <span class="hljs-keyword">if</span> metadata[<span class="hljs-string">&#x27;r1_lambda&#x27;</span>] &gt; <span class="hljs-number">0</span>: <span class="hljs-comment"># 梯度下降</span><br>                <span class="hljs-comment"># Gradient penalty 真实图像 梯度惩罚</span><br>                grad_real = torch.autograd.grad(outputs=scaler.scale(r_preds.<span class="hljs-built_in">sum</span>()), inputs=real_imgs, 	<br>                                                create_graph=<span class="hljs-literal">True</span>) <br>                inv_scale = <span class="hljs-number">1.</span>/scaler.get_scale()<br>                grad_real = [p * inv_scale <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> grad_real][<span class="hljs-number">0</span>] <span class="hljs-comment"># 计算梯度  p [batch_size, 3, img_size, img_size]</span><br><br>                <span class="hljs-keyword">with</span> torch.cuda.amp.autocast():<br>                    <span class="hljs-keyword">if</span> metadata[<span class="hljs-string">&#x27;r1_lambda&#x27;</span>] &gt; <span class="hljs-number">0</span>:<br>                        grad_penalty = (grad_real.view(grad_real.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>).norm(<span class="hljs-number">2</span>, dim=<span class="hljs-number">1</span>) ** <span class="hljs-number">2</span>).mean()<br>                        grad_penalty = <span class="hljs-number">0.5</span> * metadata[<span class="hljs-string">&#x27;r1_lambda&#x27;</span>] * grad_penalty<br>                    <span class="hljs-keyword">else</span>:<br>                        grad_penalty = <span class="hljs-number">0</span><br><br>                        <span class="hljs-comment"># 生成器生成的图像 gen_imgs</span><br>                        <span class="hljs-comment"># gen_img_prediction [batch_size, 1], latent [batch_size, 256], </span><br>                        <span class="hljs-comment"># position [batch_size, 2]</span><br>                        g_pred_latent_film, g_pred_position_film = <br>                        discriminator_ddp(gen_imgs_film, alpha, **metadata) <br>                        g_preds, g_pred_latent, g_pred_position = discriminator_ddp(gen_imgs, alpha, <br>                                                                                    **metadata) <br>                        <span class="hljs-comment"># 生成图像 梯度惩罚</span><br>                    <span class="hljs-keyword">if</span> metadata[<span class="hljs-string">&#x27;z_lambda&#x27;</span>] &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> metadata[<span class="hljs-string">&#x27;pos_lambda&#x27;</span>] &gt; <span class="hljs-number">0</span>:<br>                        <span class="hljs-comment"># latent code惩罚</span><br>                        latent_penalty = torch.nn.MSELoss()(g_pred_latent, z) * metadata[<span class="hljs-string">&#x27;z_lambda&#x27;</span>]    <br>                        position_penalty = torch.nn.MSELoss()(g_pred_position, gen_positions) * <br>                        metadata[<span class="hljs-string">&#x27;pos_lambda&#x27;</span>] <span class="hljs-comment"># 位置信息惩罚</span><br><br>                        identity_penalty = latent_penalty + position_penalty    <br>                    <span class="hljs-keyword">else</span>:<br>                        identity_penalty=<span class="hljs-number">0</span><br>                        <span class="hljs-comment"># g_preds: 生成图像的预测结果 r_preds: 真实图像的预测结果</span><br>                        d_loss = torch.nn.functional.softplus(g_preds).mean() +  <br>                        torch.nn.functional.softplus(-r_preds).mean() + grad_penalty + identity_penalty<br>                        discriminator_losses.append(d_loss.item())<br></code></pre></td></tr></table></figure><p><strong>3）训练生成器：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># TRAIN GENERATOR 训练生成器</span><br><span class="hljs-comment"># 随机噪声 z.shape [batch_size, 256]</span><br>z = z_sampler((imgs.shape[<span class="hljs-number">0</span>], metadata[<span class="hljs-string">&#x27;latent_dim&#x27;</span>]), device=device, dist=metadata[<span class="hljs-string">&#x27;z_dist&#x27;</span>]) <br>split_batch_size = z.shape[<span class="hljs-number">0</span>] // metadata[<span class="hljs-string">&#x27;batch_split&#x27;</span>]<br><br><span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(metadata[<span class="hljs-string">&#x27;batch_split&#x27;</span>]):<br>    <span class="hljs-keyword">with</span> torch.cuda.amp.autocast():<br>        subset_z = z[split * split_batch_size:(split+<span class="hljs-number">1</span>) * split_batch_size] <span class="hljs-comment"># subset_z [batch_split, 256]</span><br><br>        <span class="hljs-comment"># gen_imgs [batch_split, 3(rgb), img_size, img_size] gen_positions [batch_split, 2]</span><br>        gen_imgs, gen_positions = generator_ddp(subset_z, **metadata)  <span class="hljs-comment"># 通过噪声生成图像 以及 姿态信息</span><br><br>        <span class="hljs-comment"># g_preds [batch_split, 1] g_pred_latent [batch_split, 256] g_pred_position [batch_split, 2]</span><br>        <span class="hljs-comment"># --&gt; ProgressiveEncoderDiscriminator --&gt; forward()</span><br>        g_preds, g_pred_latent, g_pred_position = discriminator_ddp(gen_imgs, alpha, **metadata) <br>        topk_percentage = <span class="hljs-built_in">max</span>(<span class="hljs-number">0.99</span> ** (discriminator.step/metadata[<span class="hljs-string">&#x27;topk_interval&#x27;</span>]), metadata[<span class="hljs-string">&#x27;topk_v&#x27;</span>]) <br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;topk_interval&#x27;</span> <span class="hljs-keyword">in</span> metadata <span class="hljs-keyword">and</span> <span class="hljs-string">&#x27;topk_v&#x27;</span> <span class="hljs-keyword">in</span> metadata <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br><br>        topk_num = math.ceil(topk_percentage * g_preds.shape[<span class="hljs-number">0</span>])<br><br>        g_preds = torch.topk(g_preds, topk_num, dim=<span class="hljs-number">0</span>).values <span class="hljs-comment"># 选取topk_num个最大值</span><br><br>        <span class="hljs-keyword">if</span> metadata[<span class="hljs-string">&#x27;z_lambda&#x27;</span>] &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> metadata[<span class="hljs-string">&#x27;pos_lambda&#x27;</span>] &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-comment"># 辨别器 latent code 惩罚  位置信息惩罚  信任度惩罚</span><br>            latent_penalty = torch.nn.MSELoss()(g_pred_latent, subset_z) * metadata[<span class="hljs-string">&#x27;z_lambda&#x27;</span>]<br>            position_penalty = torch.nn.MSELoss()(g_pred_position, gen_positions) * metadata[<span class="hljs-string">&#x27;pos_lambda&#x27;</span>]<br>            identity_penalty = latent_penalty + position_penalty<br>        <span class="hljs-keyword">else</span>:<br>            identity_penalty = <span class="hljs-number">0</span><br><br>            g_loss = torch.nn.functional.softplus(-g_preds).mean() + identity_penalty<br>            generator_losses.append(g_loss.item())<br><br>            scaler.scale(g_loss).backward()<br></code></pre></td></tr></table></figure><h3 id="siren.py">2. siren.py</h3><ol type="1"><li>sine_init(m)：初始化sine函数</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sine_init</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Linear):<br>            num_input = m.weight.size(-<span class="hljs-number">1</span>) <span class="hljs-comment"># 输入特征数量</span><br>            <span class="hljs-comment"># uniform_() 方法将张量中的每个元素初始化为从均匀分布中获取的值</span><br>            <span class="hljs-comment"># -np.sqrt(6 / num_input) / 30, np.sqrt(6 / num_input) / 30  He正太初始化</span><br>            m.weight.uniform_(-np.sqrt(<span class="hljs-number">6</span> / num_input) / <span class="hljs-number">30</span>, np.sqrt(<span class="hljs-number">6</span> / num_input) / <span class="hljs-number">30</span>)<br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>CustomMappingNetwork类：映射网络，将随机噪声生成频率和相位。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-comment"># 一次性计算出所有层的频率 γ 和相位 β</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, z</span>):<br>    frequencies_offsets = self.network(z) <span class="hljs-comment"># [batch_size, 4608] 4608 = (8+1)*256*2</span><br>    frequencies = frequencies_offsets[..., :frequencies_offsets.shape[-<span class="hljs-number">1</span>]//<span class="hljs-number">2</span>] <span class="hljs-comment"># [batch_size, 2304]</span><br>    phase_shifts = frequencies_offsets[..., frequencies_offsets.shape[-<span class="hljs-number">1</span>]//<span class="hljs-number">2</span>:] <span class="hljs-comment"># [batch_size, 2304]</span><br><br>    <span class="hljs-keyword">return</span> frequencies, phase_shifts<br></code></pre></td></tr></table></figure><ol start="3" type="1"><li>FiLMLayer类：隐藏层的计算</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FiLMLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim, hidden_dim</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># 初始化线性层</span><br>        self.layer = nn.Linear(input_dim, hidden_dim)   <span class="hljs-comment"># 初始化Linear层 Linear --&gt; FiLMLayer</span><br>    <span class="hljs-comment"># x 输入的位置坐标信息 position x</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, freq, phase_shift</span>):<br>        logging.info(<span class="hljs-string">f&quot;FiLMLayer input_x.shape: <span class="hljs-subst">&#123;x.shape&#125;</span>&quot;</span>)<br>        <span class="hljs-comment"># 计算线性层  x.shape [batch_size, num_rays*num_step, hidden_dim]  layer --&gt; Linear FiLMLayer input</span><br>        x = self.layer(x)       <br>        logging.info(<span class="hljs-string">f&quot;FiLMLayer output_x.shape: <span class="hljs-subst">&#123;x.shape&#125;</span>&quot;</span>)<br>        <span class="hljs-comment"># 通过激活函数计算 FiLM SIREN sin(γx + β)</span><br>        freq = freq.unsqueeze(<span class="hljs-number">1</span>).expand_as(x) <span class="hljs-comment">#  freq.shape [batch_size, num_rays*num_step, hidden_dim]</span><br>        <span class="hljs-comment"># phase_shift.shape [batch_size, num_rays*num_step, hidden_dim]</span><br>        phase_shift = phase_shift.unsqueeze(<span class="hljs-number">1</span>).expand_as(x) <br>			<br>        <span class="hljs-comment"># [batch_size, num_rays*num_step, hidden_dim] FiLM SIREN sin(γ(wx+b) + β)</span><br>        <span class="hljs-keyword">return</span> torch.sin(freq * x + phase_shift) <br></code></pre></td></tr></table></figure><ol start="4" type="1"><li>TALLSIREN模型：SIREN-MLP模型，得出通过MLP的结果</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TALLSIREN</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;Primary SIREN  architecture used in pi-GAN generators.&quot;&quot;&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot; 用于pi-GAN 生成器的主要SIREN架构。&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim=<span class="hljs-number">2</span>, z_dim=<span class="hljs-number">100</span>, hidden_dim=<span class="hljs-number">256</span>, output_dim=<span class="hljs-number">1</span>, device=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.device = device<br>        self.input_dim = input_dim <span class="hljs-comment"># 3 (x, y, z)张图片初始化</span><br>        self.z_dim = z_dim <span class="hljs-comment"># 256</span><br>        self.hidden_dim = hidden_dim <span class="hljs-comment"># 256</span><br>        self.output_dim = output_dim <span class="hljs-comment"># 4   </span><br>        <span class="hljs-comment"># TALLSIREN: input_dim.shape: 3, output_dim.shape: 4</span><br>        logging.info(<span class="hljs-string">f&quot;TALLSIREN: input_dim.shape: <span class="hljs-subst">&#123;input_dim&#125;</span>, output_dim.shape: <span class="hljs-subst">&#123;output_dim&#125;</span>&quot;</span>)<br>        self.network = nn.ModuleList([  <span class="hljs-comment"># 8个FiLM SIREN 层 [3, 256], [256, 256] ... [256, 256]</span><br>            FiLMLayer(input_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>        ])<br>        self.final_layer = nn.Linear(hidden_dim, <span class="hljs-number">1</span>) <span class="hljs-comment"># [256, 1] alpha输出层</span><br><br>        self.color_layer_sine = FiLMLayer(hidden_dim + <span class="hljs-number">3</span>, hidden_dim)   <span class="hljs-comment"># 加 ray direction d [256+3, 256]</span><br>        <span class="hljs-comment"># c(x, d) [256, 3] rgb输出层 普通线性层</span><br><br>        self.color_layer_linear = nn.Sequential(nn.Linear(hidden_dim, <span class="hljs-number">3</span>), nn.Sigmoid()) <br>        <br>        <span class="hljs-comment"># mapping network output_dim = (8+1)*256*2</span><br>        self.mapping_network = CustomMappingNetwork(z_dim, <span class="hljs-number">256</span>, (<span class="hljs-built_in">len</span>(self.network) + <span class="hljs-number">1</span>)*hidden_dim*<span class="hljs-number">2</span>) <br><br>        <span class="hljs-comment"># 一次 25 张图片初始化</span><br>        self.network.apply(frequency_init(<span class="hljs-number">25</span>)) <span class="hljs-comment"># 8 层 FiLMLayer 进行初始化</span><br>        self.final_layer.apply(frequency_init(<span class="hljs-number">25</span>))  <span class="hljs-comment"># alpha 输出层初始化</span><br>        self.color_layer_sine.apply(frequency_init(<span class="hljs-number">25</span>)) <span class="hljs-comment"># rgb 额外层初始化</span><br>        self.color_layer_linear.apply(frequency_init(<span class="hljs-number">25</span>))   <span class="hljs-comment"># rgb 输出层初始化</span><br>        self.network[<span class="hljs-number">0</span>].apply(first_layer_film_sine_init) <span class="hljs-comment"># 第一层 FiLMLayer 进行初始化</span><br><br>    <span class="hljs-comment"># input -&gt; transformed_points (generator.py -&gt; coarse_output) </span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, z, ray_directions, **kwargs</span>):<br>        frequencies, phase_shifts = self.mapping_network(z) <span class="hljs-comment"># 从mapping network中获取频率 γ 和相位 β</span><br>        <span class="hljs-keyword">return</span> self.forward_with_frequencies_phase_shifts(<span class="hljs-built_in">input</span>, frequencies, phase_shifts, ray_directions, <br>                                                          **kwargs)<br><br>    <span class="hljs-comment"># SIREN MLP 网络 计算 SIREN sin(γx + β) 输出RGB 和 alpha</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_with_frequencies_phase_shifts</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, frequencies, phase_shifts, ray_directions, **kwargs</span>):<br>        <br>        frequencies = frequencies*<span class="hljs-number">15</span> + <span class="hljs-number">30</span><br>        <span class="hljs-comment"># x.shape [batch_size, num_rays*num_steps, 3] input -&gt; points</span><br>        x = <span class="hljs-built_in">input</span><br><br>        <span class="hljs-keyword">for</span> index, layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.network): <span class="hljs-comment"># 8层隐藏层的计算</span><br>            <span class="hljs-comment"># layer == FiLMLayer(i)   FiLM SIREN sin(γx + β)</span><br>            <span class="hljs-comment"># 每次取一层的 γ 和 β (end - start) == 256</span><br>            start = index * self.hidden_dim<br>            end = (index+<span class="hljs-number">1</span>) * self.hidden_dim<br>            <span class="hljs-comment"># x.shape [batch_size, num_rays*num_steps, hidden_dim] </span><br>            x = layer(x, frequencies[..., start:end], phase_shifts[..., start:end]) <span class="hljs-comment"># -&gt; FiLMLayer forward</span><br>        <span class="hljs-comment"># x通过8层 MLP计算后 的最终输出维度为 [batch_size, num_rays*num_steps, hidden_dim]</span><br>        logging.info(<span class="hljs-string">f&quot;forward_with_frequencies_phase_shifts after x.shape: <span class="hljs-subst">&#123;x.shape&#125;</span>&quot;</span>)<br>        sigma = self.final_layer(x) <span class="hljs-comment"># sigma [batch_size, num_rays*num_steps, 1] alpha 输出层</span><br>        <br>        <span class="hljs-comment"># ray_directions d [batch_size, num_rays*num_steps, 3]</span><br>        <br>        <span class="hljs-comment"># 最后一层的 γ 和 β 259 -&gt; 256</span><br>        rbg = self.color_layer_sine(torch.cat([ray_directions, x], dim=-<span class="hljs-number">1</span>),  <br>                                    frequencies[..., -self.hidden_dim:], phase_shifts[..., -self.hidden_dim:]) <br>        rbg = self.color_layer_linear(rbg) <span class="hljs-comment"># rgb [batch_size, num_rays*num_steps] 输出层 256 -&gt; 3</span><br><br>        <span class="hljs-comment"># 生成图片的时候需要将 alpha 和 rgb 拼接在一起 然后输入到volume rendering中渲染</span><br>        <span class="hljs-keyword">return</span> torch.cat([rbg, sigma], dim=-<span class="hljs-number">1</span>) <span class="hljs-comment"># return [batch_size, num_rays*num_steps, 4] rgb + alpha</span><br></code></pre></td></tr></table></figure><h3 id="generators.py">3. generators.py</h3><ol type="1"><li>ImplicitGenerator3d类：生成器模型，用来生成图像</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 传入 (SIREN, metadata[&#x27;latent_dim&#x27;])</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ImplicitGenerator3d</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, siren, z_dim, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.z_dim = z_dim <span class="hljs-comment"># 256 (latent_dim)</span><br>        self.siren = siren(output_dim=<span class="hljs-number">4</span>, z_dim=self.z_dim, input_dim=<span class="hljs-number">3</span>, device=<span class="hljs-literal">None</span>) <span class="hljs-comment"># 初始化 SIREN -&gt; siren.py</span><br>        self.epoch = <span class="hljs-number">0</span><br>        self.step = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">set_device</span>(<span class="hljs-params">self, device</span>):<br>        self.device = device<br>        self.siren.device = device<br><br>        self.generate_avg_frequencies() <span class="hljs-comment"># 求频率和相位的平均值 [1, 2304] 2304 = 256 * (8 + 1)</span><br>        <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, z, img_size, fov, ray_start, ray_end, num_steps, </span><br><span class="hljs-params">                h_stddev, v_stddev, h_mean, v_mean, hierarchical_sample, </span><br><span class="hljs-params">                sample_dist=<span class="hljs-literal">None</span>, lock_view_dependence=<span class="hljs-literal">False</span>, **kwargs</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Generates images from a noise vector, rendering parameters, and camera distribution.</span><br><span class="hljs-string">        Uses the hierarchical sampling scheme described in NeRF.</span><br><span class="hljs-string">        从 噪声向量，渲染参数，相机分布 生成图像</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># z.shape: (3, 256) [batch_size / batch_split, z_dim], num_rays = img_size * img_size</span><br>        batch_size = z.shape[<span class="hljs-number">0</span>] <br><br>        <span class="hljs-comment"># Generate initial camera rays and sample points. 生成初始相机射线和采样点</span><br>        <span class="hljs-comment"># 返回sample points, z_vals, ray directions batch_size, pixels, num_steps, 1</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            <span class="hljs-comment"># 获取 采样点，z_vals(深度)和光线方向 position x</span><br>            points_cam, z_vals, rays_d_cam = get_initial_rays_trig(<br>                batch_size, num_steps, resolution=(img_size, img_size), device=self.device, <br>                fov=fov, ray_start=ray_start, ray_end=ray_end) <br>            <span class="hljs-comment"># points_cam.shape: [batch_size, img_size*img_size, num_steps, 3(RGB)] </span><br>            <span class="hljs-comment"># z_vals.shape:  [batch_size, img_size*img_size, num_steps, 1] </span><br>            <span class="hljs-comment"># rays_d_cam.shape: [batch_size, img_size*img_size, num_steps, 3(xyz)]</span><br><br><br>            <span class="hljs-comment"># transform_sampled_points 对相机位置进行采样，并将相机空间坐标映射到世界空间坐标</span><br>            <span class="hljs-comment"># 采样点，z_vals(深度)，光线方向，光线原点，俯仰角，偏航角 转换后的坐标 </span><br>            transformed_points, z_vals, transformed_ray_directions, transformed_ray_origins, pitch, yaw = \<br>            transform_sampled_points(points_cam, z_vals, rays_d_cam, h_stddev=h_stddev, v_stddev=v_stddev, <br>                                         h_mean=h_mean, v_mean=v_mean, device=self.device, mode=sample_dist) <br>            <br>            <span class="hljs-comment"># trasformed_points.shape: [batch_size, num_rays, num_steps, 3(RGB)] </span><br>            <span class="hljs-comment"># z_vals.shape: [batch_size, num_rays, num_steps, 1] </span><br>            <span class="hljs-comment"># transformed_ray_directions.shape: [batch_size, num_rays, num_steps, 3(xyz)] </span><br>            <span class="hljs-comment"># transformed_ray_origins.shape: [batch_size, num_rays, num_steps, 3(xyz)] </span><br>            <span class="hljs-comment"># pitch.shape: [batch_size, num_rays, 1] yaw.shape: [batch_size, num_rays, 1]</span><br><br>            <span class="hljs-comment"># 坐标系变换 从相机坐标系到世界坐标系</span><br>            <span class="hljs-comment"># transformed_ray_directions_expanded 转换后的射线方向</span><br>            <br>            <span class="hljs-comment"># [batch_size, num_rays, num_steps, 1, 3]</span><br>            transformed_ray_directions_expanded = torch.unsqueeze(transformed_ray_directions, -<span class="hljs-number">2</span>) <br>            transformed_ray_directions_expanded = transformed_ray_directions_expanded.expand(-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <br>                                                num_steps, -<span class="hljs-number">1</span>) <span class="hljs-comment"># [batch_size, num_rays, num_steps, num_steps, 3]</span><br>            transformed_ray_directions_expanded = transformed_ray_directions_expanded.reshape(batch_size,                                                                                     img_size*img_size*num_steps, <span class="hljs-number">3</span>)<br>            <br>             <span class="hljs-comment"># [batch_size, num_rays*num_steps, 3]</span><br>            transformed_points = transformed_points.reshape(batch_size, img_size*img_size*num_steps, <span class="hljs-number">3</span>)<br><br>            <span class="hljs-keyword">if</span> lock_view_dependence:<br>                transformed_ray_directions_expanded = torch.zeros_like(transformed_ray_directions_expanded)<br>                transformed_ray_directions_expanded[..., -<span class="hljs-number">1</span>] = -<span class="hljs-number">1</span><br><br>        <span class="hljs-comment"># Model prediction on course points MLP 隐藏层计算 粗糙采样</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        输入：transformed_points [batch_size, num_rays*num_steps, 3(xyz)], z [batch_size, 256], </span><br><span class="hljs-string">        	 ray_directions  [batch_size, num_rays*num_steps, 3(xyz)]</span><br><span class="hljs-string">        输出：rgb aplha [batch_size, num_rays*num_steps, 4]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># input siren  # -&gt; siren.py TALLSIREN forward</span><br>        coarse_output = self.siren(transformed_points, z, ray_directions=transformed_ray_directions_expanded)<br>        <br>        <span class="hljs-comment"># [batch_size, num_rays, num_steps, 4] 每条光线上的每个采样点</span><br>        coarse_output = coarse_output.reshape(batch_size, img_size * img_size, num_steps, <span class="hljs-number">4</span>) <br><br>        <span class="hljs-comment"># Re-sample fine points alont camera rays, as described in NeRF</span><br>        <span class="hljs-keyword">if</span> hierarchical_sample: <span class="hljs-comment"># 半球采样</span><br>            <span class="hljs-keyword">with</span> torch.no_grad():<br>                <span class="hljs-comment"># 每个光线上的每个采样点</span><br>                transformed_points = transformed_points.reshape(batch_size, img_size * img_size, num_steps, <span class="hljs-number">3</span>) <br>                <span class="hljs-comment"># 从 fancy_integration 中获取 weights 权重 用来进行重要性采样（精细采样） </span><br>                <br>                _, _, weights = fancy_integration(coarse_output, z_vals, device=self.device, <br>                                                  clamp_mode=kwargs[<span class="hljs-string">&#x27;clamp_mode&#x27;</span>], <br>                                                  noise_std=kwargs[<span class="hljs-string">&#x27;nerf_noise&#x27;</span>])<br>                weights = weights.reshape(batch_size * img_size * img_size, num_steps) + <span class="hljs-number">1e-5</span><br><br>                <span class="hljs-comment">#### Start new importance sampling 重要性采样</span><br>                z_vals = z_vals.reshape(batch_size * img_size * img_size, num_steps)<br>                z_vals_mid = <span class="hljs-number">0.5</span> * (z_vals[: ,:-<span class="hljs-number">1</span>] + z_vals[: ,<span class="hljs-number">1</span>:])<br>                z_vals = z_vals.reshape(batch_size, img_size * img_size, num_steps, <span class="hljs-number">1</span>)<br>                <br>                fine_z_vals = sample_pdf(z_vals_mid, weights[:, <span class="hljs-number">1</span>:-<span class="hljs-number">1</span>],<br>                                 num_steps, det=<span class="hljs-literal">False</span>).detach()<br><br>                fine_z_vals = fine_z_vals.reshape(batch_size, img_size * img_size, num_steps, <span class="hljs-number">1</span>)<br><br>                <span class="hljs-comment"># fine_points.shape [batch_size, num_rays, num_steps, 3]</span><br><br>                fine_points = transformed_ray_origins.unsqueeze(<span class="hljs-number">2</span>).contiguous() + \<br>                    transformed_ray_directions.unsqueeze(<span class="hljs-number">2</span>).contiguous() * <br>                    fine_z_vals.expand(-<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>,<span class="hljs-number">3</span>).contiguous()<br>                <span class="hljs-comment"># 精细网络 采样点</span><br>				<br>                <span class="hljs-comment"># [batch_size, num_rays*num_steps, 3]</span><br>                fine_points = fine_points.reshape(batch_size, img_size*img_size*num_steps, <span class="hljs-number">3</span>) <br>                <br><br>                <span class="hljs-keyword">if</span> lock_view_dependence:<br>                    transformed_ray_directions_expanded = torch.zeros_like(transformed_ray_directions_expanded)<br>                    transformed_ray_directions_expanded[..., -<span class="hljs-number">1</span>] = -<span class="hljs-number">1</span><br>                <span class="hljs-comment">#### end new importance sampling</span><br><br>            <span class="hljs-comment"># Model prediction on re-sampled find points 精细采样后的点在进行预测</span><br>            <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">            输入：fine_points [batch_size, num_rays*num_steps, 3], z [batch_size, 246], </span><br><span class="hljs-string">                 ray_directions [batch_size, num_rays*num_steps, 3]</span><br><span class="hljs-string">            输出：fine_output [batch_size, num_rays, nums_steps, 4](rgb aplha)</span><br><span class="hljs-string">            &quot;&quot;&quot;</span><br>            fine_output = self.siren(fine_points, z, ray_directions=transformed_ray_directions_expanded)<br>			<span class="hljs-comment"># [batch_size, num_rays, num_steps, 4]</span><br>            fine_output = fine_output.reshape(batch_size, img_size * img_size, num_steps, <span class="hljs-number">4</span>) <br><br>            <span class="hljs-comment"># Combine course and fine points 组合粗糙采样和精细采样</span><br>            <span class="hljs-comment"># 最终输出： all_z_vals all_outputs</span><br>            <br>			<span class="hljs-comment"># [batch_size, num_rays, num_steps*2, 4]</span><br>            all_outputs = torch.cat([fine_output, coarse_output], dim = -<span class="hljs-number">2</span>) <br><br>            all_z_vals = torch.cat([fine_z_vals, z_vals], dim = -<span class="hljs-number">2</span>) <span class="hljs-comment"># [batch_size, num_rays, num_steps*2, 1]</span><br>            <br>            _, indices = torch.sort(all_z_vals, dim=-<span class="hljs-number">2</span>)<br><br><br>            all_z_vals = torch.gather(all_z_vals, -<span class="hljs-number">2</span>, indices) <span class="hljs-comment"># [batch_size, num_rays, num_steps*2, 1]</span><br>			<br>            <span class="hljs-comment"># [batch_size, num_rays, num_steps*2, 4]</span><br>            all_outputs = torch.gather(all_outputs, -<span class="hljs-number">2</span>, indices.expand(-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">4</span>))<br>        <span class="hljs-keyword">else</span>:<br>            all_outputs = coarse_output<br><br>            all_z_vals_film = z_vals<br>            all_z_vals = z_vals<br><br><br>        <span class="hljs-comment"># Create images with NeRF </span><br>        <span class="hljs-comment"># 使用 NeRF 创建图像</span><br>        <span class="hljs-comment"># 输出：rgb [batch_size, num_rays, 3], depth [batch_size, num_rays, 1], </span><br>        <span class="hljs-comment">#      weight [batch_size, num_rays, num_stpes*2 1]</span><br><br>        pixels, depth, weights = fancy_integration(all_outputs, all_z_vals, device=self.device, <br>                                                   white_back=kwargs.get(<span class="hljs-string">&#x27;white_back&#x27;</span>, <span class="hljs-literal">False</span>), <br>                                                   last_back=kwargs.get(<span class="hljs-string">&#x27;last_back&#x27;</span>, <span class="hljs-literal">False</span>), <br>                                                   clamp_mode=kwargs[<span class="hljs-string">&#x27;clamp_mode&#x27;</span>], <br>                                                   noise_std=kwargs[<span class="hljs-string">&#x27;nerf_noise&#x27;</span>])<br>        <span class="hljs-comment">#  还原 pixels.shape: [batch_size, img_size, img_size, 3]</span><br>        <br>        pixels = pixels.reshape((batch_size, img_size, img_size, <span class="hljs-number">3</span>))<br>        pixels = pixels.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous() * <span class="hljs-number">2</span> - <span class="hljs-number">1</span> <span class="hljs-comment"># 交换维度 [batch_size, 3, img_size, img_size]</span><br><br>        logging.info(<span class="hljs-string">f&quot;generators forward pixels.shape: <span class="hljs-subst">&#123;pixels.shape&#125;</span>&quot;</span>)<br>        <span class="hljs-comment"># pixels.shape: [batch_size, 3, img_size, img_size] pitch.shape: [batch_size, 1] yaw.shape: [batch_size, 1]</span><br>        <span class="hljs-keyword">return</span> pixels, torch.cat([pitch, yaw], -<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h3 id="discriminators.py">4. discriminators.py</h3><ol type="1"><li>AddCoords：额外添加坐标的信息</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-comment"># 负责为给定的特征图添加坐标通道</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">AddCoords</span>(nn.Module):    <br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Source: https://github.com/mkocabas/CoordConv-pytorch/blob/master/CoordConv.py</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, with_r=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.with_r = with_r<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_tensor</span>):  <span class="hljs-comment"># &lt;-- CoordConv</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            input_tensor --&gt; x shape(batch, channel, img_size, img_size)</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        logging.info(<span class="hljs-string">f&quot;AddCoords input_tensor.shape: <span class="hljs-subst">&#123;input_tensor.shape&#125;</span>&quot;</span>)<br>        batch_size, _, x_dim, y_dim = input_tensor.size()<br><br>        <span class="hljs-comment"># 生成x, y 坐标网格</span><br>        xx_channel = torch.arange(x_dim).repeat(<span class="hljs-number">1</span>, y_dim, <span class="hljs-number">1</span>)   <span class="hljs-comment"># [1, img_size, img_size]  </span><br>        yy_channel = torch.arange(y_dim).repeat(<span class="hljs-number">1</span>, x_dim, <span class="hljs-number">1</span>).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)   <span class="hljs-comment"># [1, img_size, img_size]  </span><br><br>        <span class="hljs-comment"># 归一化 [0, 1]</span><br>        xx_channel = xx_channel.<span class="hljs-built_in">float</span>() / (x_dim - <span class="hljs-number">1</span>) <br>        yy_channel = yy_channel.<span class="hljs-built_in">float</span>() / (y_dim - <span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># xx_channel: shape(1, img_size, img_size)</span><br>        <span class="hljs-comment"># 映射到 [-1, 1]</span><br>        xx_channel = xx_channel * <span class="hljs-number">2</span> - <span class="hljs-number">1</span><br>        yy_channel = yy_channel * <span class="hljs-number">2</span> - <span class="hljs-number">1</span><br><br>        <span class="hljs-comment"># shape: (batch_size, 1, img_size, img_size)</span><br>        xx_channel = xx_channel.repeat(batch_size, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>).transpose(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>        yy_channel = yy_channel.repeat(batch_size, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>).transpose(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br><br>        ret = torch.cat([<br>            input_tensor,<br>            xx_channel.type_as(input_tensor),<br>            yy_channel.type_as(input_tensor)], dim=<span class="hljs-number">1</span>)<br><br>        <span class="hljs-keyword">if</span> self.with_r:<br>            rr = torch.sqrt(torch.<span class="hljs-built_in">pow</span>(xx_channel.type_as(input_tensor) - <span class="hljs-number">0.5</span>, <span class="hljs-number">2</span>) + <br>                            torch.<span class="hljs-built_in">pow</span>(yy_channel.type_as(input_tensor) - <span class="hljs-number">0.5</span>, <span class="hljs-number">2</span>))<br>            ret = torch.cat([ret, rr], dim=<span class="hljs-number">1</span>)<br>        <br>        <span class="hljs-comment"># ret.shape: [batch_size, channel + (x, y), img_size, img_size] channel --&gt; 256</span><br>        <span class="hljs-keyword">return</span> ret<br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>ProgressiveDiscriminator：使用渐进式辨别器</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-comment"># 渐进式增长判别器</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ProgressiveDiscriminator</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;Implement of a progressive growing discriminator with ResidualCoordConv Blocks&quot;&quot;&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot; 每次增加新的分辨率级别时，会增加新的 ResidualCoordConvBlock &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.epoch = <span class="hljs-number">0</span><br>        self.step = <span class="hljs-number">0</span><br>        self.layers = nn.ModuleList(<br>        [<br>            <span class="hljs-comment"># inplane plane downsample</span><br>            ResidualCoordConvBlock(<span class="hljs-number">16</span>, <span class="hljs-number">32</span>, downsample=<span class="hljs-literal">True</span>),   <span class="hljs-comment"># 512x512 -&gt; 256x256 # 每层有两层的CoordConv</span><br>            ResidualCoordConvBlock(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, downsample=<span class="hljs-literal">True</span>),   <span class="hljs-comment"># 256x256 -&gt; 128x128</span><br>            ResidualCoordConvBlock(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, downsample=<span class="hljs-literal">True</span>),  <span class="hljs-comment"># 128x128 -&gt; 64x64</span><br>            ResidualCoordConvBlock(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, downsample=<span class="hljs-literal">True</span>), <span class="hljs-comment"># 64x64   -&gt; 32x32</span><br>            ResidualCoordConvBlock(<span class="hljs-number">256</span>, <span class="hljs-number">400</span>, downsample=<span class="hljs-literal">True</span>), <span class="hljs-comment"># 32x32   -&gt; 16x16</span><br>            ResidualCoordConvBlock(<span class="hljs-number">400</span>, <span class="hljs-number">400</span>, downsample=<span class="hljs-literal">True</span>), <span class="hljs-comment"># 16x16   -&gt; 8x8</span><br>            ResidualCoordConvBlock(<span class="hljs-number">400</span>, <span class="hljs-number">400</span>, downsample=<span class="hljs-literal">True</span>), <span class="hljs-comment"># 8x8     -&gt; 4x4</span><br>            ResidualCoordConvBlock(<span class="hljs-number">400</span>, <span class="hljs-number">400</span>, downsample=<span class="hljs-literal">True</span>), <span class="hljs-comment"># 4x4     -&gt; 2x2</span><br>        ])<br><br>        self.fromRGB = nn.ModuleList(<br>        [<br>            <span class="hljs-comment"># output_channels</span><br>            AdapterBlock(<span class="hljs-number">16</span>),<br>            AdapterBlock(<span class="hljs-number">32</span>),<br>            AdapterBlock(<span class="hljs-number">64</span>),<br>            AdapterBlock(<span class="hljs-number">128</span>),<br>            AdapterBlock(<span class="hljs-number">256</span>),<br>            AdapterBlock(<span class="hljs-number">400</span>),<br>            AdapterBlock(<span class="hljs-number">400</span>),<br>            AdapterBlock(<span class="hljs-number">400</span>),<br>            AdapterBlock(<span class="hljs-number">400</span>)<br>        ])<br>        self.final_layer = nn.Conv2d(<span class="hljs-number">400</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        self.img_size_to_layer = &#123;<span class="hljs-number">2</span>:<span class="hljs-number">8</span>, <span class="hljs-number">4</span>:<span class="hljs-number">7</span>, <span class="hljs-number">8</span>:<span class="hljs-number">6</span>, <span class="hljs-number">16</span>:<span class="hljs-number">5</span>, <span class="hljs-number">32</span>:<span class="hljs-number">4</span>, <span class="hljs-number">64</span>:<span class="hljs-number">3</span>, <span class="hljs-number">128</span>:<span class="hljs-number">2</span>, <span class="hljs-number">256</span>:<span class="hljs-number">1</span>, <span class="hljs-number">512</span>:<span class="hljs-number">0</span>&#125;<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, alpha, instance_noise=<span class="hljs-number">0</span>, **kwargs</span>):<br>        start = self.img_size_to_layer[<span class="hljs-built_in">input</span>.shape[-<span class="hljs-number">1</span>]]<br>        logging.info(<span class="hljs-string">f&quot;ProgressiveDiscriminator input.shape: <span class="hljs-subst">&#123;<span class="hljs-built_in">input</span>.shape&#125;</span>&quot;</span>)<br>        x = self.fromRGB[start](<span class="hljs-built_in">input</span>)<br>        logging.info(<span class="hljs-string">f&quot;ProgressiveDiscriminator x.shape: <span class="hljs-subst">&#123;x.shape&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">for</span> i, layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.layers[start:]):<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">1</span>:<br>                <span class="hljs-comment"># 改变输入数据的尺寸</span><br>                x = alpha * x + (<span class="hljs-number">1</span> - alpha) * self.fromRGB[start+<span class="hljs-number">1</span>](F.interpolate(<span class="hljs-built_in">input</span>, scale_factor=<span class="hljs-number">0.5</span>, <br>                                                                                  mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)) <br>            x = layer(x)<br><br>        x = self.final_layer(x).reshape(x.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>)<br>        logging.info(<span class="hljs-string">f&quot;ProgressiveDiscriminator x_output.shape: <span class="hljs-subst">&#123;x.shape&#125;</span>&quot;</span>)    <br><br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><h3 id="volumetirc_rendering.py">5. volumetirc_rendering.py</h3><ol type="1"><li>fancy_integration()：预测出来的rgb 生成最终的图像</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">fancy_integration</span>(<span class="hljs-params">rgb_sigma, z_vals, device, noise_std=<span class="hljs-number">0.5</span>, last_back=<span class="hljs-literal">False</span>, white_back=<span class="hljs-literal">False</span>, clamp_mode=<span class="hljs-literal">None</span>, fill_mode=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Performs NeRF volumetric rendering.&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># rgb_sigma.shape: [batch_size, num_rays, num_steps, 4]</span><br>    <span class="hljs-comment"># z_vals.shape: [batch_size, num_rays, num_steps, 1]</span><br><br>    <span class="hljs-comment"># rgb_sigma 由siren网络训练得到</span><br>    rgbs = rgb_sigma[..., :<span class="hljs-number">3</span>]   <span class="hljs-comment"># rgb [batch_size, num_rays, num_steps, 3]</span><br>    sigmas = rgb_sigma[..., <span class="hljs-number">3</span>:] <span class="hljs-comment"># sigma [batch_size, num_rays, num_steps, 1]</span><br><br>    <span class="hljs-comment"># deltas 两个采样点之间的距离 d</span><br>    deltas = z_vals[:, :, <span class="hljs-number">1</span>:] - z_vals[:, :, :-<span class="hljs-number">1</span>] <span class="hljs-comment"># 每两个采样点之间的距离</span><br>    delta_inf = <span class="hljs-number">1e10</span> * torch.ones_like(deltas[:, :, :<span class="hljs-number">1</span>]) <span class="hljs-comment"># 远平面 无穷远处</span><br>    deltas = torch.cat([deltas, delta_inf], -<span class="hljs-number">2</span>)<br><br>    noise = torch.randn(sigmas.shape, device=device) * noise_std <span class="hljs-comment"># 随机噪声 [batch_size, num_rays, num_steps, 1]</span><br><br>    <span class="hljs-comment"># 计算 alpha</span><br>    <span class="hljs-keyword">if</span> clamp_mode == <span class="hljs-string">&#x27;softplus&#x27;</span>:<br>        alphas = <span class="hljs-number">1</span>-torch.exp(-deltas * (F.softplus(sigmas + noise)))<br>    <span class="hljs-keyword">elif</span> clamp_mode == <span class="hljs-string">&#x27;relu&#x27;</span>:<br>        alphas = <span class="hljs-number">1</span> - torch.exp(-deltas * (F.relu(sigmas + noise)))<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> <span class="hljs-string">&quot;Need to choose clamp mode&quot;</span><br><br>    alphas_shifted = torch.cat([torch.ones_like(alphas[:, :, :<span class="hljs-number">1</span>]), <span class="hljs-number">1</span>-alphas + <span class="hljs-number">1e-10</span>], -<span class="hljs-number">2</span>)<br>    <br>    <span class="hljs-comment"># 计算 NeRF 中的 transmittance weights = aplhas * T_i 体渲染公式</span><br>    weights = alphas * torch.cumprod(alphas_shifted, -<span class="hljs-number">2</span>)[:, :, :-<span class="hljs-number">1</span>] <span class="hljs-comment"># [batch_size, num_rays, num_steps, 1]</span><br>    weights_sum = weights.<span class="hljs-built_in">sum</span>(<span class="hljs-number">2</span>) <span class="hljs-comment"># [batch_size, num_rays, 1] 每条射线的权重和</span><br><br>    <span class="hljs-keyword">if</span> last_back:<br>        weights[:, :, -<span class="hljs-number">1</span>] += (<span class="hljs-number">1</span> - weights_sum)<br><br>    rgb_final = torch.<span class="hljs-built_in">sum</span>(weights * rgbs, -<span class="hljs-number">2</span>) <span class="hljs-comment"># [batch_size, num_rays, 3] 最终预测出来的rgb</span><br>    depth_final = torch.<span class="hljs-built_in">sum</span>(weights * z_vals, -<span class="hljs-number">2</span>) <span class="hljs-comment"># [batch_size, num_rays, 1] 最终预测出来的深度</span><br><br>    <span class="hljs-keyword">if</span> white_back:<br>        rgb_final = rgb_final + <span class="hljs-number">1</span>-weights_sum<br><br>    <span class="hljs-keyword">if</span> fill_mode == <span class="hljs-string">&#x27;debug&#x27;</span>:<br>        rgb_final[weights_sum.squeeze(-<span class="hljs-number">1</span>) &lt; <span class="hljs-number">0.9</span>] = torch.tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], device=rgb_final.device)<br>    <span class="hljs-keyword">elif</span> fill_mode == <span class="hljs-string">&#x27;weight&#x27;</span>:<br>        rgb_final = weights_sum.expand_as(rgb_final)<br><br>    logging.info(<span class="hljs-string">f&quot;fancy_integration output rgb_final.shape: <span class="hljs-subst">&#123;rgb_final.shape&#125;</span>&quot;</span>)<br><br>    <span class="hljs-comment"># 最终预测出来的rgb 生成最终的图像</span><br>    <span class="hljs-keyword">return</span> rgb_final, depth_final, weights<br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>get_initial_rays_trig()：输出采样点，采样间隔，相机射线方向</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_initial_rays_trig</span>(<span class="hljs-params">n, num_steps, device, fov, resolution, ray_start, ray_end</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Returns sample points, z_vals, and ray directions in camera space.&quot;&quot;&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot; return: 返回相机空间中的采样点，z_vals(深度)和光线方向。</span><br><span class="hljs-string">        ray_start: 近平面</span><br><span class="hljs-string">        ray_end: 远平面</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    W, H = resolution <span class="hljs-comment"># (img_size, img_size)</span><br>    <span class="hljs-comment"># Create full screen NDC (-1 to +1) coords [x, y, 0, 1].</span><br>    <span class="hljs-comment"># Y is flipped to follow image memory layouts.</span><br>    x, y = torch.meshgrid(torch.linspace(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, W, device=device),  <span class="hljs-comment"># (W, H)</span><br>                          torch.linspace(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, H, device=device))<br>    x = x.T.flatten() <span class="hljs-comment"># (H*W,) 铺平</span><br>    y = y.T.flatten()<br>    z = -torch.ones_like(x, device=device) / np.tan((<span class="hljs-number">2</span> * math.pi * fov / <span class="hljs-number">360</span>)/<span class="hljs-number">2</span>) <span class="hljs-comment"># (H*W,) 透视投影</span><br><br>    <span class="hljs-comment"># 射线方向</span><br>    rays_d_cam = normalize_vecs(torch.stack([x, y, z], -<span class="hljs-number">1</span>)) <span class="hljs-comment"># (H*W, 3)</span><br><br>	<span class="hljs-comment"># (H*W, num_steps, 1)</span><br>    z_vals = torch.linspace(ray_start, ray_end, num_steps, device=device).reshape(<span class="hljs-number">1</span>, num_steps, <span class="hljs-number">1</span>).repeat(W*H, <span class="hljs-number">1</span>, <br>                                                                                                          <span class="hljs-number">1</span>) <br>    points = rays_d_cam.unsqueeze(<span class="hljs-number">1</span>).repeat(<span class="hljs-number">1</span>, num_steps, <span class="hljs-number">1</span>) * z_vals <span class="hljs-comment"># (H*W, num_steps, 3)</span><br><br>    points = torch.stack(n*[points]) <span class="hljs-comment"># (n, H*W, num_steps, 3) n --&gt; batch_size // batch_split</span><br>    z_vals = torch.stack(n*[z_vals])<br>    rays_d_cam = torch.stack(n*[rays_d_cam]).to(device) <span class="hljs-comment"># (n, H*W, 3)</span><br><br>    logging.info(<span class="hljs-string">f&quot;get_initial_rays_trig&#x27;s points.shape: <span class="hljs-subst">&#123;points.shape&#125;</span>, rays_d_cam.shape: <span class="hljs-subst">&#123;rays_d_cam.shape&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> points, z_vals, rays_d_cam  <span class="hljs-comment">#<span class="hljs-doctag">TODO:</span> debug these dimensions </span><br></code></pre></td></tr></table></figure><ol start="3" type="1"><li>transform_sampled_points()：采样相机位置并将相机空间中的点映射到世界空间</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">transform_sampled_points</span>(<span class="hljs-params">points, z_vals, ray_directions, device, h_stddev=<span class="hljs-number">1</span>, v_stddev=<span class="hljs-number">1</span>, h_mean=math.pi * <span class="hljs-number">0.5</span>, </span><br><span class="hljs-params">                             v_mean=math.pi * <span class="hljs-number">0.5</span>, mode=<span class="hljs-string">&#x27;normal&#x27;</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Samples a camera position and maps points in camera space to world space.&quot;&quot;&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot; 采样相机位置并将相机空间中的点映射到世界空间。 &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># n --&gt; batch_size, num_rays --&gt; H*W(pixels), num_steps --&gt; num_samples</span><br>    n, num_rays, num_steps, channels = points.shape <span class="hljs-comment"># input points.shape: [batch_size, num_rays, num_steps, 3]</span><br><br>    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> the points&#x27;s dims</span><br>    points, z_vals = perturb_points(points, z_vals, ray_directions, device)<br><br>    <span class="hljs-comment"># 获取相机原点，水平角和仰视角 camera_origin.shape: [batch_size, 3], </span><br>    <span class="hljs-comment"># pitch.shape: [batch_size, 1], yaw.shape: [batch_size, 1]</span><br>    camera_origin, pitch, yaw = sample_camera_positions(n=points.shape[<span class="hljs-number">0</span>], r=<span class="hljs-number">1</span>, horizontal_stddev=h_stddev, <br>                                                        vertical_stddev=v_stddev, <br>                                                        horizontal_mean=h_mean, vertical_mean=v_mean, <br>                                                        device=device, mode=mode)<br>    forward_vector = normalize_vecs(-camera_origin)<br><br>    cam2world_matrix = create_cam2world_matrix(forward_vector, camera_origin, device=device)<br><br>    points_homogeneous = torch.ones((points.shape[<span class="hljs-number">0</span>], points.shape[<span class="hljs-number">1</span>], points.shape[<span class="hljs-number">2</span>], points.shape[<span class="hljs-number">3</span>] + <span class="hljs-number">1</span>), <br>                                    device=device)<br>    points_homogeneous[:, :, :, :<span class="hljs-number">3</span>] = points <span class="hljs-comment"># (n, num_rays, num_steps, 4)</span><br><br>    <span class="hljs-comment"># should be n x 4 x 4 , n x r^2 x num_steps x 4 (采样点)</span><br>    transformed_points = torch.bmm(cam2world_matrix, <span class="hljs-comment"># (n, num_rays, num_steps, 4)</span><br>                                   points_homogeneous.reshape(n, -<span class="hljs-number">1</span>, <span class="hljs-number">4</span>).permute(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <br>                                   <span class="hljs-number">1</span>).reshape(n, num_rays, num_steps, <span class="hljs-number">4</span>)<br><br>    <span class="hljs-comment"># 没有使用齐次坐标(向量的平移不变性) 射线方向</span><br>    transformed_ray_directions = torch.bmm(cam2world_matrix[..., :<span class="hljs-number">3</span>, :<span class="hljs-number">3</span>],  <span class="hljs-comment"># (n, num_rays, 3(x,y,z))</span><br>                                           ray_directions.reshape(n, -<span class="hljs-number">1</span>, <span class="hljs-number">3</span>).permute(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br>    																				.reshape(n, num_rays, <span class="hljs-number">3</span>)<br><br>    <span class="hljs-comment"># 点需要平移，先转换成齐次坐标再作c2m 原点</span><br>    homogeneous_origins = torch.zeros((n, <span class="hljs-number">4</span>, num_rays), device=device) <span class="hljs-comment"># (n, 4, num_rays)</span><br>    homogeneous_origins[:, <span class="hljs-number">3</span>, :] = <span class="hljs-number">1</span><br>    transformed_ray_origins = torch.bmm(cam2world_matrix, homogeneous_origins).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>    												.reshape(n, num_rays, <span class="hljs-number">4</span>)[..., :<span class="hljs-number">3</span>] <span class="hljs-comment"># (n, num_rays, 3(x,y,z)))</span><br><br>    <span class="hljs-comment"># 返回转换之后的采样点，深度，光线方向，相机原点，仰视角，水平角</span><br>    <span class="hljs-keyword">return</span> transformed_points[..., :<span class="hljs-number">3</span>], z_vals, transformed_ray_directions, transformed_ray_origins, pitch, yaw<br></code></pre></td></tr></table></figure><p class="note note-primary">👉 详细代码与注释：https://github.com/SeulQxQ/pi-GAN-read</p></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/" class="category-chain-item">源码解读</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/3D-GAN/">#3D GAN</a></div></div><div class="license-box my-3"><div class="license-title"><div>pi-GAN源码分析</div><div>http://seulqxq.top/posts/27470/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>SeulQxQ</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2024年1月3日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/posts/51769/" title="论文随记（2024.1.4-1.5）"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">论文随记（2024.1.4-1.5）</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/posts/6012/" title="每周总结 -- 心平气和，不急不躁"><span class="hidden-mobile">每周总结 -- 心平气和，不急不躁</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",(function(){Fluid.utils.createScript("https://lib.baomitu.com/valine/1.5.1/Valine.min.js",(function(){var i=Object.assign({appId:"Qx9xEhNNylULQaxbl3lPUT12-gzGzoHsz",appKey:"bPPbrUlDDvOhU5HNAawchAXO",path:"window.location.pathname",placeholder:"留下你的足迹叭，如果愿意话，也可以留下昵称和邮箱哟~ ^_^",avatar:"monsterid",meta:["nick","mail","link"],requiredFields:[],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:null,emojiMaps:null,enableQQ:!0},{el:"#valine",path:window.location.pathname});new Valine(i),Fluid.utils.waitElementVisible("#valine .vcontent",(()=>{var i="#valine .vcontent img:not(.vemoji)";Fluid.plugins.imageCaption(i),Fluid.plugins.fancyBox(i)}))}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><font size="2"><font color="#FFFFFF"><div class="text-center py-3"><div><span id="timeDate">载入天数...</span> <span id="times">载入时分...</span><script>var now=new Date;function createtime(){var n=new Date("05/01/2023 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),document.getElementById("timeDate").innerHTML="🚀 For&nbsp"+dnum+"&nbspdays",document.getElementById("times").innerHTML=hnum+"&nbsphours&nbsp"+mnum+"&nbspminutes&nbsp😊"}setInterval("createtime()",250)</script></div><div class="text-center py-1"><div><font size="3"><font color="#FFFFFF"><span>Copyright © 2023</span> <a href="https://SeulQxQ.github.io" target="_blank" rel="nofollow noopener"><font size="3"><font color="#FFFFFF"><span>👉 SeulQxQ's Dream</span></font></font></a><br></font></font></div></div></div></font></font></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://cdn.staticfile.org/anchor-js/4.2.0/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach((t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")}))},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script src="/js/backgroundize.js"></script></body></html>