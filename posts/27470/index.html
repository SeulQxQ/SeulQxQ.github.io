<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="dark"><head><meta charset="UTF-8"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@500&display=swap" rel="stylesheet"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="SeulQxQ"><meta name="keywords" content="总结，学习，进步！"><meta name="description" content="1. train.py 1. load_images(images, curriculum, device)： 加载图像数据，批量加载。 2. z_sampler(shape, device, dist)：生成随机噪声，每次生成25张图像的噪声。 3. train(rank, world_size, opt)：开始正式训练 1）生成器和辨别器的初始化： 12345678910111213"><meta property="og:type" content="article"><meta property="og:title" content="pi-GAN源码分析"><meta property="og:url" content="http://seulqxq.top/posts/27470/index.html"><meta property="og:site_name" content="Seul"><meta property="og:description" content="1. train.py 1. load_images(images, curriculum, device)： 加载图像数据，批量加载。 2. z_sampler(shape, device, dist)：生成随机噪声，每次生成25张图像的噪声。 3. train(rank, world_size, opt)：开始正式训练 1）生成器和辨别器的初始化： 12345678910111213"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://seulqxq.top/img/index/32.jpg"><meta property="article:published_time" content="2024-01-03T14:11:04.000Z"><meta property="article:modified_time" content="2024-01-09T13:33:50.101Z"><meta property="article:author" content="SeulQxQ"><meta property="article:tag" content="3D GAN"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://seulqxq.top/img/index/32.jpg"><title>pi-GAN源码分析 - Seul</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css"><link rel="stylesheet" href="/css/cloudedGlass.css"><link rel="stylesheet" href="/css/selection.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"seulqxq.top",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:50,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:"❡"},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:1},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><header><div class="header-inner" style="height:90vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>SeulQxQ&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url('/img/index/32.jpg') no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.2)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="pi-GAN源码分析"></span></div><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> SeulQxQ </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2024-01-03 22:11" pubdate>2024年1月3日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 9.9k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 83 分钟</span></div></div><div class="scroll-down-bar"><i class="iconfont icon-arrowdown"></i></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar category-bar" style="margin-right:-1rem"><div class="category-list"><div class="category row nomargin-x"><a class="category-item list-group-item category-item-action col-10 col-md-11 col-xm-11" title="源码解读" id="heading-0607a1f4631b6ebfab5dd48e9412f72a" role="tab" data-toggle="collapse" href="#collapse-0607a1f4631b6ebfab5dd48e9412f72a" aria-expanded="true">源码解读 <span class="list-group-count">(3)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-0607a1f4631b6ebfab5dd48e9412f72a" role="tabpanel" aria-labelledby="heading-0607a1f4631b6ebfab5dd48e9412f72a"><div class="category-post-list"><a href="/posts/41203/" title="EpiGRAF源码分析" class="list-group-item list-group-item-action"><span class="category-post">EpiGRAF源码分析</span> </a><a href="/posts/27470/" title="pi-GAN源码分析" class="list-group-item list-group-item-action active"><span class="category-post">pi-GAN源码分析</span> </a><a href="/posts/15494/" title="NeRF源码解读" class="list-group-item list-group-item-action"><span class="category-post">NeRF源码解读</span></a></div></div></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">pi-GAN源码分析</h1><div class="markdown-body"><h3 id="train.py">1. train.py</h3><pre><code class="hljs">1. load_images(images, curriculum, device)： 加载图像数据，批量加载。
2. z_sampler(shape, device, dist)：生成随机噪声，每次生成25张图像的噪声。
3. train(rank, world_size, opt)：开始正式训练</code></pre><p><strong>1）生成器和辨别器的初始化：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># generator : ImplicitGenerator3d  由generators进入generator.py</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">返回：pixels, torch.cat([pitch, yaw], -1)</span><br><span class="hljs-string">pixels: rgb_final</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>generator = <span class="hljs-built_in">getattr</span>(generators, metadata[<span class="hljs-string">&#x27;generator&#x27;</span>])(SIREN, metadata[<span class="hljs-string">&#x27;latent_dim&#x27;</span>]).to(device) <span class="hljs-comment"># latent_dim = 256</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">return: prediction, latent, position</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-comment"># discriminator : ProgressiveEncoderDiscriminator  由discriminators进入discriminator.py</span><br>discriminator = <span class="hljs-built_in">getattr</span>(discriminators, metadata[<span class="hljs-string">&#x27;discriminator&#x27;</span>])().to(device) <span class="hljs-comment"># 判别器</span><br><br><span class="hljs-comment"># 用于对生成器 generator 的参数进行指数移动平均处理 </span><br><span class="hljs-comment"># decay: 决定了历史权重在平均中的影响大小</span><br>ema = ExponentialMovingAverage(generator.parameters(), decay=<span class="hljs-number">0.999</span>)<br>ema2 = ExponentialMovingAverage(generator.parameters(), decay=<span class="hljs-number">0.9999</span>)<br></code></pre></td></tr></table></figure><p><strong>2）训练辨别器：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-comment"># TRAIN DISCRIMINATOR 训练判别器</span><br><span class="hljs-keyword">with</span> torch.cuda.amp.autocast():<br>    <span class="hljs-comment"># Generate images for discriminator training</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-comment"># 随机噪声 z [9, 256]</span><br>        z = z_sampler((real_imgs.shape[<span class="hljs-number">0</span>], metadata[<span class="hljs-string">&#x27;latent_dim&#x27;</span>]), device=device, dist=metadata[<span class="hljs-string">&#x27;z_dist&#x27;</span>]) <br>        logging.info(<span class="hljs-string">f&quot;train discriminator z.shape: <span class="hljs-subst">&#123;z.shape&#125;</span>&quot;</span>) <span class="hljs-comment"># [9, 256]</span><br>        <span class="hljs-comment"># real_imgs.shape[0] == z.shape[0] --&gt; batch_size(9)</span><br>        split_batch_size = z.shape[<span class="hljs-number">0</span>] // metadata[<span class="hljs-string">&#x27;batch_split&#x27;</span>] <br>        gen_imgs_film = []<br>        gen_imgs = []<br>        gen_positions = []<br>        <span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(metadata[<span class="hljs-string">&#x27;batch_split&#x27;</span>]):   <span class="hljs-comment"># 循环 batch_split 次</span><br>            subset_z = z[split * split_batch_size:(split+<span class="hljs-number">1</span>) * split_batch_size] <span class="hljs-comment"># subset_z [3, 256]</span><br><br>            <span class="hljs-comment"># g_imgs --&gt; pixels [batch_split, 3(RGB), img_size, img_size], </span><br>            <span class="hljs-comment"># g_pos -&gt; torch.cat([pitch, yaw], -1) [batch_size, 2]</span><br>            <span class="hljs-comment"># --&gt; generator.py --&gt; ImplicitGenerator3d --&gt; forward()</span><br>            g_imgs, g_pos = generator_ddp(subset_z, **metadata) <br>            gen_imgs.append(g_imgs)<br>            gen_positions.append(g_pos)<br>            gen_imgs = torch.cat(gen_imgs, axis=<span class="hljs-number">0</span>)  <span class="hljs-comment"># [9, 3, 32, 32] [batch_size, channels, img_size, img_size]</span><br>            gen_positions = torch.cat(gen_positions, axis=<span class="hljs-number">0</span>) <span class="hljs-comment"># [9, 2] [batch_size, 2]</span><br><br>            real_imgs.requires_grad = <span class="hljs-literal">True</span><br><br>            <span class="hljs-comment"># prediction [batch_size, 1]</span><br>            <span class="hljs-comment"># 真实图像的 预测结果</span><br>            <span class="hljs-comment"># --&gt; discriminator.py --&gt; ProgressiveEncoderDiscriminator --&gt; forward()</span><br>            r_preds, _, _ = discriminator_ddp(real_imgs, alpha, **metadata) <br><br>            <span class="hljs-keyword">if</span> metadata[<span class="hljs-string">&#x27;r1_lambda&#x27;</span>] &gt; <span class="hljs-number">0</span>: <span class="hljs-comment"># 梯度下降</span><br>                <span class="hljs-comment"># Gradient penalty 真实图像 梯度惩罚</span><br>                grad_real = torch.autograd.grad(outputs=scaler.scale(r_preds.<span class="hljs-built_in">sum</span>()), inputs=real_imgs, 	<br>                                                create_graph=<span class="hljs-literal">True</span>) <br>                inv_scale = <span class="hljs-number">1.</span>/scaler.get_scale()<br>                grad_real = [p * inv_scale <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> grad_real][<span class="hljs-number">0</span>] <span class="hljs-comment"># 计算梯度  p [batch_size, 3, img_size, img_size]</span><br><br>                <span class="hljs-keyword">with</span> torch.cuda.amp.autocast():<br>                    <span class="hljs-keyword">if</span> metadata[<span class="hljs-string">&#x27;r1_lambda&#x27;</span>] &gt; <span class="hljs-number">0</span>:<br>                        grad_penalty = (grad_real.view(grad_real.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>).norm(<span class="hljs-number">2</span>, dim=<span class="hljs-number">1</span>) ** <span class="hljs-number">2</span>).mean()<br>                        grad_penalty = <span class="hljs-number">0.5</span> * metadata[<span class="hljs-string">&#x27;r1_lambda&#x27;</span>] * grad_penalty<br>                    <span class="hljs-keyword">else</span>:<br>                        grad_penalty = <span class="hljs-number">0</span><br><br>                        <span class="hljs-comment"># 生成器生成的图像 gen_imgs</span><br>                        <span class="hljs-comment"># gen_img_prediction [batch_size, 1], latent [batch_size, 256], </span><br>                        <span class="hljs-comment"># position [batch_size, 2]</span><br>                        g_pred_latent_film, g_pred_position_film = <br>                        discriminator_ddp(gen_imgs_film, alpha, **metadata) <br>                        g_preds, g_pred_latent, g_pred_position = discriminator_ddp(gen_imgs, alpha, <br>                                                                                    **metadata) <br>                        <span class="hljs-comment"># 生成图像 梯度惩罚</span><br>                    <span class="hljs-keyword">if</span> metadata[<span class="hljs-string">&#x27;z_lambda&#x27;</span>] &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> metadata[<span class="hljs-string">&#x27;pos_lambda&#x27;</span>] &gt; <span class="hljs-number">0</span>:<br>                        <span class="hljs-comment"># latent code惩罚</span><br>                        latent_penalty = torch.nn.MSELoss()(g_pred_latent, z) * metadata[<span class="hljs-string">&#x27;z_lambda&#x27;</span>]    <br>                        position_penalty = torch.nn.MSELoss()(g_pred_position, gen_positions) * <br>                        metadata[<span class="hljs-string">&#x27;pos_lambda&#x27;</span>] <span class="hljs-comment"># 位置信息惩罚</span><br><br>                        identity_penalty = latent_penalty + position_penalty    <br>                    <span class="hljs-keyword">else</span>:<br>                        identity_penalty=<span class="hljs-number">0</span><br>                        <span class="hljs-comment"># g_preds: 生成图像的预测结果 r_preds: 真实图像的预测结果</span><br>                        d_loss = torch.nn.functional.softplus(g_preds).mean() +  <br>                        torch.nn.functional.softplus(-r_preds).mean() + grad_penalty + identity_penalty<br>                        discriminator_losses.append(d_loss.item())<br></code></pre></td></tr></table></figure><p><strong>3）训练生成器：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># TRAIN GENERATOR 训练生成器</span><br><span class="hljs-comment"># 随机噪声 z.shape [batch_size, 256]</span><br>z = z_sampler((imgs.shape[<span class="hljs-number">0</span>], metadata[<span class="hljs-string">&#x27;latent_dim&#x27;</span>]), device=device, dist=metadata[<span class="hljs-string">&#x27;z_dist&#x27;</span>]) <br>split_batch_size = z.shape[<span class="hljs-number">0</span>] // metadata[<span class="hljs-string">&#x27;batch_split&#x27;</span>]<br><br><span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(metadata[<span class="hljs-string">&#x27;batch_split&#x27;</span>]):<br>    <span class="hljs-keyword">with</span> torch.cuda.amp.autocast():<br>        subset_z = z[split * split_batch_size:(split+<span class="hljs-number">1</span>) * split_batch_size] <span class="hljs-comment"># subset_z [batch_split, 256]</span><br><br>        <span class="hljs-comment"># gen_imgs [batch_split, 3(rgb), img_size, img_size] gen_positions [batch_split, 2]</span><br>        gen_imgs, gen_positions = generator_ddp(subset_z, **metadata)  <span class="hljs-comment"># 通过噪声生成图像 以及 姿态信息</span><br><br>        <span class="hljs-comment"># g_preds [batch_split, 1] g_pred_latent [batch_split, 256] g_pred_position [batch_split, 2]</span><br>        <span class="hljs-comment"># --&gt; ProgressiveEncoderDiscriminator --&gt; forward()</span><br>        g_preds, g_pred_latent, g_pred_position = discriminator_ddp(gen_imgs, alpha, **metadata) <br>        topk_percentage = <span class="hljs-built_in">max</span>(<span class="hljs-number">0.99</span> ** (discriminator.step/metadata[<span class="hljs-string">&#x27;topk_interval&#x27;</span>]), metadata[<span class="hljs-string">&#x27;topk_v&#x27;</span>]) <br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;topk_interval&#x27;</span> <span class="hljs-keyword">in</span> metadata <span class="hljs-keyword">and</span> <span class="hljs-string">&#x27;topk_v&#x27;</span> <span class="hljs-keyword">in</span> metadata <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br><br>        topk_num = math.ceil(topk_percentage * g_preds.shape[<span class="hljs-number">0</span>])<br><br>        g_preds = torch.topk(g_preds, topk_num, dim=<span class="hljs-number">0</span>).values <span class="hljs-comment"># 选取topk_num个最大值</span><br><br>        <span class="hljs-keyword">if</span> metadata[<span class="hljs-string">&#x27;z_lambda&#x27;</span>] &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> metadata[<span class="hljs-string">&#x27;pos_lambda&#x27;</span>] &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-comment"># 辨别器 latent code 惩罚  位置信息惩罚  信任度惩罚</span><br>            latent_penalty = torch.nn.MSELoss()(g_pred_latent, subset_z) * metadata[<span class="hljs-string">&#x27;z_lambda&#x27;</span>]<br>            position_penalty = torch.nn.MSELoss()(g_pred_position, gen_positions) * metadata[<span class="hljs-string">&#x27;pos_lambda&#x27;</span>]<br>            identity_penalty = latent_penalty + position_penalty<br>        <span class="hljs-keyword">else</span>:<br>            identity_penalty = <span class="hljs-number">0</span><br><br>            g_loss = torch.nn.functional.softplus(-g_preds).mean() + identity_penalty<br>            generator_losses.append(g_loss.item())<br><br>            scaler.scale(g_loss).backward()<br></code></pre></td></tr></table></figure><h3 id="siren.py">2. siren.py</h3><ol type="1"><li>sine_init(m)：初始化sine函数</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sine_init</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Linear):<br>            num_input = m.weight.size(-<span class="hljs-number">1</span>) <span class="hljs-comment"># 输入特征数量</span><br>            <span class="hljs-comment"># uniform_() 方法将张量中的每个元素初始化为从均匀分布中获取的值</span><br>            <span class="hljs-comment"># -np.sqrt(6 / num_input) / 30, np.sqrt(6 / num_input) / 30  He正太初始化</span><br>            m.weight.uniform_(-np.sqrt(<span class="hljs-number">6</span> / num_input) / <span class="hljs-number">30</span>, np.sqrt(<span class="hljs-number">6</span> / num_input) / <span class="hljs-number">30</span>)<br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>CustomMappingNetwork类：映射网络，将随机噪声生成频率和相位。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-comment"># 一次性计算出所有层的频率 γ 和相位 β</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, z</span>):<br>    frequencies_offsets = self.network(z) <span class="hljs-comment"># [batch_size, 4608] 4608 = (8+1)*256*2</span><br>    frequencies = frequencies_offsets[..., :frequencies_offsets.shape[-<span class="hljs-number">1</span>]//<span class="hljs-number">2</span>] <span class="hljs-comment"># [batch_size, 2304]</span><br>    phase_shifts = frequencies_offsets[..., frequencies_offsets.shape[-<span class="hljs-number">1</span>]//<span class="hljs-number">2</span>:] <span class="hljs-comment"># [batch_size, 2304]</span><br><br>    <span class="hljs-keyword">return</span> frequencies, phase_shifts<br></code></pre></td></tr></table></figure><ol start="3" type="1"><li>FiLMLayer类：隐藏层的计算</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FiLMLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim, hidden_dim</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># 初始化线性层</span><br>        self.layer = nn.Linear(input_dim, hidden_dim)   <span class="hljs-comment"># 初始化Linear层 Linear --&gt; FiLMLayer</span><br>    <span class="hljs-comment"># x 输入的位置坐标信息 position x</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, freq, phase_shift</span>):<br>        logging.info(<span class="hljs-string">f&quot;FiLMLayer input_x.shape: <span class="hljs-subst">&#123;x.shape&#125;</span>&quot;</span>)<br>        <span class="hljs-comment"># 计算线性层  x.shape [batch_size, num_rays*num_step, hidden_dim]  layer --&gt; Linear FiLMLayer input</span><br>        x = self.layer(x)       <br>        logging.info(<span class="hljs-string">f&quot;FiLMLayer output_x.shape: <span class="hljs-subst">&#123;x.shape&#125;</span>&quot;</span>)<br>        <span class="hljs-comment"># 通过激活函数计算 FiLM SIREN sin(γx + β)</span><br>        freq = freq.unsqueeze(<span class="hljs-number">1</span>).expand_as(x) <span class="hljs-comment">#  freq.shape [batch_size, num_rays*num_step, hidden_dim]</span><br>        <span class="hljs-comment"># phase_shift.shape [batch_size, num_rays*num_step, hidden_dim]</span><br>        phase_shift = phase_shift.unsqueeze(<span class="hljs-number">1</span>).expand_as(x) <br>			<br>        <span class="hljs-comment"># [batch_size, num_rays*num_step, hidden_dim] FiLM SIREN sin(γ(wx+b) + β)</span><br>        <span class="hljs-keyword">return</span> torch.sin(freq * x + phase_shift) <br></code></pre></td></tr></table></figure><ol start="4" type="1"><li>TALLSIREN模型：SIREN-MLP模型，得出通过MLP的结果</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TALLSIREN</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;Primary SIREN  architecture used in pi-GAN generators.&quot;&quot;&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot; 用于pi-GAN 生成器的主要SIREN架构。&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim=<span class="hljs-number">2</span>, z_dim=<span class="hljs-number">100</span>, hidden_dim=<span class="hljs-number">256</span>, output_dim=<span class="hljs-number">1</span>, device=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.device = device<br>        self.input_dim = input_dim <span class="hljs-comment"># 3 (x, y, z)张图片初始化</span><br>        self.z_dim = z_dim <span class="hljs-comment"># 256</span><br>        self.hidden_dim = hidden_dim <span class="hljs-comment"># 256</span><br>        self.output_dim = output_dim <span class="hljs-comment"># 4   </span><br>        <span class="hljs-comment"># TALLSIREN: input_dim.shape: 3, output_dim.shape: 4</span><br>        logging.info(<span class="hljs-string">f&quot;TALLSIREN: input_dim.shape: <span class="hljs-subst">&#123;input_dim&#125;</span>, output_dim.shape: <span class="hljs-subst">&#123;output_dim&#125;</span>&quot;</span>)<br>        self.network = nn.ModuleList([  <span class="hljs-comment"># 8个FiLM SIREN 层 [3, 256], [256, 256] ... [256, 256]</span><br>            FiLMLayer(input_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>            FiLMLayer(hidden_dim, hidden_dim),<br>        ])<br>        self.final_layer = nn.Linear(hidden_dim, <span class="hljs-number">1</span>) <span class="hljs-comment"># [256, 1] alpha输出层</span><br><br>        self.color_layer_sine = FiLMLayer(hidden_dim + <span class="hljs-number">3</span>, hidden_dim)   <span class="hljs-comment"># 加 ray direction d [256+3, 256]</span><br>        <span class="hljs-comment"># c(x, d) [256, 3] rgb输出层 普通线性层</span><br><br>        self.color_layer_linear = nn.Sequential(nn.Linear(hidden_dim, <span class="hljs-number">3</span>), nn.Sigmoid()) <br>        <br>        <span class="hljs-comment"># mapping network output_dim = (8+1)*256*2</span><br>        self.mapping_network = CustomMappingNetwork(z_dim, <span class="hljs-number">256</span>, (<span class="hljs-built_in">len</span>(self.network) + <span class="hljs-number">1</span>)*hidden_dim*<span class="hljs-number">2</span>) <br><br>        <span class="hljs-comment"># 一次 25 张图片初始化</span><br>        self.network.apply(frequency_init(<span class="hljs-number">25</span>)) <span class="hljs-comment"># 8 层 FiLMLayer 进行初始化</span><br>        self.final_layer.apply(frequency_init(<span class="hljs-number">25</span>))  <span class="hljs-comment"># alpha 输出层初始化</span><br>        self.color_layer_sine.apply(frequency_init(<span class="hljs-number">25</span>)) <span class="hljs-comment"># rgb 额外层初始化</span><br>        self.color_layer_linear.apply(frequency_init(<span class="hljs-number">25</span>))   <span class="hljs-comment"># rgb 输出层初始化</span><br>        self.network[<span class="hljs-number">0</span>].apply(first_layer_film_sine_init) <span class="hljs-comment"># 第一层 FiLMLayer 进行初始化</span><br><br>    <span class="hljs-comment"># input -&gt; transformed_points (generator.py -&gt; coarse_output) </span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, z, ray_directions, **kwargs</span>):<br>        frequencies, phase_shifts = self.mapping_network(z) <span class="hljs-comment"># 从mapping network中获取频率 γ 和相位 β</span><br>        <span class="hljs-keyword">return</span> self.forward_with_frequencies_phase_shifts(<span class="hljs-built_in">input</span>, frequencies, phase_shifts, ray_directions, <br>                                                          **kwargs)<br><br>    <span class="hljs-comment"># SIREN MLP 网络 计算 SIREN sin(γx + β) 输出RGB 和 alpha</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_with_frequencies_phase_shifts</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, frequencies, phase_shifts, ray_directions, **kwargs</span>):<br>        <br>        frequencies = frequencies*<span class="hljs-number">15</span> + <span class="hljs-number">30</span><br>        <span class="hljs-comment"># x.shape [batch_size, num_rays*num_steps, 3] input -&gt; points</span><br>        x = <span class="hljs-built_in">input</span><br><br>        <span class="hljs-keyword">for</span> index, layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.network): <span class="hljs-comment"># 8层隐藏层的计算</span><br>            <span class="hljs-comment"># layer == FiLMLayer(i)   FiLM SIREN sin(γx + β)</span><br>            <span class="hljs-comment"># 每次取一层的 γ 和 β (end - start) == 256</span><br>            start = index * self.hidden_dim<br>            end = (index+<span class="hljs-number">1</span>) * self.hidden_dim<br>            <span class="hljs-comment"># x.shape [batch_size, num_rays*num_steps, hidden_dim] </span><br>            x = layer(x, frequencies[..., start:end], phase_shifts[..., start:end]) <span class="hljs-comment"># -&gt; FiLMLayer forward</span><br>        <span class="hljs-comment"># x通过8层 MLP计算后 的最终输出维度为 [batch_size, num_rays*num_steps, hidden_dim]</span><br>        logging.info(<span class="hljs-string">f&quot;forward_with_frequencies_phase_shifts after x.shape: <span class="hljs-subst">&#123;x.shape&#125;</span>&quot;</span>)<br>        sigma = self.final_layer(x) <span class="hljs-comment"># sigma [batch_size, num_rays*num_steps, 1] alpha 输出层</span><br>        <br>        <span class="hljs-comment"># ray_directions d [batch_size, num_rays*num_steps, 3]</span><br>        <br>        <span class="hljs-comment"># 最后一层的 γ 和 β 259 -&gt; 256</span><br>        rbg = self.color_layer_sine(torch.cat([ray_directions, x], dim=-<span class="hljs-number">1</span>),  <br>                                    frequencies[..., -self.hidden_dim:], phase_shifts[..., -self.hidden_dim:]) <br>        rbg = self.color_layer_linear(rbg) <span class="hljs-comment"># rgb [batch_size, num_rays*num_steps] 输出层 256 -&gt; 3</span><br><br>        <span class="hljs-comment"># 生成图片的时候需要将 alpha 和 rgb 拼接在一起 然后输入到volume rendering中渲染</span><br>        <span class="hljs-keyword">return</span> torch.cat([rbg, sigma], dim=-<span class="hljs-number">1</span>) <span class="hljs-comment"># return [batch_size, num_rays*num_steps, 4] rgb + alpha</span><br></code></pre></td></tr></table></figure></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/" class="category-chain-item">源码解读</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/3D-GAN/">#3D GAN</a></div></div><div class="license-box my-3"><div class="license-title"><div>pi-GAN源码分析</div><div>http://seulqxq.top/posts/27470/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>SeulQxQ</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2024年1月3日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/posts/51769/" title="论文随记（2024.1.4-1.5）"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">论文随记（2024.1.4-1.5）</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/posts/6012/" title="每周总结 -- 心平气和，不急不躁"><span class="hidden-mobile">每周总结 -- 心平气和，不急不躁</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",(function(){Fluid.utils.createScript("https://lib.baomitu.com/valine/1.5.1/Valine.min.js",(function(){var i=Object.assign({appId:"Qx9xEhNNylULQaxbl3lPUT12-gzGzoHsz",appKey:"bPPbrUlDDvOhU5HNAawchAXO",path:"window.location.pathname",placeholder:"留下你的足迹叭，如果愿意话，也可以留下昵称和邮箱哟~ ^_^",avatar:"monsterid",meta:["nick","mail","link"],requiredFields:[],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:null,emojiMaps:null,enableQQ:!0},{el:"#valine",path:window.location.pathname});new Valine(i),Fluid.utils.waitElementVisible("#valine .vcontent",(()=>{var i="#valine .vcontent img:not(.vemoji)";Fluid.plugins.imageCaption(i),Fluid.plugins.fancyBox(i)}))}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><font size="2"><font color="#FFFFFF"><div class="text-center py-3"><div><span id="timeDate">载入天数...</span> <span id="times">载入时分...</span><script>var now=new Date;function createtime(){var n=new Date("05/01/2023 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),document.getElementById("timeDate").innerHTML="🚀 For&nbsp"+dnum+"&nbspdays",document.getElementById("times").innerHTML=hnum+"&nbsphours&nbsp"+mnum+"&nbspminutes&nbsp😊"}setInterval("createtime()",250)</script></div><div class="text-center py-1"><div><font size="3"><font color="#FFFFFF"><span>Copyright © 2023</span> <a href="https://SeulQxQ.github.io" target="_blank" rel="nofollow noopener"><font size="3"><font color="#FFFFFF"><span>👉 SeulQxQ's Dream</span></font></font></a><br></font></font></div></div></div></font></font></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://cdn.staticfile.org/anchor-js/4.2.0/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach((t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")}))},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script src="/js/backgroundize.js"></script></body></html>