<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="SeulQxQ"><meta name="keywords" content=""><meta name="description" content="Deep3DSketch+: Rapid 3D Modeling from Single Free-hand Sketches 1 引言 &amp; 相关工作 1. 引言 ​ 本文提出了一种名为Deep3DSketch+的新型3D建模方法，该方法可以从单个手绘草图中生成高保真度的3D模型。Deep3DSketch+采用了端到端的神经网络结构，包括&#x3D;&#x3D;轻量级生成网络&#x3D;&#x3D;和&#x3D;&#x3D;结构感知的对抗"><meta property="og:type" content="article"><meta property="og:title" content="Deep3DSketch+_ Rapid 3D Modeling from Single Free-hand Sketches"><meta property="og:url" content="http://seulqxq.top/posts/43769/index.html"><meta property="og:site_name" content="Seul"><meta property="og:description" content="Deep3DSketch+: Rapid 3D Modeling from Single Free-hand Sketches 1 引言 &amp; 相关工作 1. 引言 ​ 本文提出了一种名为Deep3DSketch+的新型3D建模方法，该方法可以从单个手绘草图中生成高保真度的3D模型。Deep3DSketch+采用了端到端的神经网络结构，包括&#x3D;&#x3D;轻量级生成网络&#x3D;&#x3D;和&#x3D;&#x3D;结构感知的对抗"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://seulqxq.top/img/index/15.jpg"><meta property="article:published_time" content="2023-10-17T07:29:55.000Z"><meta property="article:modified_time" content="2023-10-17T07:36:54.589Z"><meta property="article:author" content="SeulQxQ"><meta property="article:tag" content="3D"><meta property="article:tag" content="略读"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://seulqxq.top/img/index/15.jpg"><title>Deep3DSketch+_ Rapid 3D Modeling from Single Free-hand Sketches - Seul</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css"><link rel="stylesheet" href="/css/cloudedGlass.css"><link rel="stylesheet" href="/css/selection.css"><link rel="stylesheet" href="/css/iconfont_pin/pin.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"seulqxq.top",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:50,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><header><div class="header-inner" style="height:90vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>SeulQxQ&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url('/img/2.jpg') no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.2)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="Deep3DSketch+_ Rapid 3D Modeling from Single Free-hand Sketches"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-10-17 15:29" pubdate>2023年10月17日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 2.6k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 22 分钟</span></div></div><div class="scroll-down-bar"><i class="iconfont icon-arrowdown"></i></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">Deep3DSketch+_ Rapid 3D Modeling from Single Free-hand Sketches</h1><div class="markdown-body"><h3 id="deep3dsketch-rapid-3d-modeling-from-single-free-hand-sketches">Deep3DSketch+: Rapid 3D Modeling from Single Free-hand Sketches</h3><h4 id="引言-相关工作">1 引言 &amp; 相关工作</h4><p><strong>1. 引言</strong></p><p>​ 本文提出了一种名为Deep3DSketch+的新型3D建模方法，该方法可以从单个手绘草图中生成高保真度的3D模型。Deep3DSketch+采用了端到端的神经网络结构，包括==轻量级生成网络==和==结构感知的对抗训练方法==。该方法还引入了笔画增强模块==(SEM)==，以提高网络的结构特征提取能力。</p><p><strong>2. 相关工作</strong></p><p>​ 现有的手绘草图3D建模方法可以分为两类：端到端方法和交互式方法。交互式方法需要进行顺序步骤分解或特定的绘画手势或注释。本文提出的Deep3DSketch+方法采用了端到端的神经网络结构，不需要输入多个草图或视图信息，可以从单个手绘草图中生成高保真度的3D模型。</p><p>​ 基于手绘草图的建模和传统的单目3D重建有很大的区别，草图的稀疏性和抽象性以及缺乏纹理需要额外的线索来产生高质量的3D形状。<code>需要解决</code>。</p><h4 id="方法-模型">2 方法 &amp; 模型</h4><p><strong>1. Overview:</strong></p><figure><img src="image-20231015163031452.png" srcset="/img/loading.gif" lazyload alt="overview"><figcaption aria-hidden="true">overview</figcaption></figure><p><strong>2. View-aware and Structure-aware 3D Modeling</strong></p><p><code>Mesh Generation G:</code> 主干为编码器-解码器结构</p><p><code>Encoder E:</code> 由于草图是稀疏且模糊的输入形式，编码器E首先将输入的草图转换为 <em>latent shape code</em> <span class="math inline">\(z_s\)</span> ，这样可以在涉及语义类别和概念形状的粗略级别上概括草图。</p><p><code>Decoder D:</code> 级联的上采样块组成的解码器D用于计算模板网格的顶点偏移，并通过以增加的空间分辨率逐渐推断3D形状信息来使其变形以得到具有精细细节的输出网格 <span class="math inline">\(M_Θ = D{(z_s)}\)</span>。</p><p>接下来，利用可微分渲染器渲染所生成的网格 <span class="math inline">\(M_Θ\)</span>，来生成轮廓 <span class="math inline">\(S_Θ\)</span>。该网络是端到端的训练，通过近似梯度的微分渲染器的监督渲染。</p><p><strong>3. Shape discriminator and Multi-view Sampling</strong></p><p>​ 由于草图的稀疏性质和单视图轮廓约束的唯一监督，编码器-解码器结构化生成器G不能有效地获得高质量的3D形状。必须使用额外的线索来关注细粒度和逼真的对象结构。因此引入==形状匹配与多视点采样==。</p><p>​ 该辨别器为CNN网络，它在训练过程中==引入来自真实的数据集的3D形状==，以迫使网格生成器G生成逼真的形状，同时在推理过程中保持生成过程的效率。具体地说，将从预测网格生成的轮廓和从手动设计的网格渲染的轮廓输入到神经网络。同时，随机采样N个相机姿态从姿态分布p中，保证生成的网格细节合理、逼真。</p><p><strong>4. Stroke Enhancement Module</strong>(新模块，但是大概率用不上)</p><figure><img src="image-20231015171503579.png" srcset="/img/loading.gif" lazyload alt="image-20231015171503579"><figcaption aria-hidden="true">image-20231015171503579</figcaption></figure><p>​ 由于输入草图和投影轮廓是单一颜色的，不能有效地获得深度预测结果。因此通过引入笔划增强模块（SEM）来充分利用单色信息进行特征提取。SEM由一个位置感知注意力模块组成，该模块将广泛的上下文信息编码到局部特征中以学习特征的空间相互依赖性。 <span class="math display">\[ s_{i j}=\frac{\exp \left(B_{i} * C_{j}\right)}{\sum_{i=1}^{W} \exp \left(B_{i} * C_{j}\right)} \]</span> 来自轮廓 $A R^{c×n×m} $ 的局部特征被送到卷积层形成两个局部特征 <span class="math inline">\(B,~C \in R^{C\times W}\)</span>，其中 <span class="math inline">\(W~ = ~M \times N\)</span> 为像素的数量，而另一个卷积层用于形成特征图 $D R^{C N M} $ 。C和B的转置进行矩阵乘法，然后由 <em>softmax</em> 层生成注意力图 <span class="math inline">\(S \in R^{W \times W}\)</span> ，从而增强了利用由轮廓表示的关键结构信息的能力。注意力图用于通过原始特征和所有位置上的特征的加权和来产生输出F: <span class="math display">\[ F_{j} ~ = ~ \lambda\sum_{i=1}^{W}(s_jD_j) ~ + ~ A_j \]</span> <strong>5. Loss Function</strong></p><p>​ 损失函数来自三个组件，包括有：multi-scale <em>mIoU loss</em> <span class="math inline">\(\mathcal{L}_{sp}\)</span>，<em>flatten loss</em>，<em>laplacian smooth loss</em> <span class="math inline">\(\mathcal{L}_{r}\)</span>，<em>structure-aware GAN loss</em> <span class="math inline">\(\mathcal{L}_{sd}\)</span>。 <span class="math display">\[ \mathcal{L}_{sp} ~=~ \sum_{i=1}^{N} \lambda_{si} \mathcal{L}^i_{iou} \\ \mathcal{L}_{iou}(S_1, ~ S_2) ~= ~1~ - ~\frac{\left \| S_1\otimes S_2 \right \|_1 }{\left \| S_1 \otimes S_2-S_1 \otimes S_2 \right \|_1 } \]</span> S1和S2是渲染的轮廓。</p><p>​ 非饱和GAN损失： <span class="math display">\[ \begin{aligned} \mathcal{L}_{s d} &amp; =\mathbf{E}_{\mathbf{z}_{\mathbf{v}} \sim p_{z_{v}}, \xi \sim p_{\xi}}\left[f\left(C N N_{\theta_{D}}(R(M, \xi))\right)\right] \\ &amp; +\mathbf{E}_{\mathbf{z}_{\mathbf{v r}} \sim p_{z_{v r}}, \xi \sim p_{\xi}}\left[f\left(-C N N_{\theta_{D}}\left(R\left(M_{r}, \xi\right)\right)\right)\right] \\ &amp; \text { wheref }(u)=-\log (1+\exp (-u)) \end{aligned} \]</span> ​ 总损失函数Loss计算为三个分量的加权和： <span class="math display">\[ Loss = \mathcal{L}_{sp}+\mathcal{L}_{r}+\lambda_{sd}\mathcal{L}_{sd} \]</span></p><h4 id="实验-分析">3 实验 &amp; 分析</h4><p><strong>1. 消融实验</strong></p><p>​ 对形状鉴别器(SD)与笔划增强模块进行效用实验。</p><figure><img src="image-20231015180807656.png" srcset="/img/loading.gif" lazyload alt="image-20231015180807656"><figcaption aria-hidden="true">image-20231015180807656</figcaption></figure><blockquote><p>随机视点采样与形状识别（SD）相结合，以真实的形状作为输入，允许神经网络从多个角度“看到”真实的形状，从而能够预测合理的结构信息，这些信息甚至不存在于草图中（由于视点约束，可能无法表示）。</p></blockquote></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/3D/">#3D</a> <a href="/tags/%E7%95%A5%E8%AF%BB/">#略读</a></div></div><div class="license-box my-3"><div class="license-title"><div>Deep3DSketch+_ Rapid 3D Modeling from Single Free-hand Sketches</div><div>http://seulqxq.top/posts/43769/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>SeulQxQ</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年10月17日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/posts/35133/" title="A Survey on Deep Generative 3D-aware Image Synthesis"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">A Survey on Deep Generative 3D-aware Image Synthesis</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/posts/39032/" title="pi-GAN_ Periodic Implicit Generative Adversarial Networks for 3D-Aware"><span class="hidden-mobile">pi-GAN_ Periodic Implicit Generative Adversarial Networks for 3D-Aware</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><script type="text/javascript">Fluid.utils.loadComments("#comments",(function(){var t="github-light",e="github-dark",s=document.documentElement.getAttribute("data-user-color-scheme");s="dark"===s?e:t,window.UtterancesThemeLight=t,window.UtterancesThemeDark=e;var n=document.createElement("script");n.setAttribute("src","https://utteranc.es/client.js"),n.setAttribute("repo","SeulQxQ/blog-comments"),n.setAttribute("issue-term","pathname"),n.setAttribute("label","utterances"),n.setAttribute("theme",s),n.setAttribute("crossorigin","anonymous"),document.getElementById("comments").appendChild(n)}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://hexo.fluid-dev.com/docs/guide" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://cdn.staticfile.org/anchor-js/4.2.0/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach((t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")}))},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script src="/js/backgroundize.js"></script></body></html>