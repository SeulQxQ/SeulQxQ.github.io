<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="SeulQxQ"><meta name="keywords" content=""><meta name="description" content="Summary  ​ Over the past one month, I have delved into the realm of computer graphics, exploring concepts like Camera Transformation, Projection Transformation, and Viewport Transformation. Du"><meta property="og:type" content="article"><meta property="og:title" content="Summary"><meta property="og:url" content="http://seulqxq.top/posts/39277/index.html"><meta property="og:site_name" content="Seul"><meta property="og:description" content="Summary  ​ Over the past one month, I have delved into the realm of computer graphics, exploring concepts like Camera Transformation, Projection Transformation, and Viewport Transformation. Du"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://seulqxq.top/img/index/1.jpg"><meta property="article:published_time" content="2023-08-06T01:30:02.000Z"><meta property="article:modified_time" content="2023-10-22T10:14:51.992Z"><meta property="article:author" content="SeulQxQ"><meta property="article:tag" content="总结"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://seulqxq.top/img/index/1.jpg"><title>Summary - Seul</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/toubudaziji.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css"><link rel="stylesheet" href="/css/cloudedGlass.css"><link rel="stylesheet" href="/css/selection.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"seulqxq.top",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:60,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><header><div class="header-inner" style="height:90vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>SeulQxQ&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url('/img/2.jpg') no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.2)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="Summary"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-08-06 09:30" pubdate>2023年8月6日 上午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 4.8k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 41 分钟</span></div></div><div class="scroll-down-bar"><i class="iconfont icon-arrowdown"></i></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">Summary</h1><div class="markdown-body"><div align="center"><h3>Summary</h3></div><p>​ Over the past one month, I have delved into the realm of computer graphics, exploring concepts like Camera Transformation, Projection Transformation, and Viewport Transformation. During this time, I also gained insights into camera parameters, camera coordinate systems, and world coordinate systems, developing proficiency in transforming coordinates between them. Furthermore, I manually deduced rendering formulas to deepen my understanding. In parallel, I devoted time to studying Deep Learning, broadening my knowledge in this fascinating field.</p><p>Following my theoretical endeavors, I embarked on a coding journey to restructure NeRF (Neural Radiance Fields). My aim was to rewrite the NeRF code from the Tensorflow framework to PyTorch framework. This hands-on process not only enhanced my coding skills but also provided me with a profound comprehension of NeRF, rendering techniques, and the workings of Multi-Layer Perceptrons (MLP).</p><p>​ In particular, I came to understand two essential aspects of NeRF's code:</p><p>​ Position Encoding: The authors of NeRF utilized Position Encoding to address challenges associated with accurately representing high-frequency variations in color and geometry. To achieve this, they employed a clever mapping of the input coordinates (x, y, z, and view coordinate) to a higher-dimensional space using high-frequency functions. Notably, they used sine and cosine functions (sin^2(Lx) and cos^2(Lx), with L=10) to transform the three-dimensional input into a sixty-dimensional space.</p><p>​ NeRF Model: In the code implementation, NeRF comprises an MLP network with eight fully-connected ReLU layers. Each layer features 256 dimensions, except for the fifth layer, which acts as a skip connection and contains 316 features (256 from the previous layers and 60 from the positional encoding). Additionally, there is an extra layer responsible for outputting the volume density and a 256-dimensional feature vector. This feature vector is combined with the positional encoding of the input viewing direction (γ(d)), and the resulting combination is processed by an additional fully-connected ReLU layer with 128 channels. Finally, a final layer with a sigmoid activation function yields the emitted RGB radiance at position x, as viewed by a ray with direction d.</p><p>​ Loss: The loss function employed in the code is straightforward. It calculates the L2 loss between the rendered image and the ground truth image, and subsequently optimizes the model based on this loss.</p><p>​ Besides, I read tow papers, named ‘Instant Neural Graphics Primitives with a Multiresolution Hash Encoding’ and ‘Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion’ respectively.</p><p>​ The paper "Instant Neural Graphics Primitives with a Multiresolution Hash Encoding" introduces a novel approach called "Instant Neural Graphics Primitives (Instant-NGP)" with the integration of a multiresolution hash encoding. This method aims to improve the efficiency and performance of existing neural rendering algorithms.</p><p>The core idea of the paper is to utilize multiresolution hash encoding to encode the geometry and material information of scenes, enabling efficient rendering of complex 3D scenes. Instant-NGP represents scenes as a collection of basic graphics primitives (such as spheres, cubes, etc.) and associates each primitive with its corresponding geometry and material information using hash encoding, resulting in an efficient scene representation and rendering process.</p><p>In the experimental section, the paper demonstrates the outstanding performance of the Instant-NGP method in various 3D scene rendering tasks. Compared to traditional ray-tracing-based rendering algorithms, Instant-NGP achieves significant improvements in computation speed and memory usage. Furthermore, Instant-NGP exhibits high scalability and versatility, making it suitable for a wide range of 3D scene rendering tasks.</p><figure><img src="1.jpg" srcset="/img/loading.gif" lazyload alt="framework"><figcaption aria-hidden="true">framework</figcaption></figure><figure><img src="2.jpg" srcset="/img/loading.gif" lazyload alt="framework"><figcaption aria-hidden="true">framework</figcaption></figure><p>​ After read the paper, I run it’s code successfully, but it’s code written by CUDA, I just learned how to use.</p><p>The paper "Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion" proposes an iterative optimization framework based on bootstrapped radiance field inversion for estimating the 3D shape, pose, and appearance of objects from a single image. The method iteratively optimizes the estimated radiance field and object geometry while utilizing a deep neural network to estimate the object's appearance. The main advantage of this method is its ability to estimate the 3D shape, pose, and appearance of objects from a single image without requiring multiple images or prior knowledge.</p><p>​ Specifically, the method first uses an initial radiance field to generate a set of virtual images, which are then compared to the original image to compute an error function. Next, the method updates the estimated radiance field and object geometry using the error function and employs a deep neural network to estimate the object's appearance. By iteratively optimizing the estimated radiance field and object geometry while utilizing a deep neural network to estimate the object's appearance, the method achieves the goal of estimating the 3D shape, pose, and appearance of objects from a single image.</p><p>​ The method is evaluated on multiple datasets, demonstrating its effectiveness in estimating the 3D shape, pose, and appearance of objects from a single image. Additionally, data augmentation techniques and loss functions are used to improve the accuracy of the estimations.</p><p>​ The paper’s code has not run successfully, and I will debug the code in the next week.</p></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/" class="category-chain-item">工作总结</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%80%BB%E7%BB%93/">#总结</a></div></div><div class="license-box my-3"><div class="license-title"><div>Summary</div><div>http://seulqxq.top/posts/39277/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>SeulQxQ</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年8月6日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/posts/8519/" title="每周总结(23.08.07-23.08.13)"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">每周总结(23.08.07-23.08.13)</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/posts/14876/" title="基础知识"><span class="hidden-mobile">基础知识</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://hexo.fluid-dev.com/docs/guide" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://cdn.staticfile.org/anchor-js/4.2.0/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach((t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")}))},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script src="/js/backgroundize.js"></script></body></html>