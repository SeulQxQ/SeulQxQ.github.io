<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="SeulQxQ"><meta name="keywords" content=""><meta name="description" content="仅使用单视图 2D 照片集合的无监督生成高质量的多视图一致图像和 3D 形状一直是一个长期的挑战。  3D感知GAN方法可以保证视图一致性，神级辐射场用来开发3D感知图像合成技术。 生成纹理：可学习的3D位置嵌入编码，补偿高频图像细节。仅使用siren的网络缺乏细节图像。 早期的方法利用显式体素或体积表示，因此分辨率有限。最近，神经隐式场景表示被集成到生成对抗模型中，实现了更好的内存效率"><meta property="og:type" content="article"><meta property="og:title" content="毕业设计"><meta property="og:url" content="http://seulqxq.top/posts/26243/index.html"><meta property="og:site_name" content="Seul"><meta property="og:description" content="仅使用单视图 2D 照片集合的无监督生成高质量的多视图一致图像和 3D 形状一直是一个长期的挑战。  3D感知GAN方法可以保证视图一致性，神级辐射场用来开发3D感知图像合成技术。 生成纹理：可学习的3D位置嵌入编码，补偿高频图像细节。仅使用siren的网络缺乏细节图像。 早期的方法利用显式体素或体积表示，因此分辨率有限。最近，神经隐式场景表示被集成到生成对抗模型中，实现了更好的内存效率"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://seulqxq.top/img/index/17.jpg"><meta property="article:published_time" content="2023-12-15T16:00:00.000Z"><meta property="article:modified_time" content="2024-01-08T02:00:00.578Z"><meta property="article:author" content="SeulQxQ"><meta property="article:tag" content="简记"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://seulqxq.top/img/index/17.jpg"><title>毕业设计 - Seul</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css"><link rel="stylesheet" href="/css/cloudedGlass.css"><link rel="stylesheet" href="/css/selection.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"seulqxq.top",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:50,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><header><div class="header-inner" style="height:90vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>SeulQxQ&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url('/img/2.jpg') no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.2)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="毕业设计"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-12-16 00:00" pubdate>2023年12月16日 凌晨</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 4.3k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 36 分钟</span></div></div><div class="scroll-down-bar"><i class="iconfont icon-arrowdown"></i></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar category-bar" style="margin-right:-1rem"><div class="category-list"><div class="category row nomargin-x"><a class="category-item list-group-item category-item-action col-10 col-md-11 col-xm-11" title="简记" id="heading-0b37862230437d874ebde2c37c40e6a2" role="tab" data-toggle="collapse" href="#collapse-0b37862230437d874ebde2c37c40e6a2" aria-expanded="true">简记 <span class="list-group-count">(4)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-0b37862230437d874ebde2c37c40e6a2" role="tabpanel" aria-labelledby="heading-0b37862230437d874ebde2c37c40e6a2"><div class="category-post-list"><a href="/posts/51769/" title="论文随记（2024.1.4-1.5）" class="list-group-item list-group-item-action"><span class="category-post">论文随记（2024.1.4-1.5）</span> </a><a href="/posts/64309/" title="小论文实验结果" class="list-group-item list-group-item-action"><span class="category-post">小论文实验结果</span> </a><a href="/posts/52414/" title="小论文方法" class="list-group-item list-group-item-action"><span class="category-post">小论文方法</span> </a><a href="/posts/26243/" title="毕业设计" class="list-group-item list-group-item-action active"><span class="category-post">毕业设计</span></a></div></div></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">毕业设计</h1><div class="markdown-body"><p>仅使用单视图 2D 照片集合的无监督生成高质量的多视图一致图像和 3D 形状一直是一个长期的挑战。</p><ol type="1"><li><p>3D感知GAN方法可以保证视图一致性，神级辐射场用来开发3D感知图像合成技术。</p></li><li><p>生成纹理：可学习的3D位置嵌入编码，补偿高频图像细节。仅使用siren的网络缺乏细节图像。</p></li><li><p>早期的方法利用显式体素或体积表示，因此分辨率有限。最近，神经隐式场景表示被集成到生成对抗模型中，实现了更好的内存效率和多视图一致性</p></li><li><p>可学习的3D特征网格，，用于坐标嵌入的局部采样（ecoord）。为了预测具有 2D 视图方向 d 的 3D 点 x 的颜色，我们通过双三次插值从特征网格中采样一个局部特征向量，然后将其作为附加输入输入到颜色分支中。它有助于保留更细粒度的图像细节。</p></li></ol><p>EG3D</p><ol start="2" type="1"><li>EG3D目标：引入了一种新的生成器架构，用于从单视图 2D 照片集合中学习无监督 3D 表示学习，该架构旨在提高渲染的计算效率，同时保持对 3D 基础神经渲染为真。</li><li>通过混合显式隐式 3D 表示来提高基于 3D 的渲染的计算效率，该表示在不影响表现力的情况下，比完全隐式或显式方法提供了显着的速度和内存优势。</li><li>我们引入了一个基于三平面的3D GAN框架，该框架既高效又富有表现力，以实现高分辨率的几何感知图像合成。</li><li>显式表示，如离散体素网格，可以快速评估，但经常会产生沉重的内存开销，这使得它们难以扩展到高分辨率或复杂场景。隐式表示或坐标网络，通过将场景表示为连续函数，在内存效率和场景复杂性方面提供了潜在的优势。在实践中，这些隐式架构使用大型全连接网络进行评估缓慢，因为每个查询都需要通过网络进行完全传递。因此，完全显式和隐式表示提供了互补的好处。</li><li>局部隐式表示 [3, 5, 23, 56] 和混合显式隐式表示 [11,35,39,53] 通过提供计算和内存高效的架构来组合这两种类型的表示的好处。受这些想法的启发，我们设计了一种新的混合显式隐式3D感知网络，该网络使用内存高效的三平面表示显式地存储由轻量级隐式特征解码器聚合的轴对齐平面上的特征，以实现高效的体绘制(图2c)。</li><li>在三平面公式中，我们沿着三个轴对齐的正交特征平面对齐我们的显式特征，每个平面分辨率为 N × N × C（图 2c），N 是空间分辨率，C 是通道数。我们通过将任何 3D 位置 x ∈ R3 投影到三个特征平面中的每一个上，通过双线性插值检索相应的特征向量 (Fxy , Fxz , Fyz )，并通过求和聚合三个特征向量。一个额外的轻量级解码器网络，实现为一个小的 MLP，将聚合的 3D 特征 F 解释为颜色和密度。这些量使用(神经)体绘制渲染成RGB图像[41,45]。</li><li>最后，我们的三平面表示与这些替代方案相比具有另一个关键优势：特征平面可以使用现成的基于 2D CNN 的生成器生成，从而能够使用接下来讨论的 GAN 框架跨 3D 表示进行泛化。</li><li>在 GAN 设置中，我们的神经渲染器不是生成 RGB 图像，而是聚合来自每个 32 通道三平面的特征，并从给定的相机姿势预测 32 通道特征图像。接下来是一个“超分辨率”模块，用于对这些原始神经渲染图像进行上采样和细化（第 4.2 节）</li><li>在我们的 GAN 设置中使用的三平面表示的特征由 StyleGAN2 CNN 生成器生成。随机潜在代码和相机参数首先由映射网络处理以产生中间潜在代码，然后调制单独合成网络的卷积核。</li></ol><p>Tri-MipRF</p><ol type="1"><li>我们提出了一种新颖的 Tri-Mip 编码，它支持神经辐射场的瞬时重建和反锯齿高保真渲染。关键是在三个正交 mipmap 中分解预过滤的 3D 特征空间。通过这种方式，我们可以利用 2D 预过滤特征图来有效地执行 3D 区域采样，这在不牺牲效率的情况下显着提高了渲染质量。</li></ol><p>pi-GAN</p><ol type="1"><li><p>现有方法以两种方式不足：首先，它们可能缺乏潜在的 3D 表示或依赖于视图不一致的渲染，因此合成不是多视图一致的图像；其次，它们通常依赖于表达能力不够的表示网络架构，因此它们的结果缺乏图像质量。我们提出了一种新的生成模型，称为周期性隐式生成对抗网络(π-GAN或pi-GAN)，用于高质量的3D感知图像合成。π-GAN利用具有周期性激活函数和体绘制的神经表示将场景表示为视图一致的辐射场。</p></li><li><p>生成对抗网络(GANs)能够生成高分辨率、逼真的图像[25,26,27]。然而，由于缺乏逼真的 3D 训练数据，这些 GAN 通常仅限于两个维度；因此，它们不能支持诸如合成单个对象的多个视图等任务。3D感知图像合成提供了从2D图像中学习无监督神经场景表示。学习到的表示可用于从新的相机姿势渲染视图一致的图像[44,57,19]。</p></li><li><p>给定输入噪声，π-GAN 条件由 SIREN 网络 [59] 表示的隐式辐射场，这是一个具有周期性激活函数的全连接网络。条件辐射场将 3D 位置和 2D 观察方向映射到与视图相关的辐射和视图无关的体积密度 [23, 38]。使用依赖于经典体绘制技术的可微体绘制方法，我们可以从任意相机姿势[42]渲染辐射场。</p></li><li><p>π-GAN改进了以前3D感知图像合成方法的图像质量和视图一致性，如图1所示。该方法利用基于siren的神经辐射场表示来鼓励多视图一致性，允许从广泛的相机姿势渲染并提供可解释的3D结构。利用周期激活函数的SIREN隐式场景表示在表示精细细节方面比ReLU隐式表示更有能力，并使π-GAN渲染比以前工作更清晰的图像。</p></li><li><p>除了引入 π-GAN 之外，我们还做出了两个额外的技术贡献。首先，我们观察到，虽然现有工作通过将输入噪声连接到一个或多个层来调节基于 ReLU 的辐射场，但对于周期激活的隐式神经表示（SIREN）来说，逐个连接的条件是次优的。相反，我们建议使用映射网络通过特征线性调制 (FiLM) [51, 9] 来调节 SIREN 中的层。这一贡献通常可以应用于 GAN 之外的 SIREN 架构。其次，我们引入了一种渐进式增长策略，该策略受到先前在 2D 卷积 GAN [25] 中取得成功的启发，以加速训练和抵消 3D GAN 的计算复杂度增加。</p></li><li><p>我们建议利用周期激活函数进行隐式神经表示，并证明这些网络被称为正弦表示网络或SIRENs。我们提出了SIREN，这是一种用于隐式神经表示的简单神经网络架构，它使用正弦作为周期激活函数：(具有周期性激活函数的隐式神经表示)</p><p>$Φ (x) = Wn (φn−1 ◦ φn−2 ◦ . . . ◦ φ0) (x) + bn, xi 7 → φi (xi) = sin (Wixi + bi) . $这里，φi : RMi 7 → RNi 是网络的第 i 层。它由权重矩阵 Wi ∈ RNi×Mi 定义的仿射变换和应用于输入 xi ∈ RMi 的偏差 bi ∈ RNi 组成，然后是应用于结果向量的每个组件的正弦非线性。</p><figure><img src="image-20231215215813115.png" srcset="/img/loading.gif" lazyload alt="image-20231215215813115"><figcaption aria-hidden="true">image-20231215215813115</figcaption></figure></li><li><p>FLiM(Feature-wise Linear Modulation): 特征线性调制</p><figure><img src="image-20231215220018656-17026488204801.png" srcset="/img/loading.gif" lazyload alt="image-20231215220018656"><figcaption aria-hidden="true">image-20231215220018656</figcaption></figure></li><li><p>FiLM 模型从少量数据中学习，以泛化到比训练期间看到的更复杂和/或截然不同的数据。FLiM 增强了网络生成复杂和多变场景的能力。FLiM 有助于提高生成图像的质量和多样性，特别是在生成具有复杂几何和光照条件的三维场景时。</p></li><li><p>具体来说，我们使用 SIREN 作为我们框架的表示网络架构，并结合受 NeRF 启发的神经渲染技术。然而，SIREN 和 NeRF 仅在对单个对象或场景的过度拟合的背景下进行了探索，而我们研究了这些开创性作品在 3D GAN 中的应用方面的组合。探索训练由自然 2D 数据监督的神经隐式 GAN 的独特挑战是我们工作的核心贡献之一。</p></li><li><p>我们利用受 StyleGAN 启发的映射网络，该网络通过 FiLM 条件在单个输入噪声向量上调节整个 MLP。</p></li><li><p>我们的生成器 GθG (z, ξ) 不是直接从输入噪声 z 生成 2D 图像，而是生成以 z 为条件的隐式辐射场。这个辐射场是使用体绘制渲染渲染渲染的，以从一些相机姿势 ξ 生成 2D 图像。</p></li><li><p>在训练时，生成的图像被引导到传统的卷积鉴别器进行对抗训练。在测试时，辐射场可以从任意相机姿势渲染以产生视图一致的图像。</p></li><li><p>我们用神经辐射场隐式表示 3D 对象，该神经辐射场参数化为多层感知器 (MLP)，它将空间 x = (x, y, z) 中的 3D 坐标和观察方向 d 作为输入。神经辐射场输出空间变化的密度σ(x): R3→R和视相关颜色(r, g, b) =c(x, d): R5→R3。此外，我们利用StyleGAN启发的映射网络通过FiLM条件反射在噪声向量z上调节SIREN[51,9]。，我们将表示的 FiLM-ed SIREN backbone 形式化为:</p><p><span class="math display">\[\begin{aligned} \Phi(\mathbf{x})= &amp; \phi_{n-1} \circ \phi_{n-2} \circ \ldots \circ \phi_{0}(\mathbf{x}) \\ &amp; \phi_{i}\left(\mathbf{x}_{i}\right)=\sin \left(\gamma_{i} \cdot\left(\mathbf{W}_{i} \mathbf{x}_{i}+\mathbf{b}_{i}\right)+\boldsymbol{\beta}_{i}\right) \end{aligned}\]</span></p></li><li><p>神经体渲染</p></li></ol><p><span class="math display">\[\begin{array}{l} \mathbf{C}(\mathbf{r})=\int_{t_{n}}^{t_{f}} T(t) \sigma(\mathbf{r}(t)) \mathbf{c}(\mathbf{r}(t), \mathbf{d}) d t \\ \text { where } \quad T(t)=\exp \left(-\int_{t_{n}}^{t} \sigma(\mathbf{r}(s)) d s\right) . \end{array} \]</span></p><p>多视图不一致</p><ol type="1"><li><p>在没有几何约束的情况下，从一组 2D 训练图像中优化辐射场可能会遇到关键的退化解决方案，从而导致基于 NeRF 的生成模型中的多视图不一致问题。一些方法提出了颜色和形状的多视图正则化，以提高光度和几何一致性。采用不同的策略来减少2D渲染器带来的视图不一致工件[12,33,82,103,149]。</p></li><li><p>其实核心就在于体素渲染的时候，密度和颜色本身是跟视角无关的，只跟空间位置有关，不同视角的光线打到同一个位置上，他们的密度是相同的，所以相当于利用了多视图之间的一致性。</p><p>可能这时候就要有伙伴问了，颜色的建模是跟输入角度有关的呀？为什么说是多视图一致的呢。</p><p>这就是NeRF里面最微妙的一部分，虽然角度也作为了输入，但是实际上，<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=神经网络&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2718837219%7D">神经网络</a>是可以泛化到未知的角度的。看起来不可思议对不对，但是很多理论跟实验都证明了，MLP本身可以实现某种插值的效果，即便输入是离散的采样，最终也能学到未知的某个位置的采样值，类似于“插值”的功能。</p></li></ol></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E7%AE%80%E8%AE%B0/" class="category-chain-item">简记</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E7%AE%80%E8%AE%B0/">#简记</a></div></div><div class="license-box my-3"><div class="license-title"><div>毕业设计</div><div>http://seulqxq.top/posts/26243/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>SeulQxQ</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年12月16日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/posts/57809/" title="每周总结 -- 爱意随风起，风止意难平"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">每周总结 -- 爱意随风起，风止意难平</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/posts/32257/" title="TensoRF - Tensorial Radiance Fields"><span class="hidden-mobile">TensoRF - Tensorial Radiance Fields</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><script type="text/javascript">Fluid.utils.loadComments("#comments",(function(){var t="github-light",e="github-dark",s=document.documentElement.getAttribute("data-user-color-scheme");s="dark"===s?e:t,window.UtterancesThemeLight=t,window.UtterancesThemeDark=e;var n=document.createElement("script");n.setAttribute("src","https://utteranc.es/client.js"),n.setAttribute("repo","SeulQxQ/blog-comments"),n.setAttribute("issue-term","pathname"),n.setAttribute("label","utterances"),n.setAttribute("theme",s),n.setAttribute("crossorigin","anonymous"),document.getElementById("comments").appendChild(n)}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://hexo.fluid-dev.com/docs/guide" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://cdn.staticfile.org/anchor-js/4.2.0/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach((t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")}))},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script src="/js/backgroundize.js"></script></body></html>