<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="dark"><head><meta charset="UTF-8"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@500&display=swap" rel="stylesheet"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="SeulQxQ"><meta name="keywords" content="æ€»ç»“ï¼Œå­¦ä¹ ï¼Œè¿›æ­¥ï¼"><meta name="description" content="Weekly report  Date: 23.09.04-23.09.10 Paper Title: Efficient Geometry-aware 3D Generative Adversarial Networks 1 Method, Contribution, Related Work. 1.1 Method: â€‹ A hybrid explicit-impli"><meta property="og:type" content="article"><meta property="og:title" content="æ¯å‘¨æ€»ç»“(23.09.04-23.09.10)"><meta property="og:url" content="http://seulqxq.top/posts/38005/index.html"><meta property="og:site_name" content="Seul"><meta property="og:description" content="Weekly report  Date: 23.09.04-23.09.10 Paper Title: Efficient Geometry-aware 3D Generative Adversarial Networks 1 Method, Contribution, Related Work. 1.1 Method: â€‹ A hybrid explicit-impli"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://seulqxq.top/img/index/10.png"><meta property="article:published_time" content="2023-09-10T12:03:09.000Z"><meta property="article:modified_time" content="2024-01-08T01:59:52.698Z"><meta property="article:author" content="SeulQxQ"><meta property="article:tag" content="æ€»ç»“&amp;åæ€"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://seulqxq.top/img/index/10.png"><title>æ¯å‘¨æ€»ç»“(23.09.04-23.09.10) - Seul</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css"><link rel="stylesheet" href="/css/cloudedGlass.css"><link rel="stylesheet" href="/css/selection.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"seulqxq.top",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:50,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:"â¡"},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:1},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><header><div class="header-inner" style="height:90vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>SeulQxQ&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>é¦–é¡µ</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>å½’æ¡£</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>åˆ†ç±»</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>æ ‡ç­¾</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>å…³äº</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url('/img/2.jpg') no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.2)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="æ¯å‘¨æ€»ç»“(23.09.04-23.09.10)"></span></div><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> SeulQxQ </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-09-10 20:03" pubdate>2023å¹´9æœˆ10æ—¥ æ™šä¸Š</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 11k å­— </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 92 åˆ†é’Ÿ</span></div></div><div class="scroll-down-bar"><i class="iconfont icon-arrowdown"></i></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar category-bar" style="margin-right:-1rem"><div class="category-list"><div class="category row nomargin-x"><a class="category-item list-group-item category-item-action col-10 col-md-11 col-xm-11" title="æ¯å‘¨å›é¡¾" id="heading-180e4edc6a4249e78abaf014494632a1" role="tab" data-toggle="collapse" href="#collapse-180e4edc6a4249e78abaf014494632a1" aria-expanded="true">æ¯å‘¨å›é¡¾ <span class="list-group-count">(14)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-180e4edc6a4249e78abaf014494632a1" role="tabpanel" aria-labelledby="heading-180e4edc6a4249e78abaf014494632a1"><div class="category-post-list"><a href="/posts/14769/" title="æ¯å‘¨æ€»ç»“ -- è¿™ä¸€ä»½ä»½çš„é—æ†¾ï¼Œç»ˆå°†é“¸æˆæœ€åçš„é‚£ä»½ç¾å¥½" class="list-group-item list-group-item-action"><span class="category-post">æ¯å‘¨æ€»ç»“ -- è¿™ä¸€ä»½ä»½çš„é—æ†¾ï¼Œç»ˆå°†é“¸æˆæœ€åçš„é‚£ä»½ç¾å¥½</span> </a><a href="/posts/20422/" title="æ¯å‘¨æ€»ç»“ -- ä¸€ä¸ªäººå¹¶ä¸ä¼šæ„Ÿåˆ°å­¤ç‹¬ï¼Œä¸¤ä¸ªäººæ‰ä¼š" class="list-group-item list-group-item-action"><span class="category-post">æ¯å‘¨æ€»ç»“ -- ä¸€ä¸ªäººå¹¶ä¸ä¼šæ„Ÿåˆ°å­¤ç‹¬ï¼Œä¸¤ä¸ªäººæ‰ä¼š</span> </a><a href="/posts/6012/" title="æ¯å‘¨æ€»ç»“ -- å¿ƒå¹³æ°”å’Œï¼Œä¸æ€¥ä¸èº" class="list-group-item list-group-item-action"><span class="category-post">æ¯å‘¨æ€»ç»“ -- å¿ƒå¹³æ°”å’Œï¼Œä¸æ€¥ä¸èº</span> </a><a href="/posts/46941/" title="æ¯å‘¨æ€»ç»“ -- è§£é“ƒè¿˜é¡»ç³»é“ƒäºº" class="list-group-item list-group-item-action"><span class="category-post">æ¯å‘¨æ€»ç»“ -- è§£é“ƒè¿˜é¡»ç³»é“ƒäºº</span> </a><a href="/posts/57809/" title="æ¯å‘¨æ€»ç»“ -- çˆ±æ„éšé£èµ·ï¼Œé£æ­¢æ„éš¾å¹³" class="list-group-item list-group-item-action"><span class="category-post">æ¯å‘¨æ€»ç»“ -- çˆ±æ„éšé£èµ·ï¼Œé£æ­¢æ„éš¾å¹³</span> </a><a href="/posts/27646/" title="æ¯å‘¨æ€»ç»“ -- å‹‡æ•¢è¡¨è¾¾ï¼Œæ— éœ€å®³æ€•" class="list-group-item list-group-item-action"><span class="category-post">æ¯å‘¨æ€»ç»“ -- å‹‡æ•¢è¡¨è¾¾ï¼Œæ— éœ€å®³æ€•</span> </a><a href="/posts/51013/" title="æ¯å‘¨æ€»ç»“(23.09.18-23.09.24)" class="list-group-item list-group-item-action"><span class="category-post">æ¯å‘¨æ€»ç»“(23.09.18-23.09.24)</span> </a><a href="/posts/38005/" title="æ¯å‘¨æ€»ç»“(23.09.04-23.09.10)" class="list-group-item list-group-item-action active"><span class="category-post">æ¯å‘¨æ€»ç»“(23.09.04-23.09.10)</span> </a><a href="/posts/36354/" title="æ¯å‘¨æ€»ç»“(23.08.28-23.09.03)" class="list-group-item list-group-item-action"><span class="category-post">æ¯å‘¨æ€»ç»“(23.08.28-23.09.03)</span> </a><a href="/posts/22085/" title="æ¯å‘¨æ€»ç»“(23.08.14-23.08.20)" class="list-group-item list-group-item-action"><span class="category-post">æ¯å‘¨æ€»ç»“(23.08.14-23.08.20)</span> </a><a href="/posts/8519/" title="æ¯å‘¨æ€»ç»“(23.08.07-23.08.13)" class="list-group-item list-group-item-action"><span class="category-post">æ¯å‘¨æ€»ç»“(23.08.07-23.08.13)</span> </a><a href="/posts/39277/" title="Summary" class="list-group-item list-group-item-action"><span class="category-post">Summary</span> </a><a href="/posts/20521/" title="æ¯å‘¨æ€»ç»“(23.05.15-23.05.19)" class="list-group-item list-group-item-action"><span class="category-post">æ¯å‘¨æ€»ç»“(23.05.15-23.05.19)</span> </a><a href="/posts/48714/" title="æ¯å‘¨æ€»ç»“(23.05.08-23.05.12)" class="list-group-item list-group-item-action"><span class="category-post">æ¯å‘¨æ€»ç»“(23.05.08-23.05.12)</span></a></div></div></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">æ¯å‘¨æ€»ç»“(23.09.04-23.09.10)</h1><div class="markdown-body"><div align="center"><h3>Weekly report</h3></div><p><strong>Date: 23.09.04-23.09.10</strong></p><h3 id="paper">Paper</h3><p><strong>Title: </strong><code>Efficient Geometry-aware 3D Generative Adversarial Networks</code></p><h5 id="method-contribution-related-work.">1 Method, Contribution, Related Work.</h5><p><strong>1.1 Method:</strong></p><p>â€‹ A hybrid explicit-implicit 3D perception network has been designed, utilizing a <em>memory-efficient three-plane representation</em> to explicitly store features on axis-aligned planes aggregated by a <em>lightweight implicit feature decoder</em>. This approach aims to achieve efficient volume rendering and enhance the computational efficiency of 3D foundational rendering. It incorporates certain image space approximations deviating from traditional 3D foundational rendering, while introducing a dual-discriminative strategy that maintains consistency between neural rendering and the final output to regulate tendencies of view inconsistency.</p><blockquote><p>Explicit representation allows for fast evaluation but requires substantial memory, making it challenging to scale to high resolutions or complex scenes. Implicit representation, while advantageous in terms of memory efficiency and scene complexity, employs large fully connected networks for evaluation, leading to slow training speeds. Hence, explicit and implicit representations offer complementary benefits.</p></blockquote><figure><img src="1.png" srcset="/img/loading.gif" lazyload alt="ä¸‰å¹³é¢æ¨¡å‹"><figcaption aria-hidden="true">ä¸‰å¹³é¢æ¨¡å‹</figcaption></figure><p><strong>1.2 Contribution:</strong></p><ul><li>Introduced a three-plane-based 3D GAN framework that is both efficient and expressive, enabling high-resolution geometric perception image synthesis.</li><li>Developed a 3D GAN training strategy that promotes multi-view consistency through dual-discrimination and generator pose conditioning, while faithfully modeling pose-related attribute distributions present in real-world datasets, such as expressions.</li><li>Demonstrated the latest results in unconditional 3D perception image synthesis on the FFHQ and AFHQ Cats datasets, as well as high-quality 3D geometric graphics learned entirely from 2D outdoor images.</li></ul><p><strong>1.3 Related Work:</strong></p><ol type="1"><li>Neural scene representation and rendering</li></ol><p>â€‹ A new hybrid explicit-implicit 3D perception network has been designed, which utilizes a memory-efficient three-plane representation to explicitly store features on axis-aligned planes aggregated by a lightweight implicit feature decoder, aiming to achieve efficient volume rendering.</p><ol start="2" type="1"><li>Generative 3D-aware image synthesis</li></ol><p>â€‹ An efficient 3D GAN architecture with a 3D-based prior bias is crucial for successfully generating high-resolution, view-consistent images, and high-quality 3D shapes. Therefore, the authors adopted the following approaches:</p><ul><li>Directly leverage a 2D CNN feature generator, namely <em>StyleGAN2</em>.</li><li>The three-plane representation allows this paper's approach to utilize neural volume rendering as a prior bias, making it computationally more efficient than fully implicit 3D networks.</li><li>Employing an up-sampling based on 2D CNNs after neural rendering while introducing dual discriminators to mitigate view inconsistencies brought about by the up-sampling layers.</li></ul><h4 id="model-and-modules">2 Model and Modules</h4><p><strong>2.1 Tri-plane hybrid 3D represnetation</strong></p><p><code>IDEA:</code>Hybrid explicit-implicit tri-plane representation.</p><p><code>Implement:</code>Align explicit features along three axis-aligned orthogonal feature planes, each with a resolution of NÃ—NÃ—C, where N represents spatial dimensions and C stands for the number of channels. To query any 3D position point <em>x</em>, project it onto the three feature planes to retrieve the corresponding feature vector <span class="math inline">\((F_{xy} ~~,~~ F_{xz}~ , ~ F_{yz})\)</span> through bilinear interpolation and then aggregate these three feature vectors by summation. Finally, feed this aggregated feature F into a small decoder (MLP) to decode it into color and density.</p><p><strong>2.2 3D GAN framework</strong></p><p><code>IDEA:</code>Train a 3D GAN for collective perception image synthesis from 2D photos without the need for any explicit 3D or multi-view supervision. Simultaneously, use a pre-trained pose detector to associate each training image with a set of camera intrinsics and extrinsics(<em>Deep3DFaceReconstruction</em>).</p><p><code>Implement &amp;&amp; Overview:</code></p><figure><img src="2.jpg" srcset="/img/loading.gif" lazyload alt="Overview"><figcaption aria-hidden="true">Overview</figcaption></figure><blockquote><ol type="a"><li><p>A pose-conditioned StyleGAN2 feature generator and mapping network.</p></li><li><p>Three-plane 3D representation with a lightweight feature decoder.</p></li><li><p>A neural voxel renderer.</p></li><li><p>A super-resolution module.</p></li><li><p>A pose-conditioned StyleGAN2 discriminator with dual discrimination.</p></li></ol></blockquote><p>â€‹ This architecture cleverly decouples feature generation and neural rendering, enabling the utilization of the powerful StyleGAN2 generator for generalizing 3D scenes. Furthermore, the lightweight three-plane 3D representation can effectively convey rich information and achieve high-quality 3D perception view synthesis in real-time. Additionally, a two-stage training strategy is employed to accelerate training speed. The first stage involves training with reduced <span class="math inline">\((64^2)\)</span> neural rendering resolution, while the second stage consists of short-term fine-tuning at full <span class="math inline">\((128^2)\)</span> neural rendering resolution.</p><p><strong>2.3 CNN generator backbone and rendering</strong></p><p><code>IDEA:</code>The features of the <em>three-plane representation are generated by the StyleGAN2 CNN generator</em>. Random latent codes and camera parameters are first processed by the mapping network to produce intermediate latent codes, which are then used to modulate the convolution kernels of the separately synthesized network.</p><p><code>Implement:</code>Change the output shape of the StyleGAN2 backbone network to generate a feature map of dimensions 256Ã—256Ã—96 instead of generating a three-channel RGB image. Sample features from the three planes and merge the features sampled from these three planes, which are then fed into a lightweight decoder (MLP) with a single hidden layer of 64 neurons and the activation function being <em>softplus</em>.</p><p><code>Module:</code> StyleGAN2, MLP</p><p><strong>2.4 Super resolution</strong></p><p><code>IDEA:</code> Perform volume rendering at intermediate resolution <span class="math inline">\((128^2)\)</span> and rely on image space convolutional upsampling for rendering to image sizes of <span class="math inline">\((256^2 ~ or ~ 512^2)\)</span>.</p><p><code>Implement:</code> Comprised of two blocks modulating the convolutional layers in StyleGAN2:</p><ul><li>Upsampling, increasing the resolution from 128Ã—128Ã—3 to 512Ã—512Ã—3.</li><li>Adapting the 32-channel feature map to the final RGB image.</li></ul><p><strong>2.5 Dual discrimination</strong></p><p><code>IDEA:</code>Utilize the StyleGAN2 discriminator and made it two modifications.</p><p><code>Implement:</code> A) Interpret the feature map as a low-resolution RGB image. The dual discriminator ensures consistency between low-resolution RGB images and high-resolution images by upsampling them using bilinear interpolation to the same 512Ã—512Ã—3 size and concatenating them with the adjusted <span class="math inline">\((I^+_{RGB})\)</span>, resulting in a 6-channel image. B) Concatenate the input 3-channel RGB image with its appropriately blurred counterpart to form a 6-channel image as the input to the discriminator.</p><p><code>Module:</code>StyleGAN2-ADA strategy</p><blockquote><p>StyleGAN2-ADA Strategy: Pass the camera's intrinsic and extrinsic matrices (P) to the discriminator as conditional labels. This modulation introduces additional information to guide the generator in learning the correct 3D priors.</p></blockquote><p><strong>2.6 Modeling pose-correlated attributions</strong></p><p><code>IDEA:</code>Introduced <em>generator pose conditioning</em> as a means to model and decouple the correlation between observed poses and other attributes in the training images.</p><p><code>Implement:</code>Following the StyleGAN2-ADA conditional generation strategy, propose a backbone mapping network that not only provides a latent code z but also takes camera parameters P as input.</p><h4 id="other-details">3 Other details</h4><p><strong>3.1 Pose Estimators</strong></p><p>â€‹ Augment the dataset using horizontal flipping and utilize pre-existing pose estimation to extract approximate camera extrinsic parameters.</p><blockquote><p>Pre-existing pose estimation methods:</p><ol type="1"><li>https://github.com/Microsoft/Deep3DFaceReconstruction for generating pose data for faces (FFHQ).</li><li>https://github.com/kairess/cat_hipsterizer for generating pose data for cats (AFHQv2 Cats).</li></ol></blockquote><h3 id="other-work">Other Work</h3><p>â€‹ To read the code of this paper, especially the pose estimators and run these code in the two links. Then I've been learning about StyleGAN2 to understand methods in this paper better.Summray</p><p>â€‹ é˜…è¯»äº†ä¸€ç¯‡è®ºæ–‡<code>Efficient Geometry-aware 3D Generative Adversarial Networks</code>ï¼Œå¹¶å°†ä¸Šæ¬¡çš„è®ºæ–‡é‡æ–°æ€»ç»“äº†ä¸€ä¸‹ã€‚å»äº†è§£è¿è¡Œäº†å§¿æ€ä¼°è®¡çš„ä»£ç ï¼Œå¹¶ä¸”å»äº†è§£äº†StyleGAN2çš„ä¸€äº›æ€æƒ³ï¼Œå’ŒStyleGAN2-ADAè‡ªé€‚åº”å¢å¼ºç­‰ä¸€äº›çŸ¥è¯†ã€‚</p><h3 id="paper-1">Paper</h3><h4 id="title-efficient-geometry-aware-3d-generative-adversarial-networks"><strong>Title: </strong><code>Efficient Geometry-aware 3D Generative Adversarial Networks</code></h4><h5 id="ä¸€æå‡ºçš„æ–¹æ³•è´¡çŒ®ç›¸å…³å·¥ä½œ">ä¸€ã€æå‡ºçš„æ–¹æ³•ã€è´¡çŒ®ã€ç›¸å…³å·¥ä½œ</h5><p><strong>1.æ–¹æ³•ï¼š</strong></p><p>â€‹ è®¾è®¡äº†ä¸€ç§æ··åˆæ˜¾å¼-éšå¼3Dæ„ŸçŸ¥ç½‘ç»œï¼Œè¯¥ç½‘ç»œä½¿ç”¨å†…å­˜é«˜æ•ˆçš„<code>ä¸‰å¹³é¢è¡¨ç¤ºæ˜¾å¼åœ°</code>å­˜å‚¨ç”±è½»é‡çº§<code>éšå¼ç‰¹å¾è§£ç å™¨èšåˆ</code>çš„è½´å¯¹é½å¹³é¢ä¸Šçš„ç‰¹å¾ï¼Œä»¥å®ç°é«˜æ•ˆçš„ä½“ç»˜åˆ¶ï¼Œæé«˜äº†3DåŸºç¡€æ¸²æŸ“çš„è®¡ç®—æ•ˆç‡ã€‚ä½¿ç”¨äº†ä¸€äº›åç¦»3DåŸºç¡€æ¸²æŸ“çš„å›¾åƒç©ºé—´è¿‘ä¼¼ï¼ŒåŒæ—¶å¼•å…¥äº†ä¸€ç§åŒé‡åˆ¤åˆ«ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ä¿æŒç¥ç»æ¸²æŸ“å’Œæœ€ç»ˆè¾“å‡ºä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œä»¥è§„èŒƒå…¶è§†å›¾ä¸ä¸€è‡´çš„è¶‹åŠ¿ã€‚</p><blockquote><p>æ˜¾å¼è¡¨ç¤ºå¯ä»¥è¿›è¡Œå¿«é€Ÿè¯„ä¼°ï¼Œä½†æ˜¯éœ€è¦å¾ˆå¤§çš„å†…å­˜ï¼Œä½¿å¾—è¿™ç§æ–¹å¼éš¾ä»¥æ‰©å±•åˆ°é«˜åˆ†è¾¨ç‡æˆ–å¤æ‚åœºæ™¯ã€‚éšå¼è¡¨ç¤ºè™½ç„¶åœ¨å†…å­˜æ•ˆç‡å’Œåœºæ™¯å¤æ‚æ€§æ–¹é¢æœ‰ä¼˜åŠ¿ï¼Œä½†æ˜¯è¿™ç§æ–¹æ³•ä½¿ç”¨å¤§å‹çš„å…¨è¿æ¥ç½‘ç»œè¿›è¡Œè¯„ä¼°ï¼Œä½¿å¾—è®­ç»ƒé€Ÿåº¦ç¼“æ…¢ã€‚å› æ­¤ï¼Œæ˜¾å¼å’Œéšå¼è¡¨ç¤ºæä¾›äº†äº’è¡¥çš„å¥½å¤„ã€‚</p></blockquote><figure><img src="1.png" srcset="/img/loading.gif" lazyload alt="ä¸‰å¹³é¢æ¨¡å‹"><figcaption aria-hidden="true">ä¸‰å¹³é¢æ¨¡å‹</figcaption></figure><p><strong>2.è´¡çŒ®ï¼š</strong></p><ul><li>å¼•å…¥äº†ä¸€ä¸ªåŸºäºä¸‰å¹³é¢çš„3D GANæ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ—¢é«˜æ•ˆåˆå¯Œæœ‰è¡¨ç°åŠ›ï¼Œä»¥å®ç°é«˜åˆ†è¾¨ç‡å‡ ä½•æ„ŸçŸ¥å›¾åƒåˆæˆã€‚</li><li>å¼€å‘äº†ä¸€ç§3D GANè®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡åŒé‡åˆ¤åˆ«å’Œç”Ÿæˆå™¨å§¿åŠ¿æ¡ä»¶ä¿ƒè¿›å¤šè§†å›¾ä¸€è‡´æ€§ï¼ŒåŒæ—¶å¿ å®åœ°å»ºæ¨¡ç°å®ä¸–ç•Œæ•°æ®é›†ä¸­å­˜åœ¨çš„å§¿åŠ¿ç›¸å…³å±æ€§åˆ†å¸ƒï¼ˆä¾‹å¦‚è¡¨è¾¾å¼ï¼‰ã€‚</li><li>å±•ç¤ºäº†åœ¨FFHQå’ŒAFHQ Catsæ•°æ®é›†ä¸Šæ— æ¡ä»¶3Dæ„ŸçŸ¥å›¾åƒåˆæˆçš„æœ€æ–°ç»“æœï¼Œä»¥åŠå®Œå…¨ä»2Dé‡å¤–å›¾åƒä¸­å­¦ä¹ çš„é«˜è´¨é‡3Då‡ ä½•å›¾å½¢ã€‚</li></ul><p><strong>3.ç›¸å…³å·¥ä½œï¼š</strong></p><p>â€‹ 1ï¼‰Neural scene representation and rendering(ç¥ç»åœºæ™¯è¡¨ç¤ºå’Œæ¸²æŸ“)</p><p>â€‹ è®¾è®¡äº†ä¸€ç§æ–°çš„æ··åˆæ˜¾å¼éšå¼3Dæ„ŸçŸ¥ç½‘ç»œï¼Œè¯¥ç½‘ç»œä½¿ç”¨å†…å­˜é«˜æ•ˆçš„ä¸‰å¹³é¢è¡¨ç¤ºæ˜¾å¼åœ°å­˜å‚¨ç”±è½»é‡çº§éšå¼ç‰¹å¾è§£ç å™¨èšåˆçš„è½´å¯¹é½å¹³é¢ä¸Šçš„ç‰¹å¾ï¼Œä»¥å®ç°é«˜æ•ˆçš„ä½“ç»˜åˆ¶</p><p>â€‹ 2ï¼‰Generative 3D-aware image synthesis(ç”Ÿæˆå¼3Dæ„ŸçŸ¥å›¾åƒåˆæˆ)</p><p>â€‹ å…·æœ‰åŸºäº3Dçš„å…ˆéªŒåå·®çš„é«˜æ•ˆ3D GANæ¶æ„å¯¹äºæˆåŠŸç”Ÿæˆé«˜åˆ†è¾¨ç‡è§†å›¾ä¸€è‡´å›¾åƒå’Œé«˜è´¨é‡3Då½¢çŠ¶è‡³å…³é‡è¦ã€‚æ‰€ä»¥ä½œè€…é‡‡ç”¨äº†ä»¥ä¸‹æ–¹æ³•ï¼š</p><p>â€‹ a. ç›´æ¥åˆ©ç”¨åŸºäº2D CNNç‰¹å¾ç”Ÿæˆå™¨ï¼Œå³<code>StyleGAN2</code>ã€‚</p><p>â€‹ b. ä¸‰å¹³é¢è¡¨ç¤ºä½¿å¾—è¯¥è®ºæ–‡çš„æ–¹æ³•èƒ½åˆ©ç”¨ç¥ç»ä½“æ¸²æŸ“ä½œä¸ºå…ˆéªŒåå·®ï¼Œåœ¨è®¡ç®—ä¸Šæ¯”å®Œå…¨éšå¼3Dç½‘ç»œæ›´æœ‰æ•ˆã€‚</p><p>â€‹ c. åœ¨ç¥ç»æ¸²æŸ“åé‡‡ç”¨åŸºäº2D CNNçš„å‘ä¸Šé‡‡æ ·ï¼ŒåŒæ—¶å¼•å…¥åŒé‡è¾¨åˆ«å™¨å»é¿å…ä¸Šé‡‡æ ·å±‚å¸¦æ¥çš„è§†å›¾ä¸ä¸€è‡´ã€‚</p><h5 id="äºŒæ¨¡å‹ä¸æ¨¡å—">äºŒã€æ¨¡å‹ä¸æ¨¡å—</h5><p><strong>1. Tri-plane hybrid 3D representation(Tri-planeæ··åˆ3Dè¡¨ç¤º)</strong></p><p><code>æ€æƒ³ï¼š</code>hybrid explicit-implicit tri-plane representation(æ··åˆæ˜¾å¼-éšå¼ä¸‰å¹³é¢è¡¨ç¤º)ã€‚</p><p><code>å®ç°ï¼š</code>æ²¿ç€ä¸‰ä¸ªè½´å¯¹é½çš„æ­£äº¤ç‰¹å¾å¹³é¢å¯¹é½æ˜¾å¼ç‰¹å¾ï¼Œæ¯ä¸ªç‰¹å¾å¹³é¢çš„åˆ†è¾¨ç‡å‡ä¸ºNÃ—NÃ—Cï¼ŒNä¸ºç©ºé—´ç»´åº¦ï¼ŒCä¸ºé€šé“æ•°ã€‚é€šè¿‡å°†3Dä½ç½®æŠ•å½±åˆ°ä¸‰ä¸ªç‰¹å¾å¹³é¢ä¸­æ¥æŸ¥è¯¢ä»»ä½•3Dä½ç½®ç‚¹<code>x</code>ï¼Œé€šè¿‡åŒçº¿æ€§æ’å€¼æ£€ç´¢ç›¸åº”çš„ç‰¹å¾å‘é‡<span class="math inline">\((F_{xy} ~,~ F_{xz}~ , ~ F_{yz})\)</span>ï¼Œç„¶åé€šè¿‡æ±‚å’Œæ¥æ±‡æ€»è¿™ä¸‰ä¸ªç‰¹å¾å‘é‡ã€‚æœ€åå°†è¿™ä¸ªæ±‡æ€»çš„ç‰¹å¾Fè¾“å…¥åˆ°ä¸€ä¸ªå°å‹è§£ç å™¨(MLP)æ¥è§£ç ä¸ºé¢œè‰²å’Œå¯†åº¦ã€‚</p><p><code>æ¨¡å—ï¼š</code>å°å‹MLPç½‘ç»œã€‚</p><p><strong>2. 3D GAN framework(3D GANæ¡†æ¶)</strong></p><p><code>æ€æƒ³ï¼š</code>è®­ç»ƒä¸€ä¸ª3D GANï¼Œç”¨äºä»2Dç…§ç‰‡ä¸­è¿›è¡Œé›†åˆæ„ŸçŸ¥å›¾åƒåˆæˆï¼Œè€Œæ— éœ€ä»»ä½•æ˜¾å¼3Dæˆ–è€…å¤šè§†å›¾ç›‘ç£ã€‚åŒæ—¶ä½¿ç”¨ç°æˆçš„å§¿æ€æ£€æµ‹å™¨ï¼Œå°†æ¯ä¸ªè®­ç»ƒå›¾åƒä¸ä¸€ç»„ç›¸æœºå†…å‚å’Œå¤–å‚ç›¸å…³è”(<code>Deep3DFaceReconstruction</code>)ã€‚</p><p><code>å®ç°/Overview:</code></p><figure><img src="2.jpg" srcset="/img/loading.gif" lazyload alt="Overview"><figcaption aria-hidden="true">Overview</figcaption></figure><blockquote><p>â€‹ a. ä¸€ä¸ªåŸºäºå§¿æ€æ¡ä»¶çš„StyleGAN2ç‰¹å¾ç”Ÿæˆå™¨å’Œæ˜ å°„ç½‘ç»œã€‚</p><p>â€‹ b. ä¸€ä¸ªå…·æœ‰è½»é‡çº§ç‰¹å¾è§£ç å™¨çš„ä¸‰å¹³é¢3Dè¡¨ç¤ºã€‚</p><p>â€‹ c. ä¸€ä¸ªç¥ç»ä½“ç´ æ¸²æŸ“å™¨ã€‚</p><p>â€‹ d. ä¸€ä¸ªè¶…åˆ†è¾¨ç‡æ¨¡å—ã€‚</p><p>â€‹ e. ä¸€ä¸ªåŸºäºå§¿æ€æ¡ä»¶çš„å…·æœ‰åŒé‡è¾¨åˆ«çš„StyleGAN2è¾¨åˆ«å™¨ã€‚</p></blockquote><p>â€‹ è¿™ä¸ªæ¶æ„å·§å¦™åœ°å°†ç‰¹å¾ç”Ÿæˆå’Œç¥ç»æ¸²æŸ“è§£è€¦ï¼Œä½¿å¾—å¯ä»¥åˆ©ç”¨å¼ºå¤§çš„StyleGAN2ç”Ÿæˆå™¨è¿›è¡Œ3Dåœºæ™¯çš„æ³›åŒ–ã€‚æ­¤å¤–ï¼Œè½»é‡çº§çš„ä¸‰å¹³é¢3Dè¡¨ç¤ºæ—¢èƒ½å¤Ÿè¡¨è¾¾ä¸°å¯Œçš„ä¿¡æ¯ï¼Œåˆèƒ½å¤Ÿåœ¨å®æ—¶ä¸­å®ç°é«˜è´¨é‡çš„3Dæ„ŸçŸ¥è§†å›¾åˆæˆã€‚åŒæ—¶ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥åŠ é€Ÿè®­ç»ƒé€Ÿåº¦ã€‚ç¬¬ä¸€ä¸ªé˜¶æ®µï¼šä½¿ç”¨å‡å°‘<span class="math inline">\((64^2)\)</span>ç¥ç»æ¸²æŸ“åˆ†è¾¨ç‡è¿›è¡Œè®­ç»ƒï¼›ç¬¬äºŒä¸ªé˜¶æ®µï¼šåœ¨å®Œå…¨<span class="math inline">\((128^2)\)</span>ç¥ç»æ¸²æŸ“åˆ†è¾¨ç‡ä¸Šçš„çŸ­æœŸå¾®è°ƒã€‚</p><p><strong>3. CNN generator backbone and rendering(CNNç”Ÿæˆå™¨ä¸»å¹²å’Œæ¸²æŸ“)</strong></p><p><code>æ€æƒ³ï¼š</code>ç”±<code>StyleGAN2 CNNç”Ÿæˆå™¨ç”Ÿæˆä¸‰å¹³é¢è¡¨ç¤ºçš„ç‰¹å¾</code>ã€‚éšæœºæ½œåœ¨ä»£ç å’Œç›¸æœºå‚æ•°é¦–å…ˆç”±æ˜ å°„ç½‘ç»œå¤„ç†ä»¥äº§ç”Ÿä¸­é—´æ½œåœ¨ä»£ç ï¼Œç„¶åè°ƒåˆ¶å•ç‹¬åˆæˆç½‘ç»œçš„å·ç§¯æ ¸ã€‚</p><p><code>å®ç°ï¼š</code>æ”¹å˜StyleGAN2ä¸»å¹²ç½‘ç»œçš„è¾“å‡ºå½¢çŠ¶ï¼Œä¸æ˜¯ç”Ÿæˆä¸‰é€šé“RGBå›¾åƒï¼Œè€Œæ˜¯ç”Ÿæˆä¸€ä¸ª256Ã—256Ã—96çš„ç‰¹å¾å›¾åƒã€‚ä»ä¸‰å¹³é¢é‡‡æ ·ç‰¹å¾ï¼Œå¹¶èæ±‡ä»ä¸‰ä¸ªå¹³é¢é‡‡æ ·çš„ç‰¹å¾ï¼Œè¾“å…¥åˆ°è½»é‡çº§è§£ç å™¨(MLPï¼Œ64ä¸ªç¥ç»å…ƒçš„å•ä¸ªéšè—å±‚ï¼Œæ¿€æ´»å‡½æ•°ï¼šsoftplus)ã€‚</p><p><code>æ¨¡å—ï¼š</code>StyleGAN2ã€MLP</p><p><strong>4. Super resolution(è¶…åˆ†è¾¨ç‡)</strong></p><p><code>æ€æƒ³ï¼š</code>ä½¿ç”¨ä¸­ç­‰åˆ†è¾¨ç‡<span class="math inline">\((128^2)\)</span>è¿›è¡Œä½“æ¸²æŸ“ï¼Œå¹¶ä¾é å›¾åƒç©ºé—´å·ç§¯ä¸Šé‡‡æ ·ç¥ç»æ¸²æŸ“åˆ°<span class="math inline">\((256^2 ~ or ~ 512^2)\)</span>å›¾åƒå¤§å°ã€‚</p><p><code>å®ç°ï¼š</code>ç”±StyleGAN2è°ƒåˆ¶å·ç§¯å±‚çš„ä¸¤ä¸ªå—ç»„æˆã€‚1ï¼‰ä¸Šé‡‡æ ·ï¼Œå°†128Ã—128Ã—3åˆ†è¾¨ç‡æé«˜åˆ°512Ã—512Ã—3çš„åˆ†è¾¨ç‡ã€‚2ï¼‰è°ƒæ•´32é€šé“ç‰¹å¾å›¾åˆ°æœ€ç»ˆçš„RGBå›¾åƒã€‚</p><p><strong>5. Dual discrimination(åŒé‡è¾¨åˆ«å™¨)</strong></p><p><code>æ€æƒ³ï¼š</code>ä½¿ç”¨StyleGAN2çš„è¾¨åˆ«å™¨ï¼Œå¹¶è¿›è¡Œäº†ä¸¤æ¬¡ä¿®æ”¹ã€‚</p><p><code>å®ç°ï¼š</code>1ï¼‰å°†ç‰¹å¾å›¾è§£é‡Šä¸ºä½åˆ†è¾¨ç‡RGBå›¾åƒã€‚åŒé‡è¾¨åˆ«å™¨ç¡®ä¿ä½åˆ†è¾¨ç‡RGBå›¾åƒä¸é«˜åˆ†è¾¨ç‡å›¾åƒçš„ä¸€è‡´æ€§ï¼Œé€šè¿‡åŒçº¿æ€§ä¸Šé‡‡æ ·æˆåŒæ ·512Ã—512Ã—3å›¾åƒå¹¶ä¸è°ƒæ•´åçš„<span class="math inline">\((I^+_{RGB})\)</span>è¿›è¡Œè¿æ¥å˜æˆ6é€šé“å›¾åƒã€‚2ï¼‰å°†è¾“å…¥çš„3é€šé“RGBå›¾åƒä¸å…¶é€‚å½“æ¨¡ç³Šåçš„å›¾åƒè¿›è¡Œè¿æ¥ï¼Œå˜æˆ6é€šé“å›¾åƒä½œä¸ºè¾¨åˆ«å™¨çš„è¾“å…¥ã€‚</p><p><code>æ¨¡å—ï¼š</code>StyleGAN2-ADAç­–ç•¥</p><blockquote><p>â€‹ StyleGAN2-ADAç­–ç•¥ï¼šå°†æ¸²æŸ“ç›¸æœºçš„å†…å¤–çŸ©é˜µ(P)ä¼ é€’ç»™é‰´åˆ«å™¨ä½œä¸ºæ¡ä»¶æ ‡ç­¾ã€‚è¿™ç§è°ƒèŠ‚å¼•å…¥äº†é¢å¤–çš„ä¿¡æ¯ï¼ŒæŒ‡å¯¼ç”Ÿæˆå™¨å­¦ä¹ æ­£ç¡®çš„3Då…ˆéªŒã€‚</p></blockquote><p><strong>6. Modeling pose-correlated attributes(å»ºæ¨¡å§¿æ€ç›¸å…³å±æ€§)</strong></p><p><code>æ€æƒ³ï¼š</code>å¼•å…¥äº†<code>generator pose conditioning(ç”Ÿæˆå™¨å§¿åŠ¿æ¡ä»¶)</code>ä½œä¸ºå»ºæ¨¡å’Œè§£è€¦è®­ç»ƒå›¾åƒä¸­è§‚å¯Ÿåˆ°çš„å§¿åŠ¿ä¸å…¶ä»–å±æ€§ä¹‹é—´çš„ç›¸å…³æ€§çš„ä¸€ç§æ‰‹æ®µã€‚</p><p><code>å®ç°ï¼š</code>æŒ‰ç…§StyleGAN2-ADAæ¡ä»¶ç”Ÿæˆç­–ç•¥ï¼Œæå‡ºä¸€ä¸ªä¸»å¹²æ˜ å°„ç½‘ç»œï¼Œä¸ä»…æä¾›ä¸€ä¸ªæ½œåœ¨ä»£ç zï¼ŒåŒæ—¶æä¾›ç›¸æœºå‚æ•°Pä½œä¸ºè¾“å…¥ã€‚</p><h5 id="ä¸‰å…¶ä»–ç»†èŠ‚">ä¸‰ã€å…¶ä»–ç»†èŠ‚</h5><p><strong>1. Pose Estimators(å§¿æ€ä¼°è®¡)</strong></p><p>â€‹ ç”¨æ°´å¹³ç¿»è½¬çš„æ–¹æ³•æ¥æ‰©å……æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨ç°æˆçš„å§¿æ€ä¼°è®¡æ¥æå–è¿‘ä¼¼çš„ç›¸æœºå¤–éƒ¨å‚æ•°ã€‚</p><blockquote><p>ç°æˆçš„å§¿æ€ä¼°è®¡æ–¹æ³•ï¼š</p><p>1ï¼‰https://github.com/Microsoft/Deep3DFaceReconstructionï¼Œç”¨æ¥ç”Ÿæˆè„¸çš„æ•°æ®é›†çš„å§¿æ€(FFHQ)ã€‚</p><p>2ï¼‰https://github.com/kairess/cat_hipsterizerï¼Œç”¨æ¥ç”ŸæˆçŒ«çš„æ•°æ®é›†çš„å§¿æ€(AFHQv2 Cats)ã€‚</p></blockquote><h4 id="titileshape-pose-and-appearance-from-a-single-image-via-bootstrapped-radiance-field-inversion">Titileï¼š<code>Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion</code></h4><h5 id="ä¸€æå‡ºçš„æ–¹æ³•ä¸è´¡çŒ®">ä¸€ã€æå‡ºçš„æ–¹æ³•ä¸è´¡çŒ®</h5><p><strong>1.æ–¹æ³•ï¼š</strong></p><p>â€‹ ä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œå°†æ— æ¡ä»¶ç”Ÿæˆæ¨¡å‹ä¸æ··åˆåæ¼”èŒƒå¼ç›¸ç»“åˆï¼Œä»å•ä¸ªå›¾åƒä¸­æ¢å¤ä¸‰ç»´ä¿¡æ¯ã€‚å…·ä½“æ¥è¯´ï¼Œä»–ä»¬ä½¿ç”¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ¥è¡¨ç¤ºä¸‰ç»´åœºæ™¯ï¼Œå¹¶ä½¿ç”¨ç¼–ç å™¨äº§ç”Ÿæ½œåœ¨è¡¨ç¤ºå’Œå§¿æ€çš„ç¬¬ä¸€ä¸ªçŒœæµ‹ã€‚ç„¶åï¼Œä»–ä»¬é€šè¿‡ä¼˜åŒ–æ¥ç»†åŒ–è¿™äº›åˆå§‹ä¼°è®¡ï¼Œä»¥è·å¾—æ›´å‡†ç¡®çš„é‡å»ºã€‚</p><p><strong>2.è´¡çŒ®ï¼š</strong></p><ul><li>å¼•å…¥äº†ä¸€ä¸ªåŸºäºNeRFçš„ç«¯åˆ°ç«¯å•è§†å›¾ä¸‰ç»´é‡å»ºç®¡é“ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æˆåŠŸåœ°å±•ç¤ºäº†CMRåŸºå‡†ä¸‹è‡ªç„¶å›¾åƒçš„<span class="math inline">\(360^â—¦\)</span>å¯¹è±¡é‡å»ºã€‚</li><li>æå‡ºäº†ä¸€ç§ç”¨äºNeRFçš„æ··åˆåæ¼”æ–¹æ¡ˆï¼Œä»¥åŠ å¿«é¢„è®­ç»ƒçš„3Dæ„ŸçŸ¥ç”Ÿæˆå™¨çš„åè½¬ã€‚</li><li>å—å§¿æ€ä¼°è®¡æ–‡çŒ®çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºPnPçš„å§¿æ€ä¼°è®¡å™¨ï¼Œå®ƒåˆ©ç”¨æˆ‘ä»¬çš„æ¡†æ¶å¹¶ä¸”ä¸éœ€è¦é¢å¤–çš„æ•°æ®å‡è®¾ã€‚</li></ul><h5 id="äºŒæ¨¡å‹ä¸æ¨¡å—-1">äºŒã€æ¨¡å‹ä¸æ¨¡å—</h5><p><strong>1. Unconditional generator pre-trainingï¼ˆæ— æ¡ä»¶ç”Ÿæˆå™¨é¢„è®­ç»ƒæ¡†æ¶ï¼‰</strong></p><figure><img src="3.png" srcset="/img/loading.gif" lazyload alt="æ— æ¡ä»¶ç”Ÿæˆå™¨"><figcaption aria-hidden="true">æ— æ¡ä»¶ç”Ÿæˆå™¨</figcaption></figure><p><code>æ€æƒ³ï¼š</code>ä¸»è¦æ€æƒ³æ¥è‡ªEG3Dçš„ä¸»å¹²ç½‘ç»œï¼Œä¸‰å¹³é¢ç¼–ç ã€‚<code>è¯¥éƒ¨åˆ†è¢«æ¡†æ¶ä½¿ç”¨åŸºäºNeRFçš„ç”Ÿæˆå™¨Gä¸2Då›¾åƒé‰´åˆ«å™¨ç›¸ç»“åˆã€‚</code></p><p><code>æ¨¡å—ï¼š</code>StyleGAN2ï¼ŒSDF representationï¼ŒAttention-based color mappingï¼ŒPath Length Regularization revisitedã€‚</p><blockquote><p>StyleGAN2ï¼šç”Ÿæˆæ¨¡å‹ï¼ŒSDF representationï¼š3Dè¡¨ç¤ºï¼Œ</p><p><strong>Attention-based color mappingï¼šæé«˜é¢œè‰²æ³›åŒ–æ€§, Path Length Regularization revisitedï¼šä½¿ä¸‰å¹³é¢è§£ç å™¨ä¸æ­£åˆ™åŒ–ï¼Œæé«˜å­¦ä¹ ç‡ã€‚</strong></p></blockquote><p><strong>2. Bootstrapping and pose estimationï¼ˆè‡ªä¸¾å’Œå§¿æ€ä¼°è®¡ï¼‰</strong></p><figure><img src="4.png" srcset="/img/loading.gif" lazyload alt="å§¿æ€ä¼°è®¡"><figcaption aria-hidden="true">å§¿æ€ä¼°è®¡</figcaption></figure><p><code>æ€æƒ³ï¼š</code>ä¸»è¦æ€æƒ³æ¥è‡ªNOCSï¼Œ<code>æ”¹è¿›ï¼šæ˜¯ä½¿ç”¨ä»æ— æ¡ä»¶ç”Ÿæˆå™¨ç”Ÿæˆçš„æ•°æ®æ¥è®­ç»ƒç¼–ç å™¨è€Œä¸æ˜¯æ‰‹å·¥æ•°æ®ã€‚</code></p><p><code>å®ç°ï¼š</code>1ï¼‰å†»ç»“Gå¹¶è®­ç»ƒå›¾åƒç¼–ç å™¨Eï¼Œè”åˆä¼°è®¡å¯¹è±¡çš„å§¿åŠ¿åŠå…¶æ½œåœ¨ä»£ç ï¼ˆè‡ªä¸¾ï¼‰çš„åˆå§‹çŒœæµ‹ã€‚2ï¼‰å¯¹äºå§¿æ€ä¼°è®¡ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§åŸåˆ™æ€§çš„æ–¹æ³•æ¥é¢„æµ‹å±å¹•ç©ºé—´ä¸­çš„è§„èŒƒæ˜ å°„é€šè¿‡é€è§†nç‚¹(PnP)ç®—æ³•ã€‚<code>è¾“å…¥çœŸå®å›¾åƒï¼Œå°†é¢„æµ‹çš„è§„èŒƒæ˜ å°„è½¬æ¢ä¸ºç‚¹äº‘ï¼Œå¹¶è¿è¡ŒPnPæ±‚è§£å™¨æ¥æ¢å¤æ‰€æœ‰å§¿æ€å‚æ•°(è§†å›¾çŸ©é˜µå’Œç„¦è·)ã€‚</code></p><p><code>æ¨¡å—ï¼š</code>SegFormer</p><blockquote><p><strong>è®­ç»ƒSegFormerç½‘ç»œæ¥ä»RGBå›¾åƒä¸­é¢„æµ‹è§„èŒƒå›¾å’Œlatent code w</strong></p></blockquote><p><strong>SegFormeråˆ†å‰²ç½‘ç»œå›¾ï¼š</strong></p><figure><img src="5.png" srcset="/img/loading.gif" lazyload alt="åˆ†å‰²ç½‘ç»œ"><figcaption aria-hidden="true">åˆ†å‰²ç½‘ç»œ</figcaption></figure><p><strong>3. Reconstruction via hybrid GAN inversionï¼ˆé€šè¿‡æ··åˆGANåæ¼”é‡å»ºï¼‰</strong></p><figure><img src="6.png" srcset="/img/loading.gif" lazyload alt="æ··åˆåæ¼”"><figcaption aria-hidden="true">æ··åˆåæ¼”</figcaption></figure><p>é€šè¿‡åŸºäºæ¢¯åº¦çš„ä¼˜åŒ–(æ··åˆåæ¼”)æ”¹è¿›äº†å‡ ä¸ªæ­¥éª¤çš„å§¿æ€å’Œæ½œåœ¨ä»£ç ã€‚æŸå¤±å‡½æ•°ï¼šVGG</p><p><code>æ¨¡å—ï¼š</code>adaptive discriminator augmentation(ADA)</p><blockquote><p>æœ‰åŠ©äºå‡å°‘æ¢¯åº¦çš„æ–¹å·®ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿè¿›ä¸€æ­¥æé«˜å­¦ä¹ ç‡ã€‚</p></blockquote><h3 id="other-work-1">Other Work</h3><p>â€‹ é˜…è¯»è¿™ç¯‡è®ºæ–‡çš„ä»£ç ï¼Œç‰¹åˆ«æ˜¯å§¿æ€ä¼°è®¡å™¨çš„éƒ¨åˆ†ï¼Œå¹¶åœ¨è¿™ä¸¤ä¸ªé“¾æ¥ä¸­è¿è¡Œè¿™äº›ä»£ç ã€‚ç„¶åï¼Œæˆ‘ä¸€ç›´åœ¨å­¦ä¹ å…³äºStyleGAN2ï¼Œä»¥æ›´å¥½åœ°ç†è§£è¿™ç¯‡è®ºæ–‡ä¸­çš„æ–¹æ³•ã€‚</p></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%AF%8F%E5%91%A8%E5%9B%9E%E9%A1%BE/" class="category-chain-item">æ¯å‘¨å›é¡¾</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%80%BB%E7%BB%93-%E5%8F%8D%E6%80%9D/">#æ€»ç»“&åæ€</a></div></div><div class="license-box my-3"><div class="license-title"><div>æ¯å‘¨æ€»ç»“(23.09.04-23.09.10)</div><div>http://seulqxq.top/posts/38005/</div></div><div class="license-meta"><div class="license-meta-item"><div>ä½œè€…</div><div>SeulQxQ</div></div><div class="license-meta-item license-meta-date"><div>å‘å¸ƒäº</div><div>2023å¹´9æœˆ10æ—¥</div></div><div class="license-meta-item"><div>è®¸å¯åè®®</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - ç½²å"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/posts/51013/" title="æ¯å‘¨æ€»ç»“(23.09.18-23.09.24)"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">æ¯å‘¨æ€»ç»“(23.09.18-23.09.24)</span> <span class="visible-mobile">ä¸Šä¸€ç¯‡</span></a></article><article class="post-next col-6"><a href="/posts/36354/" title="æ¯å‘¨æ€»ç»“(23.08.28-23.09.03)"><span class="hidden-mobile">æ¯å‘¨æ€»ç»“(23.08.28-23.09.03)</span> <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",(function(){Fluid.utils.createScript("https://lib.baomitu.com/valine/1.5.1/Valine.min.js",(function(){var i=Object.assign({appId:"Qx9xEhNNylULQaxbl3lPUT12-gzGzoHsz",appKey:"bPPbrUlDDvOhU5HNAawchAXO",path:"window.location.pathname",placeholder:"ç•™ä¸‹ä½ çš„è¶³è¿¹å­ï¼Œå¦‚æœæ„¿æ„è¯ï¼Œä¹Ÿå¯ä»¥ç•™ä¸‹æ˜µç§°å’Œé‚®ç®±å“Ÿ~ ^_^",avatar:"monsterid",meta:["nick","mail","link"],requiredFields:[],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:null,emojiMaps:null,enableQQ:!0},{el:"#valine",path:window.location.pathname});new Valine(i),Fluid.utils.waitElementVisible("#valine .vcontent",(()=>{var i="#valine .vcontent img:not(.vemoji)";Fluid.plugins.imageCaption(i),Fluid.plugins.fancyBox(i)}))}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>ç›®å½•</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">å…³é”®è¯</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><font size="2"><font color="#FFFFFF"><div class="text-center py-3"><div><span id="timeDate">è½½å…¥å¤©æ•°...</span> <span id="times">è½½å…¥æ—¶åˆ†...</span><script>var now=new Date;function createtime(){var n=new Date("05/01/2023 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),document.getElementById("timeDate").innerHTML="ğŸš€ For&nbsp"+dnum+"&nbspdays",document.getElementById("times").innerHTML=hnum+"&nbsphours&nbsp"+mnum+"&nbspminutes&nbspğŸ˜Š"}setInterval("createtime()",250)</script></div><div class="text-center py-1"><div><font size="3"><font color="#FFFFFF"><span>Copyright Â© 2023</span> <a href="https://SeulQxQ.github.io" target="_blank" rel="nofollow noopener"><font size="3"><font color="#FFFFFF"><span>ğŸ‘‰ SeulQxQ's Dream</span></font></font></a><br></font></font></div></div></div></font></font></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://cdn.staticfile.org/anchor-js/4.2.0/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach((t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")}))},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">åšå®¢åœ¨å…è®¸ JavaScript è¿è¡Œçš„ç¯å¢ƒä¸‹æµè§ˆæ•ˆæœæ›´ä½³</div></noscript><script src="/js/backgroundize.js"></script></body></html>